æ ¹æ®ä½ çš„åœºæ™¯ï¼ˆ7ä¸ªæ‘„åƒå¤´ï¼Œæ¯ä¸ªsnapshotæŠ“å–7å¼ raw image dataï¼‰ï¼Œè®©æˆ‘åˆ†ææœ€é€‚åˆçš„ä¼ è¾“æ–¹å¼ï¼š


[5 tools called]

åŸºäºä½ çš„åœºæ™¯ï¼ˆ7ä¸ªæ‘„åƒå¤´ï¼Œæ¯ä¸ªsnapshotæŠ“å–7å¼ raw image dataï¼‰ï¼Œæˆ‘æ¨èä»¥ä¸‹ä¼ è¾“æ–¹æ¡ˆï¼š

## ğŸ¯ **æ¨èæ–¹æ¡ˆï¼šå¤šé€šé“WebSocket + å‹ç¼©ä¼ è¾“**

### 1. **æ¶æ„è®¾è®¡**

```
7ä¸ªæ‘„åƒå¤´ â†’ 7ä¸ªç‹¬ç«‹Channel â†’ å‹ç¼©å¤„ç† â†’ WebSocketå¤šé€šé“ä¼ è¾“ â†’ å‰ç«¯æ¥æ”¶
```

### 2. **å…·ä½“å®ç°æ–¹æ¡ˆ**

#### **æ–¹æ¡ˆAï¼šç‹¬ç«‹é€šé“ä¼ è¾“ï¼ˆæ¨èï¼‰**

```cpp
// åç«¯ï¼šä¸ºæ¯ä¸ªæ‘„åƒå¤´åˆ›å»ºç‹¬ç«‹é€šé“
// 7ä¸ªæ‘„åƒå¤´é…ç½®
std::vector<std::string> camera_channels = {
    "/apollo/sensor/camera/front_6mm/image",
    "/apollo/sensor/camera/front_12mm/image", 
    "/apollo/sensor/camera/front_fisheye/image",
    "/apollo/sensor/camera/left_front/image",
    "/apollo/sensor/camera/left_rear/image",
    "/apollo/sensor/camera/right_front/image",
    "/apollo/sensor/camera/right_rear/image"
};

// æ¯ä¸ªæ‘„åƒå¤´ç‹¬ç«‹çš„WebSocketè¿æ¥
for (const auto& channel : camera_channels) {
    websocket_->addWebSocketHandler("/camera/" + channel, camera_handler);
}
```

#### **æ–¹æ¡ˆBï¼šæ‰¹é‡ä¼ è¾“ï¼ˆé«˜æ•ˆï¼‰**

```cpp
// è‡ªå®šä¹‰MultiCameraUpdate protobuf
message MultiCameraUpdate {
    repeated CameraFrame frames = 1;
    optional double timestamp = 2;
}

message CameraFrame {
    optional string camera_id = 1;        // æ‘„åƒå¤´ID
    optional bytes image_data = 2;        // å‹ç¼©åçš„JPEGæ•°æ®
    optional double timestamp = 3;        // å¸§æ—¶é—´æˆ³
    optional uint32 width = 4;            // å›¾åƒå®½åº¦
    optional uint32 height = 5;           // å›¾åƒé«˜åº¦
    optional double compression_ratio = 6; // å‹ç¼©æ¯”
}

// åç«¯æ‰¹é‡å¤„ç†
void PublishMultiCameraData() {
    MultiCameraUpdate multi_update;
    multi_update.set_timestamp(cyber::Time::Now().ToSecond());
    
    for (int i = 0; i < 7; ++i) {
        CameraFrame* frame = multi_update.add_frames();
        frame->set_camera_id("camera_" + std::to_string(i));
        
        // å‹ç¼©å¤„ç†
        std::vector<uint8_t> compressed_data;
        cv::imencode(".jpg", camera_images[i], compressed_data, 
                    {cv::IMWRITE_JPEG_QUALITY, 85});  // 85%è´¨é‡
        
        frame->set_image_data(compressed_data.data(), compressed_data.size());
        frame->set_width(camera_images[i].cols);
        frame->set_height(camera_images[i].rows);
        frame->set_compression_ratio(compressed_data.size() / 
                                   (double)(camera_images[i].total() * camera_images[i].elemSize()));
    }
    
    // é€šè¿‡WebSocketå‘é€
    std::string serialized_data;
    multi_update.SerializeToString(&serialized_data);
    websocket_->BroadcastBinaryData(serialized_data);
}
```

### 3. **å‰ç«¯æ¥æ”¶å¤„ç†**

```typescript
// å‰ç«¯ï¼šå¤šæ‘„åƒå¤´æ•°æ®æ¥æ”¶
class MultiCameraService {
    private websocket: WebSocket;
    private cameraCanvases: Map<string, HTMLCanvasElement> = new Map();
    
    constructor() {
        this.websocket = new WebSocket('ws://localhost:8888/multicamera');
        this.websocket.binaryType = 'arraybuffer';
        
        this.websocket.onmessage = (event) => {
            const multiUpdate = MultiCameraUpdate.decode(new Uint8Array(event.data));
            this.processMultiCameraData(multiUpdate);
        };
    }
    
    private processMultiCameraData(data: MultiCameraUpdate) {
        data.frames.forEach(frame => {
            const canvas = this.cameraCanvases.get(frame.cameraId);
            if (canvas) {
                this.renderCameraFrame(canvas, frame);
            }
        });
    }
    
    private renderCameraFrame(canvas: HTMLCanvasElement, frame: CameraFrame) {
        const blob = new Blob([frame.imageData], { type: 'image/jpeg' });
        
        createImageBitmap(blob).then(imageBitmap => {
            const ctx = canvas.getContext('2d');
            canvas.width = frame.width;
            canvas.height = frame.height;
            ctx.drawImage(imageBitmap, 0, 0);
        });
    }
}
```

### 4. **æ€§èƒ½ä¼˜åŒ–ç­–ç•¥**

#### **æ•°æ®å‹ç¼©ä¼˜åŒ–**
```cpp
// åˆ†å±‚å‹ç¼©ç­–ç•¥
class ImageCompressor {
public:
    static std::vector<uint8_t> CompressImage(const cv::Mat& image, 
                                            int quality = 85,
                                            bool resize = true) {
        cv::Mat processed = image.clone();
        
        // 1. åˆ†è¾¨ç‡ç¼©æ”¾ï¼ˆå¯é€‰ï¼‰
        if (resize && (image.cols > 1280 || image.rows > 720)) {
            cv::resize(image, processed, cv::Size(1280, 720), 0, 0, cv::INTER_LINEAR);
        }
        
        // 2. JPEGå‹ç¼©
        std::vector<int> compression_params = {
            cv::IMWRITE_JPEG_QUALITY, quality,
            cv::IMWRITE_JPEG_OPTIMIZE, 1
        };
        
        std::vector<uint8_t> compressed;
        cv::imencode(".jpg", processed, compressed, compression_params);
        
        return compressed;
    }
};
```

#### **ä¼ è¾“é¢‘ç‡æ§åˆ¶**
```cpp
// æ™ºèƒ½ä¼ è¾“é¢‘ç‡
class CameraTransmissionController {
private:
    std::map<std::string, double> last_transmission_time;
    double base_interval = 0.1;  // 100msåŸºç¡€é—´éš”
    
public:
    bool ShouldTransmit(const std::string& camera_id, 
                       double current_time,
                       double image_change_ratio = 0.0) {
        // æ ¹æ®å›¾åƒå˜åŒ–ç‡åŠ¨æ€è°ƒæ•´ä¼ è¾“é¢‘ç‡
        double interval = base_interval;
        if (image_change_ratio > 0.1) {  // åœºæ™¯å˜åŒ–å¤§
            interval *= 0.5;  // æé«˜ä¼ è¾“é¢‘ç‡
        } else if (image_change_ratio < 0.01) {  // åœºæ™¯å˜åŒ–å°
            interval *= 2.0;  // é™ä½ä¼ è¾“é¢‘ç‡
        }
        
        if (current_time - last_transmission_time[camera_id] >= interval) {
            last_transmission_time[camera_id] = current_time;
            return true;
        }
        return false;
    }
};
```

### 5. **é…ç½®å»ºè®®**

#### **WebSocketé…ç½®**
```cpp
// åç«¯WebSocketé…ç½®
server_->addWebSocketHandler("/multicamera", *multi_camera_handler);

// æˆ–è€…ç‹¬ç«‹é€šé“é…ç½®
for (int i = 0; i < 7; ++i) {
    std::string endpoint = "/camera/cam_" + std::to_string(i);
    server_->addWebSocketHandler(endpoint, *camera_handlers[i]);
}
```

#### **å‰ç«¯é…ç½®**
```typescript
// å‰ç«¯è¿æ¥é…ç½®
const cameraEndpoints = [
    'ws://localhost:8888/camera/cam_0',
    'ws://localhost:8888/camera/cam_1',
    'ws://localhost:8888/camera/cam_2',
    'ws://localhost:8888/camera/cam_3',
    'ws://localhost:8888/camera/cam_4',
    'ws://localhost:8888/camera/cam_5',
    'ws://localhost:8888/camera/cam_6'
];

// æˆ–è€…å•è¿æ¥æ‰¹é‡æ¥æ”¶
const multiCameraEndpoint = 'ws://localhost:8888/multicamera';
```

### 6. **æ€§èƒ½é¢„æœŸ**

| æ–¹æ¡ˆ         | å¸¦å®½éœ€æ±‚ | å»¶è¿Ÿ | å¤æ‚åº¦ | æ¨èåœºæ™¯     |
| ------------ | -------- | ---- | ------ | ------------ |
| **ç‹¬ç«‹é€šé“** | 7Ã—å¸¦å®½   | ä½   | ä¸­ç­‰   | éœ€è¦ç‹¬ç«‹æ§åˆ¶ |
| **æ‰¹é‡ä¼ è¾“** | 1Ã—å¸¦å®½   | ä¸­ç­‰ | ä½     | åŒæ­¥æ˜¾ç¤º     |
| **å‹ç¼©ä¼ è¾“** | 0.1Ã—å¸¦å®½ | ä¸­ç­‰ | é«˜     | å¸¦å®½å—é™     |

## ğŸš€ **æœ€ç»ˆæ¨è**

å¯¹äºä½ çš„åœºæ™¯ï¼ˆ7æ‘„åƒå¤´Ã—7å¼ raw imageï¼‰ï¼Œæˆ‘æ¨èï¼š

1. **ä½¿ç”¨æ–¹æ¡ˆBï¼ˆæ‰¹é‡ä¼ è¾“ï¼‰** + **é«˜å‹ç¼©æ¯”ï¼ˆ85% JPEGè´¨é‡ï¼‰**
2. **ä¼ è¾“é¢‘ç‡æ§åˆ¶åœ¨10fps**ï¼ˆæ¯100msä¸€æ¬¡ï¼‰
3. **åˆ†è¾¨ç‡ç¼©æ”¾åˆ°1280Ã—720**ï¼ˆå¦‚æœéœ€è¦ï¼‰
4. **ä½¿ç”¨å•WebSocketè¿æ¥**ä¼ è¾“æ‰€æœ‰æ‘„åƒå¤´æ•°æ®

è¿™æ ·å¯ä»¥åœ¨ä¿è¯å›¾åƒè´¨é‡çš„åŒæ—¶ï¼Œå°†å¸¦å®½éœ€æ±‚æ§åˆ¶åœ¨åˆç†èŒƒå›´å†…ï¼ˆé¢„è®¡çº¦10-20MB/sï¼‰ã€‚



åŸºäºä½ çš„åŸå§‹å›¾åƒå¤§å°ï¼ˆ960Ã—640ï¼‰å’Œä¼ è¾“é€Ÿç‡è¦æ±‚ï¼ˆ2MB/sä»¥ä¸‹ï¼‰ï¼Œæˆ‘æ¥è®¾è®¡æœ€ä¼˜çš„å‹ç¼©æ¯”ä¾‹æ–¹æ¡ˆã€‚

## 1. **æ•°æ®é‡åˆ†æ**

### 1.1 åŸå§‹æ•°æ®é‡è®¡ç®—
```cpp
// åŸå§‹å›¾åƒæ•°æ®é‡
å•å¼ å›¾åƒå¤§å° = 960 Ã— 640 Ã— 3 bytes (RGB) = 1,843,200 bytes â‰ˆ 1.76 MB
7å¼ å›¾åƒæ€»å¤§å° = 1.76 MB Ã— 7 = 12.32 MB
```

### 1.2 ç›®æ ‡ä¼ è¾“é€Ÿç‡åˆ†æ
```cpp
// ç›®æ ‡ä¼ è¾“é€Ÿç‡ï¼š2MB/s
// å‡è®¾ä¼ è¾“é¢‘ç‡ï¼š10fps (æ¯100msä¸€æ¬¡)
å•æ¬¡ä¼ è¾“é™åˆ¶ = 2MB/s Ã· 10fps = 0.2MB = 200KB
å•å¼ å›¾åƒé™åˆ¶ = 200KB Ã· 7å¼  = 28.6KB
```

## 2. **å‹ç¼©æ¯”ä¾‹è®¾è®¡**

### 2.1 å¤šçº§å‹ç¼©ç­–ç•¥

```cpp
// modules/dreamview_plus/backend/multi_camera_updater/multi_camera_updater.h
class MultiCameraUpdater {
public:
  // å‹ç¼©é…ç½®ç»“æ„
  struct CompressionConfig {
    double resolution_scale = 0.5;    // åˆ†è¾¨ç‡ç¼©æ”¾ï¼š960â†’480, 640â†’320
    int jpeg_quality = 75;           // JPEGè´¨é‡ï¼š75%
    double target_size_kb = 25.0;    // ç›®æ ‡å¤§å°ï¼š25KB/å¼ 
    double max_total_size_kb = 175.0; // æœ€å¤§æ€»å¤§å°ï¼š175KB (7Ã—25KB)
  };
  
private:
  CompressionConfig compression_config_;
  
  // è‡ªé€‚åº”å‹ç¼©
  std::vector<uint8_t> CompressImageAdaptive(
      const cv::Mat& image, 
      const std::string& camera_id,
      double target_size_kb);
      
  // è®¡ç®—æœ€ä¼˜å‹ç¼©å‚æ•°
  CompressionConfig CalculateOptimalCompression(
      const std::vector<cv::Mat>& images);
};
```

### 2.2 è‡ªé€‚åº”å‹ç¼©å®ç°

```cpp
// modules/dreamview_plus/backend/multi_camera_updater/multi_camera_updater.cc

MultiCameraUpdater::MultiCameraUpdater(WebSocketHandler* websocket)
    : websocket_(websocket),
      node_(cyber::CreateNode("multi_camera_updater")),
      last_transmission_time_(0.0),
      transmission_interval_(0.1) {
  
  // åˆå§‹åŒ–å‹ç¼©é…ç½®
  compression_config_.resolution_scale = 0.5;  // 50%ç¼©æ”¾
  compression_config_.jpeg_quality = 75;       // 75%è´¨é‡
  compression_config_.target_size_kb = 25.0;   // 25KBç›®æ ‡
  compression_config_.max_total_size_kb = 175.0; // 175KBæ€»é™åˆ¶
}

std::vector<uint8_t> MultiCameraUpdater::CompressImageAdaptive(
    const cv::Mat& image, 
    const std::string& camera_id,
    double target_size_kb) {
  
  if (image.empty()) {
    return {};
  }
  
  // 1. åˆ†è¾¨ç‡ç¼©æ”¾
  cv::Mat resized_image;
  int target_width = static_cast<int>(960 * compression_config_.resolution_scale);
  int target_height = static_cast<int>(640 * compression_config_.resolution_scale);
  
  cv::resize(image, resized_image, cv::Size(target_width, target_height), 
             0, 0, cv::INTER_AREA);  // ä½¿ç”¨INTER_AREAè·å¾—æ›´å¥½çš„ç¼©æ”¾è´¨é‡
  
  // 2. è‡ªé€‚åº”JPEGè´¨é‡
  int quality = compression_config_.jpeg_quality;
  std::vector<uint8_t> compressed_data;
  
  // äºŒåˆ†æœç´¢æœ€ä¼˜è´¨é‡
  int min_quality = 20;
  int max_quality = 95;
  double target_size_bytes = target_size_kb * 1024;
  
  while (min_quality <= max_quality) {
    quality = (min_quality + max_quality) / 2;
    
    std::vector<int> compression_params = {
      cv::IMWRITE_JPEG_QUALITY, quality,
      cv::IMWRITE_JPEG_OPTIMIZE, 1,
      cv::IMWRITE_JPEG_PROGRESSIVE, 1
    };
    
    compressed_data.clear();
    cv::imencode(".jpg", resized_image, compressed_data, compression_params);
    
    if (compressed_data.size() <= target_size_bytes) {
      min_quality = quality + 1;  // å°è¯•æ›´é«˜è´¨é‡
    } else {
      max_quality = quality - 1;  // é™ä½è´¨é‡
    }
  }
  
  // æœ€ç»ˆå‹ç¼©
  quality = max_quality;
  std::vector<int> final_params = {
    cv::IMWRITE_JPEG_QUALITY, quality,
    cv::IMWRITE_JPEG_OPTIMIZE, 1,
    cv::IMWRITE_JPEG_PROGRESSIVE, 1
  };
  
  compressed_data.clear();
  cv::imencode(".jpg", resized_image, compressed_data, final_params);
  
  // è®°å½•å‹ç¼©ç»Ÿè®¡
  double original_size = image.total() * image.elemSize();
  double compressed_size = compressed_data.size();
  double compression_ratio = compressed_size / original_size;
  
  AINFO << "Camera " << camera_id 
        << " - Original: " << (original_size/1024) << "KB"
        << " - Compressed: " << (compressed_size/1024) << "KB"
        << " - Ratio: " << (compression_ratio*100) << "%"
        << " - Quality: " << quality
        << " - Resolution: " << target_width << "x" << target_height;
  
  return compressed_data;
}
```

### 2.3 æ‰¹é‡å‹ç¼©ä¼˜åŒ–

```cpp
void MultiCameraUpdater::PublishMessage() {
  std::lock_guard<std::mutex> transmission_lock(transmission_mutex_);
  double current_time = cyber::Time::Now().ToSecond();
  
  if (current_time - last_transmission_time_ < transmission_interval_) {
    return;
  }
  
  MultiCameraUpdate multi_update;
  multi_update.set_timestamp(current_time);
  multi_update.set_k_image_scale(compression_config_.resolution_scale);
  
  // æ”¶é›†æ‰€æœ‰å›¾åƒ
  std::vector<cv::Mat> all_images;
  std::vector<std::string> camera_ids;
  
  {
    std::lock_guard<std::mutex> channels_lock(channels_mutex_);
    for (auto& [camera_id, channel_info] : camera_channels_) {
      std::lock_guard<std::mutex> image_lock(channel_info->image_mutex);
      if (!channel_info->latest_image.empty()) {
        all_images.push_back(channel_info->latest_image.clone());
        camera_ids.push_back(camera_id);
      }
    }
  }
  
  if (all_images.empty()) {
    return;
  }
  
  // è®¡ç®—æœ€ä¼˜å‹ç¼©é…ç½®
  auto optimal_config = CalculateOptimalCompression(all_images);
  
  // åº”ç”¨æœ€ä¼˜é…ç½®å‹ç¼©æ‰€æœ‰å›¾åƒ
  double total_size_kb = 0;
  for (size_t i = 0; i < all_images.size(); ++i) {
    auto compressed_data = CompressImageAdaptive(
        all_images[i], camera_ids[i], optimal_config.target_size_kb);
    
    if (!compressed_data.empty()) {
      // åˆ›å»ºå¸§æ•°æ®
      CameraFrame* frame = multi_update.add_frames();
      frame->set_camera_id(camera_ids[i]);
      frame->set_image_data(compressed_data.data(), compressed_data.size());
      frame->set_timestamp(current_time);
      frame->set_width(all_images[i].cols);
      frame->set_height(all_images[i].rows);
      frame->set_compression_ratio(
          static_cast<double>(compressed_data.size()) / 
          (all_images[i].total() * all_images[i].elemSize()));
      
      total_size_kb += compressed_data.size() / 1024.0;
    }
  }
  
  if (multi_update.frames_size() > 0) {
    multi_update.set_frame_count(multi_update.frames_size());
    
    // åºåˆ—åŒ–å¹¶å‘é€
    std::string serialized_data;
    multi_update.SerializeToString(&serialized_data);
    
    websocket_->BroadcastBinaryData(serialized_data);
    last_transmission_time_ = current_time;
    
    AINFO << "Published multi-camera data: " 
          << multi_update.frames_size() << " frames, "
          << total_size_kb << "KB total, "
          << (total_size_kb/transmission_interval_) << "KB/s";
  }
}

MultiCameraUpdater::CompressionConfig MultiCameraUpdater::CalculateOptimalCompression(
    const std::vector<cv::Mat>& images) {
  
  CompressionConfig config;
  
  // æ ¹æ®å›¾åƒæ•°é‡åŠ¨æ€è°ƒæ•´
  int image_count = images.size();
  double per_image_limit = compression_config_.max_total_size_kb / image_count;
  
  // åŠ¨æ€è°ƒæ•´åˆ†è¾¨ç‡ç¼©æ”¾
  if (per_image_limit < 20) {
    config.resolution_scale = 0.3;  // 30%ç¼©æ”¾
  } else if (per_image_limit < 30) {
    config.resolution_scale = 0.4;  // 40%ç¼©æ”¾
  } else {
    config.resolution_scale = 0.5;  // 50%ç¼©æ”¾
  }
  
  // åŠ¨æ€è°ƒæ•´JPEGè´¨é‡
  if (per_image_limit < 15) {
    config.jpeg_quality = 60;
  } else if (per_image_limit < 25) {
    config.jpeg_quality = 70;
  } else {
    config.jpeg_quality = 75;
  }
  
  config.target_size_kb = per_image_limit;
  config.max_total_size_kb = compression_config_.max_total_size_kb;
  
  return config;
}
```

## 3. **å‹ç¼©æ•ˆæœé¢„æœŸ**

### 3.1 ä¸åŒé…ç½®ä¸‹çš„æ•°æ®é‡

| åˆ†è¾¨ç‡ç¼©æ”¾    | JPEGè´¨é‡ | å•å¼ å¤§å° | 7å¼ æ€»å¤§å° | ä¼ è¾“é€Ÿç‡ |
| ------------- | -------- | -------- | --------- | -------- |
| 50% (480Ã—320) | 75%      | ~25KB    | ~175KB    | 1.75MB/s |
| 40% (384Ã—256) | 70%      | ~18KB    | ~126KB    | 1.26MB/s |
| 30% (288Ã—192) | 60%      | ~12KB    | ~84KB     | 0.84MB/s |

### 3.2 æ¨èé…ç½®

```cpp
// æ¨èé…ç½®ï¼ˆå¹³è¡¡è´¨é‡å’Œå¸¦å®½ï¼‰
struct RecommendedConfig {
  double resolution_scale = 0.4;    // 40%ç¼©æ”¾ï¼š384Ã—256
  int jpeg_quality = 70;           // 70%è´¨é‡
  double target_size_kb = 18.0;    // ç›®æ ‡18KB/å¼ 
  double max_total_size_kb = 126.0; // æ€»é™åˆ¶126KB
  double max_bandwidth_mbps = 1.26; // 1.26MB/s
};
```

## 4. **å‰ç«¯æ˜¾ç¤ºä¼˜åŒ–**

### 4.1 ç¼©æ”¾æ˜¾ç¤ºå¤„ç†

```typescript
// å‰ç«¯ç»„ä»¶ä¸­å¤„ç†ç¼©æ”¾åçš„å›¾åƒ
const renderCameraFrame = useCallback((canvas: HTMLCanvasElement, frame: CameraFrame) => {
  const blob = new Blob([frame.imageData], { type: 'image/jpeg' });
  
  createImageBitmap(blob)
    .then(imageBitmap => {
      const ctx = canvas.getContext('2d');
      if (!ctx) return;
      
      // è·å–å®¹å™¨å°ºå¯¸
      const containerWidth = canvas.parentElement?.clientWidth || 800;
      const containerHeight = canvas.parentElement?.clientHeight || 600;
      
      // è®¡ç®—æ˜¾ç¤ºå°ºå¯¸ï¼ˆä¿æŒå®½é«˜æ¯”ï¼Œå±…ä¸­æ˜¾ç¤ºï¼‰
      const scaleX = containerWidth / imageBitmap.width;
      const scaleY = containerHeight / imageBitmap.height;
      const scale = Math.min(scaleX, scaleY, 1.0); // ä¸æ”¾å¤§
      
      const displayWidth = imageBitmap.width * scale;
      const displayHeight = imageBitmap.height * scale;
      
      // è®¾ç½®canvaså°ºå¯¸
      canvas.width = displayWidth;
      canvas.height = displayHeight;
      
      // å±…ä¸­ç»˜åˆ¶
      const offsetX = (displayWidth - displayWidth) / 2;
      const offsetY = (displayHeight - displayHeight) / 2;
      
      ctx.drawImage(imageBitmap, offsetX, offsetY, displayWidth, displayHeight);
      
      // æ·»åŠ ä¿¡æ¯è¦†ç›–å±‚
      ctx.fillStyle = 'rgba(0, 0, 0, 0.7)';
      ctx.fillRect(0, 0, displayWidth, 25);
      
      ctx.fillStyle = 'white';
      ctx.font = '12px Arial';
      ctx.fillText(
        `${frame.cameraId} (${frame.width}Ã—${frame.height})`, 
        5, 17
      );
      
      // æ˜¾ç¤ºå‹ç¼©ä¿¡æ¯
      ctx.fillText(
        `${(frame.compressionRatio * 100).toFixed(1)}%`, 
        displayWidth - 50, 17
      );
    });
}, []);
```

## 5. **æ€§èƒ½ç›‘æ§**

### 5.1 å®æ—¶å¸¦å®½ç›‘æ§

```cpp
class BandwidthMonitor {
private:
  std::deque<std::pair<double, double>> bandwidth_history_; // timestamp, size_kb
  double window_size_seconds_ = 5.0; // 5ç§’çª—å£
  
public:
  void RecordTransmission(double timestamp, double size_kb) {
    bandwidth_history_.push_back({timestamp, size_kb});
    
    // æ¸…ç†è¿‡æœŸæ•°æ®
    while (!bandwidth_history_.empty() && 
           timestamp - bandwidth_history_.front().first > window_size_seconds_) {
      bandwidth_history_.pop_front();
    }
  }
  
  double GetAverageBandwidth() const {
    if (bandwidth_history_.size() < 2) return 0.0;
    
    double total_size = 0.0;
    double time_span = bandwidth_history_.back().first - bandwidth_history_.front().first;
    
    for (const auto& [timestamp, size] : bandwidth_history_) {
      total_size += size;
    }
    
    return total_size / time_span; // KB/s
  }
  
  bool IsBandwidthExceeded(double limit_kbps) const {
    return GetAverageBandwidth() > limit_kbps;
  }
};
```

## 6. **æœ€ç»ˆé…ç½®å»ºè®®**

```cpp
// é’ˆå¯¹960Ã—640åŸå§‹å›¾åƒçš„ä¼˜åŒ–é…ç½®
constexpr struct {
  double resolution_scale = 0.4;      // 384Ã—256åˆ†è¾¨ç‡
  int jpeg_quality = 70;             // 70%è´¨é‡
  double target_size_kb = 18.0;      // 18KB/å¼ 
  double max_total_size_kb = 126.0;  // 126KBæ€»è®¡
  double transmission_fps = 10.0;    // 10fps
  double max_bandwidth_mbps = 1.26;  // 1.26MB/s
} OPTIMAL_CONFIG;
```

è¿™ä¸ªé…ç½®å¯ä»¥ç¡®ä¿ï¼š
- âœ… ä¼ è¾“é€Ÿç‡æ§åˆ¶åœ¨1.26MB/sï¼ˆè¿œä½äº2MB/sé™åˆ¶ï¼‰
- âœ… ä¿æŒåˆç†çš„å›¾åƒè´¨é‡ï¼ˆ70%JPEGè´¨é‡ï¼‰
- âœ… æ”¯æŒå®æ—¶ä¼ è¾“ï¼ˆ10fpsï¼‰
- âœ… è‡ªé€‚åº”å‹ç¼©è°ƒæ•´
- âœ… å®æ—¶æ€§èƒ½ç›‘æ§

é€šè¿‡è¿™ç§å¤šçº§å‹ç¼©ç­–ç•¥ï¼Œå¯ä»¥åœ¨æ»¡è¶³å¸¦å®½é™åˆ¶çš„åŒæ—¶ï¼Œæœ€å¤§åŒ–å›¾åƒè´¨é‡ã€‚

å¥½é—®é¢˜ï¼è®©æˆ‘è¯¦ç»†è§£é‡Šä¸ºä»€ä¹ˆç§°ä¸º"å¤šçº§å‹ç¼©"ï¼Œä»¥åŠè¿™ç§å‹ç¼©ç­–ç•¥çš„å…·ä½“å«ä¹‰ã€‚

## 1. **ä¼ ç»Ÿå•çº§å‹ç¼© vs å¤šçº§å‹ç¼©**

### 1.1 ä¼ ç»Ÿå•çº§å‹ç¼©
```cpp
// ä¼ ç»Ÿæ–¹å¼ï¼šåªè¿›è¡Œä¸€æ¬¡å‹ç¼©
cv::Mat original_image; // 960Ã—640
cv::Mat compressed_image;
cv::imencode(".jpg", original_image, compressed_image, {cv::IMWRITE_JPEG_QUALITY, 85});
// ç»“æœï¼šå¯èƒ½å¾—åˆ° 200KB çš„å›¾åƒï¼Œè¿œè¶…ç›®æ ‡å¤§å°
```

### 1.2 å¤šçº§å‹ç¼©ç­–ç•¥
```cpp
// å¤šçº§å‹ç¼©ï¼šåˆ†å¤šä¸ªé˜¶æ®µè¿›è¡Œå‹ç¼©
cv::Mat original_image; // 960Ã—640

// ç¬¬ä¸€çº§ï¼šåˆ†è¾¨ç‡å‹ç¼©
cv::Mat resized_image;
cv::resize(original_image, resized_image, cv::Size(384, 256)); // 40%ç¼©æ”¾

// ç¬¬äºŒçº§ï¼šè´¨é‡å‹ç¼©
cv::Mat quality_compressed;
std::vector<int> params = {cv::IMWRITE_JPEG_QUALITY, 70};
cv::imencode(".jpg", resized_image, quality_compressed, params);

// ç¬¬ä¸‰çº§ï¼šè‡ªé€‚åº”è°ƒæ•´
if (quality_compressed.size() > target_size) {
    // è¿›ä¸€æ­¥é™ä½è´¨é‡æˆ–åˆ†è¾¨ç‡
}
```

## 2. **å¤šçº§å‹ç¼©çš„å…·ä½“å±‚çº§**

### 2.1 ç¬¬ä¸€çº§ï¼šåˆ†è¾¨ç‡å‹ç¼©ï¼ˆSpatial Compressionï¼‰
```cpp
class MultiLevelCompressor {
public:
    enum CompressionLevel {
        LEVEL_1_RESOLUTION = 1,    // åˆ†è¾¨ç‡ç¼©æ”¾
        LEVEL_2_QUALITY = 2,       // JPEGè´¨é‡è°ƒæ•´
        LEVEL_3_ADAPTIVE = 3,      // è‡ªé€‚åº”å‚æ•°è°ƒæ•´
        LEVEL_4_FALLBACK = 4       // é™çº§å¤„ç†
    };
    
private:
    // ç¬¬ä¸€çº§ï¼šåˆ†è¾¨ç‡å‹ç¼©
    cv::Mat CompressResolution(const cv::Mat& image, double scale_factor) {
        cv::Mat resized;
        cv::Size new_size(
            static_cast<int>(image.cols * scale_factor),
            static_cast<int>(image.rows * scale_factor)
        );
        
        // ä½¿ç”¨ä¸åŒçš„æ’å€¼ç®—æ³•
        cv::InterpolationFlags method;
        if (scale_factor < 0.5) {
            method = cv::INTER_AREA;  // ç¼©å°ç”¨AREAï¼Œè´¨é‡æ›´å¥½
        } else {
            method = cv::INTER_LINEAR; // å…¶ä»–æƒ…å†µç”¨çº¿æ€§æ’å€¼
        }
        
        cv::resize(image, resized, new_size, 0, 0, method);
        return resized;
    }
};
```

### 2.2 ç¬¬äºŒçº§ï¼šè´¨é‡å‹ç¼©ï¼ˆQuality Compressionï¼‰
```cpp
    // ç¬¬äºŒçº§ï¼šJPEGè´¨é‡å‹ç¼©
    std::vector<uint8_t> CompressQuality(const cv::Mat& image, int quality) {
        std::vector<int> compression_params = {
            cv::IMWRITE_JPEG_QUALITY, quality,
            cv::IMWRITE_JPEG_OPTIMIZE, 1,        // å¯ç”¨ä¼˜åŒ–
            cv::IMWRITE_JPEG_PROGRESSIVE, 1,     // æ¸è¿›å¼JPEG
            cv::IMWRITE_JPEG_RST_INTERVAL, 64    // é‡å¯é—´éš”
        };
        
        std::vector<uint8_t> compressed;
        cv::imencode(".jpg", image, compressed, compression_params);
        return compressed;
    }
```

### 2.3 ç¬¬ä¸‰çº§ï¼šè‡ªé€‚åº”å‹ç¼©ï¼ˆAdaptive Compressionï¼‰
```cpp
    // ç¬¬ä¸‰çº§ï¼šè‡ªé€‚åº”å‚æ•°è°ƒæ•´
    std::vector<uint8_t> CompressAdaptive(const cv::Mat& image, 
                                         double target_size_kb) {
        double target_bytes = target_size_kb * 1024;
        
        // äºŒåˆ†æœç´¢æœ€ä¼˜è´¨é‡å‚æ•°
        int min_quality = 20;
        int max_quality = 95;
        int optimal_quality = 70;
        
        while (min_quality <= max_quality) {
            int test_quality = (min_quality + max_quality) / 2;
            auto compressed = CompressQuality(image, test_quality);
            
            if (compressed.size() <= target_bytes) {
                optimal_quality = test_quality;
                min_quality = test_quality + 1; // å°è¯•æ›´é«˜è´¨é‡
            } else {
                max_quality = test_quality - 1; // é™ä½è´¨é‡
            }
        }
        
        return CompressQuality(image, optimal_quality);
    }
```

### 2.4 ç¬¬å››çº§ï¼šé™çº§å¤„ç†ï¼ˆFallback Compressionï¼‰
```cpp
    // ç¬¬å››çº§ï¼šé™çº§å¤„ç†ï¼ˆå½“å…¶ä»–çº§åˆ«éƒ½æ— æ³•æ»¡è¶³è¦æ±‚æ—¶ï¼‰
    std::vector<uint8_t> CompressFallback(const cv::Mat& image, 
                                         double target_size_kb) {
        double target_bytes = target_size_kb * 1024;
        
        // å°è¯•æ›´æ¿€è¿›çš„åˆ†è¾¨ç‡å‹ç¼©
        std::vector<double> fallback_scales = {0.3, 0.25, 0.2, 0.15};
        std::vector<int> fallback_qualities = {50, 40, 30, 20};
        
        for (double scale : fallback_scales) {
            for (int quality : fallback_qualities) {
                auto resized = CompressResolution(image, scale);
                auto compressed = CompressQuality(resized, quality);
                
                if (compressed.size() <= target_bytes) {
                    AINFO << "Fallback compression: scale=" << scale 
                          << ", quality=" << quality
                          << ", size=" << (compressed.size()/1024.0) << "KB";
                    return compressed;
                }
            }
        }
        
        // æœ€åçš„æç«¯å‹ç¼©
        auto extreme_resized = CompressResolution(image, 0.1); // 10%ç¼©æ”¾
        return CompressQuality(extreme_resized, 10); // 10%è´¨é‡
    }
```

## 3. **å¤šçº§å‹ç¼©çš„å®Œæ•´æµç¨‹**

```cpp
class MultiLevelImageCompressor {
public:
    struct CompressionResult {
        std::vector<uint8_t> compressed_data;
        CompressionLevel used_level;
        double compression_ratio;
        int final_quality;
        cv::Size final_resolution;
        double processing_time_ms;
    };
    
    CompressionResult Compress(const cv::Mat& image, 
                             double target_size_kb,
                             const std::string& camera_id) {
        auto start_time = std::chrono::high_resolution_clock::now();
        
        // ç¬¬ä¸€çº§ï¼šåˆ†è¾¨ç‡å‹ç¼©
        auto resized = CompressResolution(image, 0.4); // 40%ç¼©æ”¾
        auto level1_result = CompressQuality(resized, 70);
        
        if (level1_result.size() <= target_size_kb * 1024) {
            return CreateResult(level1_result, LEVEL_1_RESOLUTION, 70, 
                              resized.size(), start_time);
        }
        
        // ç¬¬äºŒçº§ï¼šè´¨é‡è°ƒæ•´
        auto level2_result = CompressAdaptive(resized, target_size_kb);
        if (!level2_result.empty() && 
            level2_result.size() <= target_size_kb * 1024) {
            return CreateResult(level2_result, LEVEL_2_QUALITY, 70,
                              resized.size(), start_time);
        }
        
        // ç¬¬ä¸‰çº§ï¼šè‡ªé€‚åº”è°ƒæ•´
        auto level3_result = CompressAdaptive(image, target_size_kb);
        if (!level3_result.empty() && 
            level3_result.size() <= target_size_kb * 1024) {
            return CreateResult(level3_result, LEVEL_3_ADAPTIVE, 70,
                              image.size(), start_time);
        }
        
        // ç¬¬å››çº§ï¼šé™çº§å¤„ç†
        auto level4_result = CompressFallback(image, target_size_kb);
        return CreateResult(level4_result, LEVEL_4_FALLBACK, 10,
                          cv::Size(image.cols * 0.1, image.rows * 0.1), 
                          start_time);
    }
    
private:
    CompressionResult CreateResult(const std::vector<uint8_t>& data,
                                 CompressionLevel level,
                                 int quality,
                                 cv::Size resolution,
                                 std::chrono::high_resolution_clock::time_point start) {
        auto end_time = std::chrono::high_resolution_clock::now();
        double processing_time = std::chrono::duration<double, std::milli>(
            end_time - start).count();
        
        return {
            data,
            level,
            static_cast<double>(data.size()) / (resolution.area() * 3),
            quality,
            resolution,
            processing_time
        };
    }
};
```

## 4. **ä¸ºä»€ä¹ˆéœ€è¦å¤šçº§å‹ç¼©ï¼Ÿ**

### 4.1 å•ä¸€å‹ç¼©æ–¹æ³•çš„å±€é™æ€§
```cpp
// é—®é¢˜1ï¼šå›ºå®šè´¨é‡å¯èƒ½è¿‡å¤§æˆ–è¿‡å°
cv::imencode(".jpg", image, compressed, {cv::IMWRITE_JPEG_QUALITY, 85});
// ç»“æœï¼šå¯èƒ½200KBï¼Œè¿œè¶…25KBç›®æ ‡

// é—®é¢˜2ï¼šå›ºå®šåˆ†è¾¨ç‡å¯èƒ½ä¸å¤Ÿçµæ´»
cv::resize(image, resized, cv::Size(480, 320));
cv::imencode(".jpg", resized, compressed, {cv::IMWRITE_JPEG_QUALITY, 70});
// ç»“æœï¼šå¯èƒ½50KBï¼Œè¶…è¿‡25KBç›®æ ‡
```

### 4.2 å¤šçº§å‹ç¼©çš„ä¼˜åŠ¿
```cpp
// ä¼˜åŠ¿1ï¼šæ¸è¿›å¼ä¼˜åŒ–
// 960Ã—640 â†’ 384Ã—256 â†’ 70%è´¨é‡ â†’ 18KB âœ…

// ä¼˜åŠ¿2ï¼šè‡ªé€‚åº”è°ƒæ•´
// å¦‚æœ18KBä»å¤ªå¤§ â†’ 60%è´¨é‡ â†’ 15KB âœ…

// ä¼˜åŠ¿3ï¼šé™çº§ä¿æŠ¤
// å¦‚æœä»å¤ªå¤§ â†’ 288Ã—192 â†’ 50%è´¨é‡ â†’ 12KB âœ…

// ä¼˜åŠ¿4ï¼šè´¨é‡ä¿è¯
// ä¼˜å…ˆä¿æŒåˆ†è¾¨ç‡ï¼Œå¿…è¦æ—¶æ‰é™ä½è´¨é‡
```

## 5. **å¤šçº§å‹ç¼©çš„å†³ç­–æ ‘**

```cpp
class CompressionDecisionTree {
public:
    enum Decision {
        MAINTAIN_RESOLUTION,  // ä¿æŒåˆ†è¾¨ç‡ï¼Œè°ƒæ•´è´¨é‡
        REDUCE_RESOLUTION,    // é™ä½åˆ†è¾¨ç‡ï¼Œä¿æŒè´¨é‡
        AGGRESSIVE_COMPRESS,  // æ¿€è¿›å‹ç¼©
        FALLBACK_COMPRESS     // é™çº§å¤„ç†
    };
    
    Decision DecideCompressionStrategy(const cv::Mat& image, 
                                     double target_size_kb,
                                     const std::string& camera_id) {
        double original_size_mb = (image.total() * image.elemSize()) / (1024.0 * 1024.0);
        double target_size_mb = target_size_kb / 1024.0;
        double required_compression_ratio = target_size_mb / original_size_mb;
        
        // å†³ç­–é€»è¾‘
        if (required_compression_ratio > 0.1) {
            return MAINTAIN_RESOLUTION;  // å‹ç¼©æ¯”è¦æ±‚ä¸é«˜ï¼Œä¿æŒåˆ†è¾¨ç‡
        } else if (required_compression_ratio > 0.05) {
            return REDUCE_RESOLUTION;    // éœ€è¦ä¸­ç­‰å‹ç¼©ï¼Œé™ä½åˆ†è¾¨ç‡
        } else if (required_compression_ratio > 0.02) {
            return AGGRESSIVE_COMPRESS;  // éœ€è¦é«˜å‹ç¼©ï¼Œæ¿€è¿›å¤„ç†
        } else {
            return FALLBACK_COMPRESS;    // éœ€è¦æé«˜å‹ç¼©ï¼Œé™çº§å¤„ç†
        }
    }
};
```

## 6. **æ€»ç»“**

**"å¤šçº§å‹ç¼©"** ä¹‹æ‰€ä»¥ç§°ä¸º"å¤šçº§"ï¼Œæ˜¯å› ä¸ºå®ƒé‡‡ç”¨äº†**åˆ†å±‚é€’è¿›**çš„å‹ç¼©ç­–ç•¥ï¼š

1. **ç¬¬ä¸€çº§**ï¼šåˆ†è¾¨ç‡å‹ç¼©ï¼ˆç©ºé—´åŸŸï¼‰
2. **ç¬¬äºŒçº§**ï¼šè´¨é‡å‹ç¼©ï¼ˆé¢‘åŸŸï¼‰
3. **ç¬¬ä¸‰çº§**ï¼šè‡ªé€‚åº”è°ƒæ•´ï¼ˆå‚æ•°ä¼˜åŒ–ï¼‰
4. **ç¬¬å››çº§**ï¼šé™çº§å¤„ç†ï¼ˆæç«¯æƒ…å†µï¼‰

æ¯ä¸€çº§éƒ½æœ‰**æ˜ç¡®çš„å‹ç¼©ç›®æ ‡**å’Œ**å›é€€æœºåˆ¶**ï¼Œç¡®ä¿ï¼š
- âœ… ä¼˜å…ˆä¿æŒå›¾åƒè´¨é‡
- âœ… æ»¡è¶³å¸¦å®½é™åˆ¶è¦æ±‚
- âœ… å¤„ç†å„ç§è¾¹ç¼˜æƒ…å†µ
- âœ… æä¾›å¯é¢„æµ‹çš„å‹ç¼©ç»“æœ

è¿™ç§è®¾è®¡æ¯”å•ä¸€å‹ç¼©æ–¹æ³•æ›´åŠ **æ™ºèƒ½**ã€**çµæ´»**å’Œ**å¯é **ã€‚

å¾ˆå¥½çš„é—®é¢˜ï¼è®©æˆ‘è¯¦ç»†è§£é‡Š**æ–¹æ¡ˆAï¼ˆCanvaså åŠ ï¼‰**çš„åŸç†å’Œå®ç°æœºåˆ¶ã€‚

## 1. **Canvaså åŠ çš„æ ¸å¿ƒåŸç†**

### 1.1 å›¾å±‚å åŠ æ¦‚å¿µ
```typescript
// Canvaså åŠ æœ¬è´¨ä¸Šæ˜¯åœ¨åŒä¸€ä¸ªå®¹å™¨ä¸­åˆ›å»ºå¤šä¸ªCanvaså…ƒç´ ï¼Œé€šè¿‡CSSå®šä½è®©å®ƒä»¬é‡å 
<div className="camera-container">
  <canvas className="background-layer" />  {/* åº•å±‚ï¼šæ‘„åƒå¤´å›¾åƒ */}
  <canvas className="overlay-layer" />     {/* é¡¶å±‚ï¼šæ£€æµ‹æ¡†å’Œæ ‡æ³¨ */}
</div>
```

### 1.2 åæ ‡ç³»ç»ŸåŒæ­¥
```typescript
// å…³é”®ï¼šä¸¤ä¸ªCanvaså¿…é¡»ä¿æŒå®Œå…¨ç›¸åŒçš„å°ºå¯¸å’Œä½ç½®
const setupOverlayCanvas = (mainCanvas: HTMLCanvasElement, overlayCanvas: HTMLCanvasElement) => {
  // 1. è·å–ä¸»Canvasçš„å°ºå¯¸å’Œä½ç½®
  const rect = mainCanvas.getBoundingClientRect();
  const width = mainCanvas.width;
  const height = mainCanvas.height;
  
  // 2. è®¾ç½®å åŠ Canvaså®Œå…¨ç›¸åŒçš„å°ºå¯¸
  overlayCanvas.width = width;
  overlayCanvas.height = height;
  
  // 3. é€šè¿‡CSSç»å¯¹å®šä½è®©å®ƒä»¬é‡å 
  overlayCanvas.style.position = 'absolute';
  overlayCanvas.style.left = rect.left + 'px';
  overlayCanvas.style.top = rect.top + 'px';
  overlayCanvas.style.pointerEvents = 'none'; // ä¸é˜»æŒ¡é¼ æ ‡äº‹ä»¶
};
```

## 2. **åæ ‡è½¬æ¢åŸç†**

### 2.1 åæ ‡ç³»æ˜ å°„
```typescript
class CoordinateMapper {
  private originalWidth: number;   // åŸå§‹å›¾åƒå®½åº¦ (960)
  private originalHeight: number;  // åŸå§‹å›¾åƒé«˜åº¦ (640)
  private displayWidth: number;    // æ˜¾ç¤ºå®½åº¦ (ç¼©æ”¾å)
  private displayHeight: number;   // æ˜¾ç¤ºé«˜åº¦ (ç¼©æ”¾å)
  private scale: number;           // ç¼©æ”¾æ¯”ä¾‹
  
  constructor(originalSize: {width: number, height: number}, 
              displaySize: {width: number, height: number}) {
    this.originalWidth = originalSize.width;
    this.originalHeight = originalSize.height;
    this.displayWidth = displaySize.width;
    this.displayHeight = displaySize.height;
    this.scale = Math.min(displaySize.width / originalSize.width, 
                         displaySize.height / originalSize.height);
  }
  
  // å°†åŸå§‹å›¾åƒåæ ‡è½¬æ¢ä¸ºæ˜¾ç¤ºåæ ‡
  mapToDisplay(originalX: number, originalY: number): {x: number, y: number} {
    return {
      x: originalX * this.scale,
      y: originalY * this.scale
    };
  }
  
  // å°†åŸå§‹å›¾åƒå°ºå¯¸è½¬æ¢ä¸ºæ˜¾ç¤ºå°ºå¯¸
  mapSizeToDisplay(originalWidth: number, originalHeight: number): {width: number, height: number} {
    return {
      width: originalWidth * this.scale,
      height: originalHeight * this.scale
    };
  }
}
```

### 2.2 å®é™…åæ ‡è½¬æ¢ç¤ºä¾‹
```typescript
// å‡è®¾æ£€æµ‹æ¡†åœ¨åŸå§‹å›¾åƒä¸­çš„åæ ‡
const detectionBox = {
  xmin: 100,  // åŸå§‹å›¾åƒXåæ ‡
  ymin: 80,   // åŸå§‹å›¾åƒYåæ ‡
  xmax: 200,  // åŸå§‹å›¾åƒXåæ ‡
  ymax: 180   // åŸå§‹å›¾åƒYåæ ‡
};

// å›¾åƒç¼©æ”¾ä¿¡æ¯
const imageInfo = {
  originalWidth: 960,
  originalHeight: 640,
  displayWidth: 480,  // 50%ç¼©æ”¾
  displayHeight: 320,
  scale: 0.5
};

// åæ ‡è½¬æ¢
const mapper = new CoordinateMapper(
  {width: 960, height: 640},
  {width: 480, height: 320}
);

const displayBox = {
  x: mapper.mapToDisplay(detectionBox.xmin, detectionBox.ymin).x,      // 50
  y: mapper.mapToDisplay(detectionBox.xmin, detectionBox.ymin).y,      // 40
  width: mapper.mapSizeToDisplay(
    detectionBox.xmax - detectionBox.xmin, 
    detectionBox.ymax - detectionBox.ymin
  ).width,  // 50
  height: mapper.mapSizeToDisplay(
    detectionBox.xmax - detectionBox.xmin, 
    detectionBox.ymax - detectionBox.ymin
  ).height  // 50
};
```

## 3. **Canvaså åŠ çš„å®Œæ•´å®ç°åŸç†**

### 3.1 æ¸²æŸ“ç®¡é“
```typescript
class CanvasOverlayRenderer {
  private mainCanvas: HTMLCanvasElement;
  private overlayCanvas: HTMLCanvasElement;
  private coordinateMapper: CoordinateMapper;
  
  constructor(mainCanvas: HTMLCanvasElement, overlayCanvas: HTMLCanvasElement) {
    this.mainCanvas = mainCanvas;
    this.overlayCanvas = overlayCanvas;
    this.coordinateMapper = new CoordinateMapper(
      {width: 960, height: 640},
      {width: 480, height: 320}
    );
  }
  
  // æ¸²æŸ“ç®¡é“ï¼šå›¾åƒ â†’ ä¸»Canvas â†’ æ£€æµ‹æ•°æ® â†’ å åŠ Canvas
  render(cameraFrame: CameraFrame, detections: Detection[]) {
    // æ­¥éª¤1ï¼šæ¸²æŸ“ä¸»å›¾åƒåˆ°ä¸»Canvas
    this.renderMainImage(cameraFrame);
    
    // æ­¥éª¤2ï¼šæ¸²æŸ“æ£€æµ‹æ¡†åˆ°å åŠ Canvas
    this.renderDetections(detections);
  }
  
  // æ¸²æŸ“ä¸»å›¾åƒ
  private async renderMainImage(frame: CameraFrame) {
    const blob = new Blob([frame.imageData], { type: 'image/jpeg' });
    const imageBitmap = await createImageBitmap(blob);
    
    const ctx = this.mainCanvas.getContext('2d')!;
    
    // è®¡ç®—æ˜¾ç¤ºå°ºå¯¸
    const scale = Math.min(
      this.mainCanvas.clientWidth / imageBitmap.width,
      this.mainCanvas.clientHeight / imageBitmap.height
    );
    
    const displayWidth = imageBitmap.width * scale;
    const displayHeight = imageBitmap.height * scale;
    
    // è®¾ç½®Canvaså°ºå¯¸
    this.mainCanvas.width = displayWidth;
    this.mainCanvas.height = displayHeight;
    
    // ç»˜åˆ¶å›¾åƒ
    ctx.drawImage(imageBitmap, 0, 0, displayWidth, displayHeight);
    
    // æ›´æ–°åæ ‡æ˜ å°„å™¨
    this.coordinateMapper = new CoordinateMapper(
      {width: imageBitmap.width, height: imageBitmap.height},
      {width: displayWidth, height: displayHeight}
    );
  }
  
  // æ¸²æŸ“æ£€æµ‹æ¡†
  private renderDetections(detections: Detection[]) {
    const ctx = this.overlayCanvas.getContext('2d')!;
    
    // æ¸…é™¤ä¹‹å‰çš„å†…å®¹
    ctx.clearRect(0, 0, this.overlayCanvas.width, this.overlayCanvas.height);
    
    // è®¾ç½®å åŠ Canvaså°ºå¯¸ä¸ä¸»Canvasä¸€è‡´
    this.overlayCanvas.width = this.mainCanvas.width;
    this.overlayCanvas.height = this.mainCanvas.height;
    
    // æ¸²æŸ“æ¯ä¸ªæ£€æµ‹æ¡†
    detections.forEach(detection => {
      this.renderDetectionBox(ctx, detection);
    });
  }
  
  // æ¸²æŸ“å•ä¸ªæ£€æµ‹æ¡†
  private renderDetectionBox(ctx: CanvasRenderingContext2D, detection: Detection) {
    // åæ ‡è½¬æ¢
    const displayCoords = this.coordinateMapper.mapToDisplay(
      detection.bbox.xmin, 
      detection.bbox.ymin
    );
    const displaySize = this.coordinateMapper.mapSizeToDisplay(
      detection.bbox.xmax - detection.bbox.xmin,
      detection.bbox.ymax - detection.bbox.ymin
    );
    
    // ç»˜åˆ¶æ£€æµ‹æ¡†
    ctx.strokeStyle = this.getDetectionColor(detection.type);
    ctx.lineWidth = 2;
    ctx.strokeRect(displayCoords.x, displayCoords.y, displaySize.width, displaySize.height);
    
    // ç»˜åˆ¶æ ‡ç­¾
    const labelText = `${detection.type} (${(detection.confidence * 100).toFixed(1)}%)`;
    const labelWidth = ctx.measureText(labelText).width + 8;
    const labelHeight = 20;
    
    // æ ‡ç­¾èƒŒæ™¯
    ctx.fillStyle = this.getDetectionColor(detection.type);
    ctx.fillRect(displayCoords.x, displayCoords.y - labelHeight, labelWidth, labelHeight);
    
    // æ ‡ç­¾æ–‡å­—
    ctx.fillStyle = 'white';
    ctx.font = '12px Arial';
    ctx.fillText(labelText, displayCoords.x + 4, displayCoords.y - 6);
  }
}
```

## 4. **åŒæ­¥æœºåˆ¶åŸç†**

### 4.1 å°ºå¯¸åŒæ­¥
```typescript
// å…³é”®ï¼šç¡®ä¿ä¸¤ä¸ªCanvaså§‹ç»ˆä¿æŒåŒæ­¥
class CanvasSynchronizer {
  private mainCanvas: HTMLCanvasElement;
  private overlayCanvas: HTMLCanvasElement;
  private resizeObserver: ResizeObserver;
  
  constructor(mainCanvas: HTMLCanvasElement, overlayCanvas: HTMLCanvasElement) {
    this.mainCanvas = mainCanvas;
    this.overlayCanvas = overlayCanvas;
    
    // ç›‘å¬ä¸»Canvaså°ºå¯¸å˜åŒ–
    this.resizeObserver = new ResizeObserver(() => {
      this.synchronizeCanvasSizes();
    });
    this.resizeObserver.observe(mainCanvas);
  }
  
  private synchronizeCanvasSizes() {
    // è·å–ä¸»Canvasçš„å®é™…æ˜¾ç¤ºå°ºå¯¸
    const rect = this.mainCanvas.getBoundingClientRect();
    
    // åŒæ­¥å åŠ Canvasçš„å°ºå¯¸
    this.overlayCanvas.width = this.mainCanvas.width;
    this.overlayCanvas.height = this.mainCanvas.height;
    
    // åŒæ­¥å åŠ Canvasçš„ä½ç½®
    this.overlayCanvas.style.position = 'absolute';
    this.overlayCanvas.style.left = rect.left + 'px';
    this.overlayCanvas.style.top = rect.top + 'px';
    this.overlayCanvas.style.width = rect.width + 'px';
    this.overlayCanvas.style.height = rect.height + 'px';
  }
}
```

### 4.2 æ¸²æŸ“åŒæ­¥
```typescript
// ç¡®ä¿å›¾åƒå’Œæ£€æµ‹æ¡†åŒæ—¶æ›´æ–°
class SynchronizedRenderer {
  private renderQueue: Array<() => Promise<void>> = [];
  private isRendering = false;
  
  // æ·»åŠ æ¸²æŸ“ä»»åŠ¡åˆ°é˜Ÿåˆ—
  addRenderTask(task: () => Promise<void>) {
    this.renderQueue.push(task);
    this.processRenderQueue();
  }
  
  // å¤„ç†æ¸²æŸ“é˜Ÿåˆ—
  private async processRenderQueue() {
    if (this.isRendering || this.renderQueue.length === 0) {
      return;
    }
    
    this.isRendering = true;
    
    while (this.renderQueue.length > 0) {
      const task = this.renderQueue.shift()!;
      try {
        await task();
      } catch (error) {
        console.error('Render task failed:', error);
      }
    }
    
    this.isRendering = false;
  }
}
```

## 5. **æ€§èƒ½ä¼˜åŒ–åŸç†**

### 5.1 è„åŒºåŸŸé‡ç»˜
```typescript
class DirtyRegionRenderer {
  private lastDetections: Detection[] = [];
  private dirtyRegions: Array<{x: number, y: number, width: number, height: number}> = [];
  
  // åªé‡ç»˜å˜åŒ–çš„åŒºåŸŸ
  renderDetections(newDetections: Detection[]) {
    const ctx = this.overlayCanvas.getContext('2d')!;
    
    // 1. æ¸…é™¤ä¹‹å‰æ£€æµ‹æ¡†çš„åŒºåŸŸ
    this.dirtyRegions.forEach(region => {
      ctx.clearRect(region.x, region.y, region.width, region.height);
    });
    
    // 2. æ¸…é™¤å½“å‰æ£€æµ‹æ¡†çš„åŒºåŸŸ
    newDetections.forEach(detection => {
      const region = this.getDetectionRegion(detection);
      this.dirtyRegions.push(region);
    });
    
    // 3. é‡ç»˜æ–°çš„æ£€æµ‹æ¡†
    newDetections.forEach(detection => {
      this.renderDetectionBox(ctx, detection);
    });
    
    this.lastDetections = newDetections;
  }
  
  private getDetectionRegion(detection: Detection) {
    // è¿”å›æ£€æµ‹æ¡†çš„è¾¹ç•ŒåŒºåŸŸï¼ˆåŒ…å«æ ‡ç­¾ï¼‰
    const coords = this.coordinateMapper.mapToDisplay(detection.bbox.xmin, detection.bbox.ymin);
    const size = this.coordinateMapper.mapSizeToDisplay(
      detection.bbox.xmax - detection.bbox.xmin,
      detection.bbox.ymax - detection.bbox.ymin
    );
    
    return {
      x: coords.x - 5,  // æ‰©å¤§åŒºåŸŸä»¥åŒ…å«æ ‡ç­¾
      y: coords.y - 25,
      width: size.width + 10,
      height: size.height + 30
    };
  }
}
```

### 5.2 Canvasåˆ†å±‚ä¼˜åŒ–
```typescript
// å°†ä¸åŒç±»å‹çš„å…ƒç´ æ”¾åœ¨ä¸åŒçš„Canvaså±‚
class LayeredCanvasRenderer {
  private backgroundCanvas: HTMLCanvasElement;  // èƒŒæ™¯å›¾åƒ
  private detectionCanvas: HTMLCanvasElement;   // æ£€æµ‹æ¡†
  private uiCanvas: HTMLCanvasElement;          // UIå…ƒç´ ï¼ˆæ ‡ç­¾ã€æŒ‰é’®ç­‰ï¼‰
  
  constructor() {
    this.setupCanvasLayers();
  }
  
  private setupCanvasLayers() {
    // èƒŒæ™¯å±‚ï¼šä¸é€æ˜ï¼Œæ‰¿è½½å›¾åƒ
    this.backgroundCanvas.style.zIndex = '1';
    
    // æ£€æµ‹å±‚ï¼šåŠé€æ˜ï¼Œæ‰¿è½½æ£€æµ‹æ¡†
    this.detectionCanvas.style.zIndex = '2';
    this.detectionCanvas.style.backgroundColor = 'transparent';
    
    // UIå±‚ï¼šæœ€é«˜å±‚ï¼Œæ‰¿è½½äº¤äº’å…ƒç´ 
    this.uiCanvas.style.zIndex = '3';
    this.uiCanvas.style.pointerEvents = 'auto';
  }
}
```

## 6. **æ€»ç»“**

**Canvaså åŠ çš„æ ¸å¿ƒåŸç†**ï¼š

1. **å›¾å±‚åˆ†ç¦»**ï¼šå›¾åƒå’Œæ£€æµ‹æ¡†åˆ†åˆ«åœ¨ä¸åŒçš„Canvasä¸Šç»˜åˆ¶
2. **åæ ‡åŒæ­¥**ï¼šé€šè¿‡åæ ‡æ˜ å°„å™¨ç¡®ä¿ä¸¤ä¸ªCanvasçš„åæ ‡ç³»ä¸€è‡´
3. **å°ºå¯¸åŒæ­¥**ï¼šé€šè¿‡ResizeObserverå’ŒCSSå®šä½ç¡®ä¿ä¸¤ä¸ªCanvaså°ºå¯¸å®Œå…¨ä¸€è‡´
4. **æ¸²æŸ“åŒæ­¥**ï¼šé€šè¿‡æ¸²æŸ“é˜Ÿåˆ—ç¡®ä¿å›¾åƒå’Œæ£€æµ‹æ¡†åŒæ—¶æ›´æ–°
5. **æ€§èƒ½ä¼˜åŒ–**ï¼šé€šè¿‡è„åŒºåŸŸé‡ç»˜å’Œåˆ†å±‚æ¸²æŸ“æå‡æ€§èƒ½

è¿™ç§æ–¹æ¡ˆçš„ä¼˜åŠ¿ï¼š
- âœ… **æ€§èƒ½å¥½**ï¼šCanvasæ¸²æŸ“æ¯”DOMæ“ä½œå¿«å¾—å¤š
- âœ… **ç²¾åº¦é«˜**ï¼šåƒç´ çº§ç²¾ç¡®çš„åæ ‡æ˜ å°„
- âœ… **å®æ—¶æ€§å¼º**ï¼šæ”¯æŒé«˜é¢‘æ›´æ–°
- âœ… **å¯æ‰©å±•**ï¼šå®¹æ˜“æ·»åŠ æ–°çš„å åŠ å…ƒç´ 

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆCanvaså åŠ æ–¹æ¡ˆåœ¨å®æ—¶å›¾åƒæ ‡æ³¨åœºæ™¯ä¸­è¢«å¹¿æ³›ä½¿ç”¨çš„åŸå› ã€‚

å½“ç„¶å¯ä»¥ï¼åŠé€æ˜å åŠ æ˜¯éå¸¸å®ç”¨çš„åŠŸèƒ½ï¼Œå¯ä»¥å®ç°æ›´ä¸°å¯Œçš„è§†è§‰æ•ˆæœã€‚è®©æˆ‘ä¸ºä½ å±•ç¤ºå‡ ç§åŠé€æ˜å åŠ çš„å®ç°æ–¹æ¡ˆã€‚

## 1. **CanvasåŠé€æ˜å åŠ **

### 1.1 è®¾ç½®Canvasé€æ˜åº¦

```typescript
// è®¾ç½®Canvaså…ƒç´ çš„é€æ˜åº¦
const setupTransparentCanvas = (canvas: HTMLCanvasElement, opacity: number) => {
  canvas.style.opacity = opacity.toString(); // 0.0 - 1.0
  canvas.style.backgroundColor = 'transparent';
};

// ä½¿ç”¨ç¤ºä¾‹
const overlayCanvas = document.getElementById('overlay-canvas') as HTMLCanvasElement;
setupTransparentCanvas(overlayCanvas, 0.8); // 80%é€æ˜åº¦
```

### 1.2 åœ¨Canvasç»˜åˆ¶ä¸­ä½¿ç”¨alphaé€šé“

```typescript
class TransparentCanvasRenderer {
  private overlayCanvas: HTMLCanvasElement;
  
  renderDetectionWithTransparency(detection: Detection, alpha: number = 0.7) {
    const ctx = this.overlayCanvas.getContext('2d')!;
    
    // è®¾ç½®å…¨å±€é€æ˜åº¦
    ctx.globalAlpha = alpha;
    
    // ç»˜åˆ¶åŠé€æ˜æ£€æµ‹æ¡†
    ctx.strokeStyle = this.getDetectionColor(detection.type);
    ctx.lineWidth = 3;
    ctx.strokeRect(x, y, width, height);
    
    // ç»˜åˆ¶åŠé€æ˜å¡«å……
    ctx.fillStyle = this.getDetectionColor(detection.type);
    ctx.globalAlpha = alpha * 0.3; // å¡«å……æ›´é€æ˜
    ctx.fillRect(x, y, width, height);
    
    // é‡ç½®é€æ˜åº¦
    ctx.globalAlpha = 1.0;
    
    // æ ‡ç­¾ä¿æŒä¸é€æ˜
    this.renderLabel(ctx, detection, x, y);
  }
  
  private renderLabel(ctx: CanvasRenderingContext2D, detection: Detection, x: number, y: number) {
    // æ ‡ç­¾èƒŒæ™¯ï¼ˆåŠé€æ˜ï¼‰
    ctx.fillStyle = 'rgba(0, 0, 0, 0.7)'; // ä½¿ç”¨rgbaè®¾ç½®é€æ˜åº¦
    ctx.fillRect(x, y - 25, 150, 20);
    
    // æ ‡ç­¾æ–‡å­—ï¼ˆä¸é€æ˜ï¼‰
    ctx.fillStyle = 'white';
    ctx.font = '12px Arial';
    ctx.fillText(`${detection.type} (${(detection.confidence * 100).toFixed(1)}%)`, x + 5, y - 10);
  }
}
```

## 2. **CSSåŠé€æ˜å åŠ **

### 2.1 ä½¿ç”¨CSS opacityå’Œrgba

```typescript
// modules/dreamview_plus/frontend/packages/dreamview-core/src/components/panels/MultiCameraView/style.ts
export const useStyle = createUseStyles({
  'overlay-canvas': {
    position: 'absolute',
    top: 0,
    left: 0,
    pointerEvents: 'none',
    zIndex: 2,
    opacity: 0.8, // æ•´ä¸ªCanvasåŠé€æ˜
    backgroundColor: 'transparent',
  },
  
  'detection-box': {
    position: 'absolute',
    border: '2px solid rgba(255, 107, 107, 0.8)', // åŠé€æ˜è¾¹æ¡†
    backgroundColor: 'rgba(255, 107, 107, 0.2)',   // åŠé€æ˜èƒŒæ™¯
    borderRadius: '4px',
    transition: 'all 0.2s ease',
    '&:hover': {
      backgroundColor: 'rgba(255, 107, 107, 0.4)', // æ‚¬åœæ—¶æ›´ä¸é€æ˜
      border: '2px solid rgba(255, 107, 107, 1.0)',
    },
  },
  
  'detection-label': {
    position: 'absolute',
    backgroundColor: 'rgba(0, 0, 0, 0.7)', // åŠé€æ˜é»‘è‰²èƒŒæ™¯
    color: 'white',
    padding: '2px 6px',
    fontSize: '12px',
    borderRadius: '3px',
    backdropFilter: 'blur(4px)', // æ¯›ç»ç’ƒæ•ˆæœ
  },
});
```

### 2.2 åŠ¨æ€é€æ˜åº¦æ§åˆ¶

```typescript
// åˆ›å»ºé€æ˜åº¦æ§åˆ¶ç»„ä»¶
const TransparencyController: React.FC = () => {
  const [overlayOpacity, setOverlayOpacity] = useState(0.8);
  const [detectionOpacity, setDetectionOpacity] = useState(0.7);
  
  return (
    <div className={classes['transparency-controls']}>
      <div className={classes['control-group']}>
        <label>å åŠ å±‚é€æ˜åº¦:</label>
        <input
          type="range"
          min="0"
          max="1"
          step="0.1"
          value={overlayOpacity}
          onChange={(e) => setOverlayOpacity(parseFloat(e.target.value))}
        />
        <span>{Math.round(overlayOpacity * 100)}%</span>
      </div>
      
      <div className={classes['control-group']}>
        <label>æ£€æµ‹æ¡†é€æ˜åº¦:</label>
        <input
          type="range"
          min="0"
          max="1"
          step="0.1"
          value={detectionOpacity}
          onChange={(e) => setDetectionOpacity(parseFloat(e.target.value))}
        />
        <span>{Math.round(detectionOpacity * 100)}%</span>
      </div>
    </div>
  );
};
```

## 3. **é«˜çº§åŠé€æ˜æ•ˆæœ**

### 3.1 æ¸å˜åŠé€æ˜å åŠ 

```typescript
class GradientTransparencyRenderer {
  private overlayCanvas: HTMLCanvasElement;
  
  renderGradientDetection(detection: Detection) {
    const ctx = this.overlayCanvas.getContext('2d')!;
    const { x, y, width, height } = this.getDetectionBounds(detection);
    
    // åˆ›å»ºæ¸å˜æ•ˆæœ
    const gradient = ctx.createLinearGradient(x, y, x + width, y + height);
    gradient.addColorStop(0, `rgba(255, 107, 107, 0.8)`); // èµ·å§‹ç‚¹ï¼š80%é€æ˜åº¦
    gradient.addColorStop(0.5, `rgba(255, 107, 107, 0.4)`); // ä¸­é—´ç‚¹ï¼š40%é€æ˜åº¦
    gradient.addColorStop(1, `rgba(255, 107, 107, 0.1)`);   // ç»“æŸç‚¹ï¼š10%é€æ˜åº¦
    
    // ç»˜åˆ¶æ¸å˜æ£€æµ‹æ¡†
    ctx.fillStyle = gradient;
    ctx.fillRect(x, y, width, height);
    
    // è¾¹æ¡†ä¿æŒç›¸å¯¹ä¸é€æ˜
    ctx.strokeStyle = `rgba(255, 107, 107, 0.9)`;
    ctx.lineWidth = 2;
    ctx.strokeRect(x, y, width, height);
  }
  
  renderRadialTransparency(detection: Detection) {
    const ctx = this.overlayCanvas.getContext('2d')!;
    const { x, y, width, height } = this.getDetectionBounds(detection);
    
    // å¾„å‘æ¸å˜ï¼ˆä»ä¸­å¿ƒå‘å¤–é€æ˜åº¦é€’å‡ï¼‰
    const centerX = x + width / 2;
    const centerY = y + height / 2;
    const radius = Math.max(width, height) / 2;
    
    const radialGradient = ctx.createRadialGradient(centerX, centerY, 0, centerX, centerY, radius);
    radialGradient.addColorStop(0, `rgba(255, 107, 107, 0.8)`); // ä¸­å¿ƒï¼š80%é€æ˜åº¦
    radialGradient.addColorStop(1, `rgba(255, 107, 107, 0.1)`); // è¾¹ç¼˜ï¼š10%é€æ˜åº¦
    
    ctx.fillStyle = radialGradient;
    ctx.fillRect(x, y, width, height);
  }
}
```

### 3.2 åŠ¨æ€é€æ˜åº¦åŠ¨ç”»

```typescript
class AnimatedTransparencyRenderer {
  private overlayCanvas: HTMLCanvasElement;
  private animationFrameId: number | null = null;
  private animationStartTime: number = 0;
  
  renderAnimatedDetection(detection: Detection) {
    if (this.animationFrameId) {
      cancelAnimationFrame(this.animationFrameId);
    }
    
    this.animationStartTime = performance.now();
    this.animateDetection(detection);
  }
  
  private animateDetection(detection: Detection) {
    const ctx = this.overlayCanvas.getContext('2d')!;
    const currentTime = performance.now();
    const elapsed = currentTime - this.animationStartTime;
    
    // è®¡ç®—é€æ˜åº¦ï¼ˆå‘¼å¸æ•ˆæœï¼š0.3 - 0.8ï¼‰
    const alpha = 0.3 + 0.5 * (1 + Math.sin(elapsed * 0.005)) / 2;
    
    // æ¸…é™¤ä¹‹å‰çš„å†…å®¹
    ctx.clearRect(0, 0, this.overlayCanvas.width, this.overlayCanvas.height);
    
    // ç»˜åˆ¶åŠ¨ç”»æ£€æµ‹æ¡†
    ctx.globalAlpha = alpha;
    this.renderDetectionBox(ctx, detection);
    
    // ç»§ç»­åŠ¨ç”»
    this.animationFrameId = requestAnimationFrame(() => this.animateDetection(detection));
  }
  
  stopAnimation() {
    if (this.animationFrameId) {
      cancelAnimationFrame(this.animationFrameId);
      this.animationFrameId = null;
    }
  }
}
```

## 4. **æ··åˆæ¨¡å¼åŠé€æ˜**

### 4.1 Canvasæ··åˆæ¨¡å¼

```typescript
class BlendModeRenderer {
  private overlayCanvas: HTMLCanvasElement;
  
  renderWithBlendMode(detection: Detection) {
    const ctx = this.overlayCanvas.getContext('2d')!;
    const { x, y, width, height } = this.getDetectionBounds(detection);
    
    // è®¾ç½®æ··åˆæ¨¡å¼
    ctx.globalCompositeOperation = 'multiply'; // ç›¸ä¹˜æ¨¡å¼
    ctx.globalAlpha = 0.6;
    
    // ç»˜åˆ¶æ£€æµ‹æ¡†
    ctx.fillStyle = this.getDetectionColor(detection.type);
    ctx.fillRect(x, y, width, height);
    
    // é‡ç½®æ··åˆæ¨¡å¼
    ctx.globalCompositeOperation = 'source-over';
    ctx.globalAlpha = 1.0;
    
    // ç»˜åˆ¶è¾¹æ¡†ï¼ˆæ­£å¸¸æ¨¡å¼ï¼‰
    ctx.strokeStyle = this.getDetectionColor(detection.type);
    ctx.lineWidth = 2;
    ctx.strokeRect(x, y, width, height);
  }
  
  // å¯ç”¨çš„æ··åˆæ¨¡å¼
  private blendModes = [
    'source-over',    // æ­£å¸¸
    'multiply',       // ç›¸ä¹˜
    'screen',         // æ»¤è‰²
    'overlay',        // å åŠ 
    'soft-light',     // æŸ”å…‰
    'hard-light',     // å¼ºå…‰
    'color-dodge',    // é¢œè‰²å‡æ·¡
    'color-burn',     // é¢œè‰²åŠ æ·±
    'difference',     // å·®å€¼
    'exclusion',      // æ’é™¤
  ];
}
```

### 4.2 CSSæ··åˆæ¨¡å¼

```css
/* CSSæ··åˆæ¨¡å¼ */
.detection-overlay {
  mix-blend-mode: multiply; /* ç›¸ä¹˜æ··åˆ */
  opacity: 0.6;
}

.detection-box {
  mix-blend-mode: overlay; /* å åŠ æ··åˆ */
  background-color: rgba(255, 107, 107, 0.5);
}

/* æ¯›ç»ç’ƒæ•ˆæœ */
.glass-effect {
  backdrop-filter: blur(8px);
  background-color: rgba(255, 255, 255, 0.1);
  border: 1px solid rgba(255, 255, 255, 0.2);
}
```

## 5. **å®Œæ•´çš„åŠé€æ˜å åŠ ç»„ä»¶**

```typescript
// modules/dreamview_plus/frontend/packages/dreamview-core/src/components/panels/MultiCameraView/TransparentDetectionOverlay.tsx
import React, { useRef, useEffect, useState } from 'react';

interface TransparentDetectionOverlayProps {
  detections: Detection[];
  cameraId: string;
  scale: number;
  displayWidth: number;
  displayHeight: number;
  transparency: number;
  blendMode: string;
  showGradient: boolean;
}

const TransparentDetectionOverlay: React.FC<TransparentDetectionOverlayProps> = ({
  detections,
  cameraId,
  scale,
  displayWidth,
  displayHeight,
  transparency,
  blendMode,
  showGradient
}) => {
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [animationFrameId, setAnimationFrameId] = useState<number | null>(null);
  
  useEffect(() => {
    const canvas = canvasRef.current;
    if (!canvas) return;
    
    const ctx = canvas.getContext('2d');
    if (!ctx) return;
    
    // è®¾ç½®Canvaså°ºå¯¸
    canvas.width = displayWidth;
    canvas.height = displayHeight;
    
    // è®¾ç½®æ··åˆæ¨¡å¼
    ctx.globalCompositeOperation = blendMode as GlobalCompositeOperation;
    
    // æ¸…é™¤ç”»å¸ƒ
    ctx.clearRect(0, 0, displayWidth, displayHeight);
    
    // è¿‡æ»¤å½“å‰æ‘„åƒå¤´çš„æ£€æµ‹ç»“æœ
    const currentDetections = detections.filter(det => det.cameraId === cameraId);
    
    // æ¸²æŸ“æ¯ä¸ªæ£€æµ‹æ¡†
    currentDetections.forEach(detection => {
      renderDetection(ctx, detection, transparency, showGradient);
    });
    
    return () => {
      if (animationFrameId) {
        cancelAnimationFrame(animationFrameId);
      }
    };
  }, [detections, cameraId, scale, displayWidth, displayHeight, transparency, blendMode, showGradient]);
  
  const renderDetection = (
    ctx: CanvasRenderingContext2D, 
    detection: Detection, 
    alpha: number,
    useGradient: boolean
  ) => {
    const x = detection.bbox.xmin * scale;
    const y = detection.bbox.ymin * scale;
    const width = (detection.bbox.xmax - detection.bbox.xmin) * scale;
    const height = (detection.bbox.ymax - detection.bbox.ymin) * scale;
    
    // è®¾ç½®é€æ˜åº¦
    ctx.globalAlpha = alpha;
    
    if (useGradient) {
      // æ¸å˜å¡«å……
      const gradient = ctx.createLinearGradient(x, y, x + width, y + height);
      gradient.addColorStop(0, `rgba(255, 107, 107, ${alpha})`);
      gradient.addColorStop(1, `rgba(255, 107, 107, ${alpha * 0.3})`);
      ctx.fillStyle = gradient;
    } else {
      // çº¯è‰²å¡«å……
      ctx.fillStyle = `rgba(255, 107, 107, ${alpha})`;
    }
    
    // ç»˜åˆ¶æ£€æµ‹æ¡†
    ctx.fillRect(x, y, width, height);
    
    // ç»˜åˆ¶è¾¹æ¡†ï¼ˆæ›´ä¸é€æ˜ï¼‰
    ctx.globalAlpha = Math.min(alpha + 0.3, 1.0);
    ctx.strokeStyle = getDetectionColor(detection.type);
    ctx.lineWidth = 2;
    ctx.strokeRect(x, y, width, height);
    
    // ç»˜åˆ¶æ ‡ç­¾ï¼ˆä¸é€æ˜ï¼‰
    ctx.globalAlpha = 1.0;
    renderLabel(ctx, detection, x, y);
    
    // é‡ç½®é€æ˜åº¦
    ctx.globalAlpha = 1.0;
  };
  
  const renderLabel = (ctx: CanvasRenderingContext2D, detection: Detection, x: number, y: number) => {
    const labelText = `${detection.type} (${(detection.confidence * 100).toFixed(1)}%)`;
    const labelWidth = ctx.measureText(labelText).width + 8;
    const labelHeight = 20;
    
    // æ ‡ç­¾èƒŒæ™¯ï¼ˆåŠé€æ˜ï¼‰
    ctx.fillStyle = 'rgba(0, 0, 0, 0.7)';
    ctx.fillRect(x, y - labelHeight, labelWidth, labelHeight);
    
    // æ ‡ç­¾æ–‡å­—
    ctx.fillStyle = 'white';
    ctx.font = '12px Arial';
    ctx.fillText(labelText, x + 4, y - 6);
  };
  
  return (
    <canvas
      ref={canvasRef}
      style={{
        position: 'absolute',
        top: 0,
        left: 0,
        pointerEvents: 'none',
        zIndex: 2,
      }}
    />
  );
};

const getDetectionColor = (type: string): string => {
  const colorMap: { [key: string]: string } = {
    'car': '#FF6B6B',
    'truck': '#4ECDC4',
    'bus': '#45B7D1',
    'person': '#96CEB4',
    'bicycle': '#FECA57',
    'motorcycle': '#FF9FF3',
    'traffic_light': '#54A0FF',
    'stop_sign': '#5F27CD'
  };
  return colorMap[type] || '#FF6B6B';
};

export default TransparentDetectionOverlay;
```

## 6. **ä½¿ç”¨ç¤ºä¾‹**

```typescript
// åœ¨ä¸»ç»„ä»¶ä¸­ä½¿ç”¨åŠé€æ˜å åŠ 
function InternalMultiCameraView() {
  const [transparency, setTransparency] = useState(0.7);
  const [blendMode, setBlendMode] = useState('source-over');
  const [showGradient, setShowGradient] = useState(false);
  
  return (
    <div className={classes['multi-camera-container']}>
      {/* é€æ˜åº¦æ§åˆ¶ */}
      <div className={classes['transparency-controls']}>
        <input
          type="range"
          min="0"
          max="1"
          step="0.1"
          value={transparency}
          onChange={(e) => setTransparency(parseFloat(e.target.value))}
        />
        <select
          value={blendMode}
          onChange={(e) => setBlendMode(e.target.value)}
        >
          <option value="source-over">æ­£å¸¸</option>
          <option value="multiply">ç›¸ä¹˜</option>
          <option value="screen">æ»¤è‰²</option>
          <option value="overlay">å åŠ </option>
        </select>
        <label>
          <input
            type="checkbox"
            checked={showGradient}
            onChange={(e) => setShowGradient(e.target.checked)}
          />
          æ¸å˜æ•ˆæœ
        </label>
      </div>
      
      {/* ä¸»æ‘„åƒå¤´æ˜¾ç¤ºåŒºåŸŸ */}
      <div className={classes['main-camera-view']}>
        <canvas
          ref={(canvas) => registerCanvas(selectedCamera, canvas)}
          className={classes['main-camera-canvas']}
        />
        
        {/* åŠé€æ˜æ£€æµ‹å åŠ å±‚ */}
        <TransparentDetectionOverlay
          detections={detections}
          cameraId={selectedCamera}
          scale={displayInfo.scale}
          displayWidth={displayInfo.displayWidth}
          displayHeight={displayInfo.displayHeight}
          transparency={transparency}
          blendMode={blendMode}
          showGradient={showGradient}
        />
      </div>
    </div>
  );
}
```

## æ€»ç»“

åŠé€æ˜å åŠ å¯ä»¥å®ç°ï¼š

- âœ… **è§†è§‰æ•ˆæœä¸°å¯Œ**ï¼šæ¸å˜ã€åŠ¨ç”»ã€æ··åˆæ¨¡å¼
- âœ… **ä¿¡æ¯å±‚æ¬¡æ¸…æ™°**ï¼šé‡è¦ä¿¡æ¯çªå‡ºï¼ŒèƒŒæ™¯ä¿¡æ¯æ·¡åŒ–
- âœ… **ç”¨æˆ·ä½“éªŒå¥½**ï¼šå¯è°ƒèŠ‚é€æ˜åº¦ï¼Œé€‚åº”ä¸åŒéœ€æ±‚
- âœ… **æ€§èƒ½ä¼˜åŒ–**ï¼šé€šè¿‡é€æ˜åº¦å‡å°‘è§†è§‰å¹²æ‰°
- âœ… **äº¤äº’å‹å¥½**ï¼šä¿æŒèƒŒæ™¯å›¾åƒå¯è§æ€§çš„åŒæ—¶çªå‡ºæ£€æµ‹ç»“æœ

è¿™ç§åŠé€æ˜å åŠ ç‰¹åˆ«é€‚åˆåœ¨æ‘„åƒå¤´å›¾åƒä¸Šæ˜¾ç¤ºæ£€æµ‹ç»“æœï¼Œæ—¢ä¿æŒäº†åŸå§‹å›¾åƒçš„å®Œæ•´æ€§ï¼Œåˆæ¸…æ™°åœ°æ ‡æ³¨äº†æ£€æµ‹åˆ°çš„ç‰©ä½“ã€‚

å¾ˆå¥½çš„é—®é¢˜ï¼è®©æˆ‘è¯¦ç»†è§£é‡Šå¦‚ä½•å°†multicameraä¼ è¾“é›†æˆåˆ°é¡¹ç›®ç°æœ‰çš„image handlerä¸­ï¼Œä»¥åŠå®ƒä»¬ä¹‹é—´çš„å…³ç³»ã€‚

## 1. **ç°æœ‰Image Handleråˆ†æ**

### 1.1 ä¼ ç»ŸImage Handlerçš„å·¥ä½œæ–¹å¼
```cpp
// modules/dreamview/backend/common/handlers/image_handler.cc
class ImageHandler : public CivetHandler {
public:
  ImageHandler();
  bool handleGet(CivetServer *server, struct mg_connection *conn);

private:
  template <typename SensorMsgsImage>
  void OnImage(const std::shared_ptr<SensorMsgsImage> &image);
  
  std::vector<uint8_t> send_buffer_;
  std::atomic<int> requests_;
  std::unique_ptr<cyber::Node> node_;
};

// å…³é”®ï¼šä¼ ç»Ÿæ–¹å¼é€šè¿‡HTTP MJPEGæµä¼ è¾“
bool ImageHandler::handleGet(CivetServer *server, struct mg_connection *conn) {
  mg_printf(conn,
            "HTTP/1.1 200 OK\r\n"
            "Content-Type: multipart/x-mixed-replace; "  // MJPEGæµ
            "boundary=--BoundaryString\r\n"
            "\r\n");
  
  // æŒç»­å‘é€å›¾åƒå¸§
  while (true) {
    std::vector<uchar> to_send;
    {
      std::unique_lock<std::mutex> lock(mutex_);
      to_send = send_buffer_;
    }
    
    if (!to_send.empty()) {
      mg_printf(conn, "--BoundaryString\r\n"
                "Content-type: image/jpeg\r\n"
                "Content-Length: %zu\r\n\r\n", to_send.size());
      mg_write(conn, &to_send[0], to_send.size());
      mg_printf(conn, "\r\n\r\n");
    }
    std::unique_lock<std::mutex> lock(mutex_);
    cvar_.wait(lock);
  }
}
```

## 2. **MultiCameraä¸Image Handlerçš„é›†æˆæ–¹æ¡ˆ**

### 2.1 æ–¹æ¡ˆAï¼šæ‰©å±•ç°æœ‰Image Handler

```cpp
// modules/dreamview_plus/backend/common/handlers/multi_image_handler.h
#pragma once

#include "modules/dreamview/backend/common/handlers/image_handler.h"
#include "modules/dreamview_plus/backend/multi_camera_updater/multi_camera_updater.h"

namespace apollo {
namespace dreamview {

class MultiImageHandler : public ImageHandler {
public:
  MultiImageHandler();
  ~MultiImageHandler() = default;
  
  // ç»§æ‰¿åŸæœ‰çš„HTTP MJPEGæµåŠŸèƒ½
  bool handleGet(CivetServer *server, struct mg_connection *conn) override;
  
  // æ–°å¢ï¼šWebSocketæ‰¹é‡ä¼ è¾“åŠŸèƒ½
  void StartWebSocketMode();
  void StopWebSocketMode();
  
  // æ–°å¢ï¼šå¤šæ‘„åƒå¤´ç®¡ç†
  void AddCameraChannel(const std::string& channel_name, const std::string& camera_id);
  void RemoveCameraChannel(const std::string& camera_id);
  
  // æ–°å¢ï¼šä¼ è¾“æ¨¡å¼åˆ‡æ¢
  enum TransmissionMode {
    HTTP_MJPEG_STREAM,    // ä¼ ç»ŸHTTP MJPEGæµ
    WEBSOCKET_BATCH,      // WebSocketæ‰¹é‡ä¼ è¾“
    HYBRID_MODE           // æ··åˆæ¨¡å¼
  };
  void SetTransmissionMode(TransmissionMode mode);
  
  // æ–°å¢ï¼šè·å–å¤šæ‘„åƒå¤´æ•°æ®
  void GetMultiCameraUpdate(std::string* multi_camera_data);

private:
  std::unique_ptr<MultiCameraUpdater> multi_camera_updater_;
  std::unique_ptr<WebSocketHandler> websocket_;
  TransmissionMode transmission_mode_;
  
  // å¤šæ‘„åƒå¤´æ•°æ®ç¼“å­˜
  std::map<std::string, cv::Mat> camera_images_;
  std::mutex images_mutex_;
  
  void OnMultiCameraData(const MultiCameraUpdate& update);
  void ProcessHttpRequest(CivetServer *server, struct mg_connection *conn);
  void ProcessWebSocketData();
};

}  // namespace dreamview
}  // namespace apollo
```

### 2.2 å®ç°MultiImageHandler

```cpp
// modules/dreamview_plus/backend/common/handlers/multi_image_handler.cc
#include "modules/dreamview_plus/backend/common/handlers/multi_image_handler.h"

namespace apollo {
namespace dreamview {

MultiImageHandler::MultiImageHandler() 
    : ImageHandler(),  // è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
      transmission_mode_(HTTP_MJPEG_STREAM),
      websocket_(nullptr) {
  
  // åˆå§‹åŒ–å¤šæ‘„åƒå¤´æ›´æ–°å™¨
  multi_camera_updater_.reset(new MultiCameraUpdater(websocket_.get()));
}

bool MultiImageHandler::handleGet(CivetServer *server, struct mg_connection *conn) {
  // æ ¹æ®ä¼ è¾“æ¨¡å¼é€‰æ‹©å¤„ç†æ–¹å¼
  switch (transmission_mode_) {
    case HTTP_MJPEG_STREAM:
      // ä½¿ç”¨çˆ¶ç±»çš„HTTP MJPEGæµå¤„ç†
      return ImageHandler::handleGet(server, conn);
      
    case WEBSOCKET_BATCH:
      // è¿”å›WebSocketè¿æ¥ä¿¡æ¯
      return HandleWebSocketRedirect(server, conn);
      
    case HYBRID_MODE:
      // æ£€æŸ¥è¯·æ±‚ç±»å‹ï¼Œåˆ†åˆ«å¤„ç†
      return ProcessHybridRequest(server, conn);
      
    default:
      return false;
  }
}

bool MultiImageHandler::HandleWebSocketRedirect(CivetServer *server, struct mg_connection *conn) {
  // é‡å®šå‘åˆ°WebSocketç«¯ç‚¹
  mg_printf(conn,
            "HTTP/1.1 302 Found\r\n"
            "Location: ws://%s/multicamera\r\n"
            "Content-Type: text/html\r\n\r\n"
            "<html><body>Redirecting to WebSocket...</body></html>",
            server->getHost());
  return true;
}

void MultiImageHandler::SetTransmissionMode(TransmissionMode mode) {
  transmission_mode_ = mode;
  
  switch (mode) {
    case HTTP_MJPEG_STREAM:
      // åœæ­¢WebSocketæ¨¡å¼ï¼Œå¯åŠ¨HTTPæµæ¨¡å¼
      StopWebSocketMode();
      break;
      
    case WEBSOCKET_BATCH:
      // åœæ­¢HTTPæµæ¨¡å¼ï¼Œå¯åŠ¨WebSocketæ¨¡å¼
      StartWebSocketMode();
      break;
      
    case HYBRID_MODE:
      // åŒæ—¶æ”¯æŒä¸¤ç§æ¨¡å¼
      StartWebSocketMode();
      break;
  }
}

void MultiImageHandler::StartWebSocketMode() {
  if (!websocket_) {
    websocket_.reset(new WebSocketHandler("MultiImage"));
  }
  
  // å¯åŠ¨å¤šæ‘„åƒå¤´æ›´æ–°å™¨
  multi_camera_updater_->Start();
  
  AINFO << "Multi-image WebSocket mode started";
}

void MultiImageHandler::StopWebSocketMode() {
  if (multi_camera_updater_) {
    multi_camera_updater_->Stop();
  }
  
  AINFO << "Multi-image WebSocket mode stopped";
}

void MultiImageHandler::AddCameraChannel(const std::string& channel_name, 
                                       const std::string& camera_id) {
  // æ·»åŠ åˆ°å¤šæ‘„åƒå¤´æ›´æ–°å™¨
  multi_camera_updater_->AddCameraChannel(channel_name, camera_id);
  
  // åŒæ—¶æ·»åŠ åˆ°çˆ¶ç±»çš„å›¾åƒå¤„ç†ç®¡é“ï¼ˆå…¼å®¹æ€§ï¼‰
  // è¿™é‡Œå¯ä»¥è°ƒç”¨çˆ¶ç±»çš„ç›¸å…³æ–¹æ³•æˆ–ç›´æ¥å¤„ç†
  AINFO << "Added camera channel: " << channel_name << " (ID: " << camera_id << ")";
}

void MultiImageHandler::GetMultiCameraUpdate(std::string* multi_camera_data) {
  if (!multi_camera_updater_) {
    return;
  }
  
  // è·å–æœ€æ–°çš„å¤šæ‘„åƒå¤´æ•°æ®
  MultiCameraUpdate update;
  // è¿™é‡Œéœ€è¦ä»multi_camera_updater_è·å–æ•°æ®
  // multi_camera_updater_->GetLatestUpdate(&update);
  
  update.SerializeToString(multi_camera_data);
}

}  // namespace dreamview
}  // namespace apollo
```

## 3. **åœ¨Dreamviewä¸»ç¨‹åºä¸­é›†æˆ**

### 3.1 ä¿®æ”¹Dreamviewä¸»ç¨‹åº

```cpp
// modules/dreamview_plus/backend/dreamview.cc

// åœ¨Dreamviewç±»ä¸­æ·»åŠ æˆå‘˜å˜é‡
private:
  std::unique_ptr<MultiImageHandler> multi_image_handler_;  // æ›¿æ¢åŸæœ‰çš„image_

// åœ¨Init()æ–¹æ³•ä¸­åˆå§‹åŒ–
apollo::common::Status Dreamview::Init() {
  // ... ç°æœ‰ä»£ç  ...
  
  // æ›¿æ¢åŸæœ‰çš„image_åˆå§‹åŒ–
  // image_.reset(new ImageHandler());
  multi_image_handler_.reset(new MultiImageHandler());
  
  // é…ç½®ä¼ è¾“æ¨¡å¼
  multi_image_handler_->SetTransmissionMode(MultiImageHandler::WEBSOCKET_BATCH);
  
  // æ·»åŠ æ‘„åƒå¤´é€šé“
  multi_image_handler_->AddCameraChannel(
      "/apollo/sensor/camera/front_6mm/image", "front_6mm");
  multi_image_handler_->AddCameraChannel(
      "/apollo/sensor/camera/front_12mm/image", "front_12mm");
  multi_image_handler_->AddCameraChannel(
      "/apollo/sensor/camera/front_fisheye/image", "front_fisheye");
  multi_image_handler_->AddCameraChannel(
      "/apollo/sensor/camera/left_front/image", "left_front");
  multi_image_handler_->AddCameraChannel(
      "/apollo/sensor/camera/left_rear/image", "left_rear");
  multi_image_handler_->AddCameraChannel(
      "/apollo/sensor/camera/right_front/image", "right_front");
  multi_image_handler_->AddCameraChannel(
      "/apollo/sensor/camera/right_rear/image", "right_rear");
  
  // æ³¨å†ŒHTTPå’ŒWebSocketå¤„ç†å™¨
  server_->addHandler("/image", *multi_image_handler_);           // HTTP MJPEGæµ
  server_->addHandler("/multicamera", *multi_image_handler_);     // WebSocketæ‰¹é‡ä¼ è¾“
  server_->addWebSocketHandler("/multicamera", *websocket_);      // WebSocketç«¯ç‚¹
  
  return Status::OK();
}

// åœ¨Start()æ–¹æ³•ä¸­å¯åŠ¨
apollo::common::Status Dreamview::Start() {
  // ... ç°æœ‰ä»£ç  ...
  
  // å¯åŠ¨å¤šå›¾åƒå¤„ç†å™¨
  if (multi_image_handler_) {
    multi_image_handler_->StartWebSocketMode();
  }
  
  return Status::OK();
}

// åœ¨Stop()æ–¹æ³•ä¸­åœæ­¢
void Dreamview::Stop() {
  // ... ç°æœ‰ä»£ç  ...
  
  if (multi_image_handler_) {
    multi_image_handler_->StopWebSocketMode();
  }
}
```

## 4. **å‰ç«¯é›†æˆç°æœ‰Image Handler**

### 4.1 åˆ›å»ºå…¼å®¹æ€§é€‚é…å™¨

```typescript
// modules/dreamview_plus/frontend/packages/dreamview-core/src/services/image-handler-adapter.ts
import { Observable, Subject } from 'rxjs';

export interface ImageHandlerConfig {
  mode: 'http_mjpeg' | 'websocket_batch' | 'hybrid';
  endpoint: string;
  cameraIds: string[];
}

export class ImageHandlerAdapter {
  private config: ImageHandlerConfig;
  private httpMjpegConnections: Map<string, EventSource> = new Map();
  private websocketConnection: WebSocket | null = null;
  private dataSubject = new Subject<MultiCameraData>();
  
  constructor(config: ImageHandlerConfig) {
    this.config = config;
  }
  
  // å¯åŠ¨å›¾åƒä¼ è¾“
  start(): Observable<MultiCameraData> {
    switch (this.config.mode) {
      case 'http_mjpeg':
        this.startHttpMjpegMode();
        break;
      case 'websocket_batch':
        this.startWebSocketBatchMode();
        break;
      case 'hybrid':
        this.startHybridMode();
        break;
    }
    
    return this.dataSubject.asObservable();
  }
  
  // HTTP MJPEGæµæ¨¡å¼ï¼ˆå…¼å®¹ç°æœ‰å‰ç«¯ï¼‰
  private startHttpMjpegMode() {
    this.config.cameraIds.forEach(cameraId => {
      const eventSource = new EventSource(`${this.config.endpoint}/image?camera=${cameraId}`);
      
      eventSource.onmessage = (event) => {
        // å¤„ç†MJPEGæµæ•°æ®
        const imageData = this.parseMjpegData(event.data);
        this.dataSubject.next({
          frames: [{
            cameraId,
            imageData,
            timestamp: Date.now() / 1000,
            width: 0,
            height: 0,
            compressionRatio: 0,
            frameId: `frame_${Date.now()}`
          }],
          timestamp: Date.now() / 1000,
          frameCount: 1,
          kImageScale: 1.0
        });
      };
      
      this.httpMjpegConnections.set(cameraId, eventSource);
    });
  }
  
  // WebSocketæ‰¹é‡æ¨¡å¼
  private startWebSocketBatchMode() {
    this.websocketConnection = new WebSocket(`${this.config.endpoint}/multicamera`);
    this.websocketConnection.binaryType = 'arraybuffer';
    
    this.websocketConnection.onmessage = (event) => {
      // è§£æWebSocketæ•°æ®
      const data = new Uint8Array(event.data);
      const multiUpdate = MultiCameraUpdate.decode(data);
      
      // è½¬æ¢ä¸ºå‰ç«¯æ ¼å¼
      const frames: CameraFrame[] = (multiUpdate.frames || []).map(frame => ({
        cameraId: frame.cameraId || '',
        imageData: new Uint8Array(frame.imageData || []),
        timestamp: frame.timestamp || 0,
        width: frame.width || 0,
        height: frame.height || 0,
        compressionRatio: frame.compressionRatio || 0,
        frameId: frame.frameId || ''
      }));
      
      this.dataSubject.next({
        frames,
        timestamp: multiUpdate.timestamp || 0,
        frameCount: multiUpdate.frameCount || 0,
        kImageScale: multiUpdate.kImageScale || 1.0
      });
    };
  }
  
  // æ··åˆæ¨¡å¼
  private startHybridMode() {
    // åŒæ—¶å¯åŠ¨ä¸¤ç§æ¨¡å¼ï¼Œæ ¹æ®æ•°æ®å¯ç”¨æ€§é€‰æ‹©ä½¿ç”¨
    this.startHttpMjpegMode();
    this.startWebSocketBatchMode();
  }
  
  // åœæ­¢ä¼ è¾“
  stop() {
    // å…³é—­HTTPè¿æ¥
    this.httpMjpegConnections.forEach(connection => {
      connection.close();
    });
    this.httpMjpegConnections.clear();
    
    // å…³é—­WebSocketè¿æ¥
    if (this.websocketConnection) {
      this.websocketConnection.close();
      this.websocketConnection = null;
    }
  }
  
  private parseMjpegData(data: string): Uint8Array {
    // è§£æMJPEGæ•°æ®
    // è¿™é‡Œéœ€è¦å®ç°MJPEGæµçš„è§£æé€»è¾‘
    return new Uint8Array();
  }
}
```

### 4.2 å‰ç«¯ç»„ä»¶é€‚é…

```typescript
// modules/dreamview_plus/frontend/packages/dreamview-core/src/components/panels/MultiCameraView/index.tsx
import { ImageHandlerAdapter } from '../../services/image-handler-adapter';

function InternalMultiCameraView() {
  const [imageHandlerAdapter, setImageHandlerAdapter] = useState<ImageHandlerAdapter | null>(null);
  const [multiCameraData, setMultiCameraData] = useState<MultiCameraData | null>(null);
  
  useEffect(() => {
    // é…ç½®å›¾åƒå¤„ç†å™¨
    const config: ImageHandlerConfig = {
      mode: 'websocket_batch', // ä½¿ç”¨WebSocketæ‰¹é‡æ¨¡å¼
      endpoint: 'ws://localhost:8888',
      cameraIds: ['front_6mm', 'front_12mm', 'front_fisheye', 'left_front', 'left_rear', 'right_front', 'right_rear']
    };
    
    const adapter = new ImageHandlerAdapter(config);
    setImageHandlerAdapter(adapter);
    
    // å¯åŠ¨å›¾åƒä¼ è¾“
    const subscription = adapter.start().subscribe({
      next: (data: MultiCameraData) => {
        setMultiCameraData(data);
        renderCameraFrames(data);
      },
      error: (error) => {
        console.error('Image handler error:', error);
      }
    });
    
    return () => {
      subscription.unsubscribe();
      adapter.stop();
    };
  }, []);
  
  // æ¸²æŸ“æ‘„åƒå¤´å¸§ï¼ˆä¸ä¹‹å‰ç›¸åŒï¼‰
  const renderCameraFrames = useCallback((data: MultiCameraData) => {
    // ... æ¸²æŸ“é€»è¾‘ ...
  }, []);
  
  return (
    <div className={classes['multi-camera-container']}>
      {/* ä¼ è¾“æ¨¡å¼åˆ‡æ¢ */}
      <div className={classes['transmission-controls']}>
        <select 
          onChange={(e) => {
            // åˆ‡æ¢ä¼ è¾“æ¨¡å¼
            const newMode = e.target.value as 'http_mjpeg' | 'websocket_batch' | 'hybrid';
            imageHandlerAdapter?.setMode(newMode);
          }}
        >
          <option value="websocket_batch">WebSocketæ‰¹é‡ä¼ è¾“</option>
          <option value="http_mjpeg">HTTP MJPEGæµ</option>
          <option value="hybrid">æ··åˆæ¨¡å¼</option>
        </select>
      </div>
      
      {/* æ‘„åƒå¤´æ˜¾ç¤ºåŒºåŸŸ */}
      <div className={classes['main-camera-view']}>
        {/* æ¸²æŸ“é€»è¾‘ä¸ä¹‹å‰ç›¸åŒ */}
      </div>
    </div>
  );
}
```

## 5. **é…ç½®æ–‡ä»¶æ›´æ–°**

### 5.1 æ›´æ–°æ•°æ®å¤„ç†å™¨é…ç½®

```protobuf
# modules/dreamview_plus/conf/data_handler.conf ä¸­æ·»åŠ 
data_handler_info {
  key: "apollo.dreamview.MultiCameraUpdate",
  value {
    data_name: "multicamera",
    msg_type: "apollo.dreamview.MultiCameraUpdate",
    websocket_info {
      websocket_name: "multicamera",
      websocket_pipe: "/multicamera"
    },
    different_for_channels: false
  }
}

# ä¿æŒåŸæœ‰çš„cameraé…ç½®ä»¥æ”¯æŒå…¼å®¹æ€§
data_handler_info {
  key: "apollo.dreamview.CameraUpdate",
  value {
    data_name: "camera",
    msg_type: "apollo.dreamview.CameraUpdate",
    websocket_info {
      websocket_name: "camera",
      websocket_pipe: "/camera"
    },
    different_for_channels: true
  }
}
```

## 6. **æ€»ç»“**

é€šè¿‡è¿™ç§æ–¹å¼é›†æˆMultiCameraä¼ è¾“ä¸ç°æœ‰Image Handlerï¼š

### âœ… **å…¼å®¹æ€§ä¿æŒ**
- ä¿ç•™åŸæœ‰HTTP MJPEGæµåŠŸèƒ½
- æ”¯æŒç°æœ‰çš„å•æ‘„åƒå¤´æ˜¾ç¤º
- å‘åå…¼å®¹ç°æœ‰å‰ç«¯ä»£ç 

### âœ… **åŠŸèƒ½æ‰©å±•**
- æ–°å¢WebSocketæ‰¹é‡ä¼ è¾“
- æ”¯æŒå¤šæ‘„åƒå¤´åŒæ—¶ä¼ è¾“
- æä¾›æ··åˆä¼ è¾“æ¨¡å¼

### âœ… **æ€§èƒ½ä¼˜åŒ–**
- æ‰¹é‡ä¼ è¾“å‡å°‘ç½‘ç»œå¼€é”€
- å‹ç¼©ä¼ è¾“é™ä½å¸¦å®½éœ€æ±‚
- æ™ºèƒ½ä¼ è¾“æ¨¡å¼åˆ‡æ¢

### âœ… **çµæ´»æ€§**
- å¯æ ¹æ®éœ€æ±‚é€‰æ‹©ä¼ è¾“æ¨¡å¼
- æ”¯æŒè¿è¡Œæ—¶æ¨¡å¼åˆ‡æ¢
- ä¾¿äºè°ƒè¯•å’Œæµ‹è¯•

è¿™ç§é›†æˆæ–¹æ¡ˆæ—¢ä¿æŒäº†ä¸ç°æœ‰ç³»ç»Ÿçš„å…¼å®¹æ€§ï¼Œåˆæä¾›äº†æ–°çš„å¤šæ‘„åƒå¤´æ‰¹é‡ä¼ è¾“åŠŸèƒ½ï¼Œæ˜¯ä¸€ä¸ªæ¸è¿›å¼çš„å‡çº§æ–¹æ¡ˆã€‚

å½“ç„¶å¯ä»¥ï¼å®é™…ä¸Šï¼Œä¸ä½¿ç”¨image handleræ¥å®ç°multicameraä¼ è¾“å¯èƒ½æ›´ç®€æ´ã€æ›´é«˜æ•ˆã€‚è®©æˆ‘ä¸ºä½ å±•ç¤ºå‡ ç§ç‹¬ç«‹çš„å®ç°æ–¹æ¡ˆã€‚

## 1. **æ–¹æ¡ˆAï¼šç‹¬ç«‹çš„WebSocketå¤šæ‘„åƒå¤´ä¼ è¾“**

### 1.1 åˆ›å»ºç‹¬ç«‹çš„å¤šæ‘„åƒå¤´WebSocketå¤„ç†å™¨

```cpp
// modules/dreamview_plus/backend/multi_camera_websocket/multi_camera_websocket_handler.h
#pragma once

#include <memory>
#include <string>
#include <vector>
#include <map>
#include <mutex>
#include <atomic>
#include <opencv2/opencv.hpp>
#include "cyber/cyber.h"
#include "modules/dreamview/backend/common/handlers/websocket_handler.h"
#include "modules/dreamview_plus/proto/multi_camera_update.pb.h"
#include "modules/common_msgs/sensor_msgs/sensor_image.pb.h"

namespace apollo {
namespace dreamview {

struct CameraInfo {
  std::string channel_name;
  std::string camera_id;
  std::shared_ptr<cyber::Reader<apollo::drivers::Image>> reader;
  cv::Mat latest_image;
  double last_timestamp;
  std::mutex image_mutex;
  bool is_active;
  
  CameraInfo(const std::string& ch_name, const std::string& cam_id)
      : channel_name(ch_name), camera_id(cam_id), last_timestamp(0.0), is_active(false) {}
};

class MultiCameraWebSocketHandler : public WebSocketHandler {
public:
  explicit MultiCameraWebSocketHandler(const std::string& name);
  ~MultiCameraWebSocketHandler() = default;
  
  // å¯åŠ¨/åœæ­¢
  void Start();
  void Stop();
  
  // æ‘„åƒå¤´ç®¡ç†
  void AddCamera(const std::string& channel_name, const std::string& camera_id);
  void RemoveCamera(const std::string& camera_id);
  void EnableCamera(const std::string& camera_id, bool enable = true);
  
  // ä¼ è¾“æ§åˆ¶
  void SetTransmissionRate(double fps);  // è®¾ç½®ä¼ è¾“å¸§ç‡
  void SetCompressionQuality(int quality);  // è®¾ç½®å‹ç¼©è´¨é‡
  void SetMaxBandwidth(double mbps);  // è®¾ç½®æœ€å¤§å¸¦å®½
  
  // WebSocketæ¶ˆæ¯å¤„ç†
  void RegisterMessageHandlers() override;

private:
  std::unique_ptr<cyber::Node> node_;
  std::map<std::string, std::unique_ptr<CameraInfo>> cameras_;
  std::mutex cameras_mutex_;
  
  // ä¼ è¾“æ§åˆ¶
  std::atomic<double> transmission_rate_;  // ä¼ è¾“å¸§ç‡
  std::atomic<int> compression_quality_;   // å‹ç¼©è´¨é‡
  std::atomic<double> max_bandwidth_;      // æœ€å¤§å¸¦å®½
  std::atomic<bool> is_running_;
  
  // å®šæ—¶å™¨
  std::unique_ptr<cyber::Timer> transmission_timer_;
  
  // å›¾åƒå¤„ç†
  void OnCameraImage(const std::shared_ptr<apollo::drivers::Image>& image, 
                     const std::string& camera_id);
  std::vector<uint8_t> CompressImage(const cv::Mat& image);
  void PublishMultiCameraData();
  
  // å¸¦å®½æ§åˆ¶
  class BandwidthController {
  private:
    std::deque<std::pair<double, double>> bandwidth_history_;  // timestamp, size_kb
    double max_bandwidth_mbps_;
    
  public:
    BandwidthController(double max_bandwidth_mbps) 
        : max_bandwidth_mbps_(max_bandwidth_mbps) {}
    
    bool CanTransmit(double size_kb);
    void RecordTransmission(double timestamp, double size_kb);
    double GetCurrentBandwidth();
  };
  
  std::unique_ptr<BandwidthController> bandwidth_controller_;
};

}  // namespace dreamview
}  // namespace apollo
```

### 1.2 å®ç°ç‹¬ç«‹çš„å¤šæ‘„åƒå¤´WebSocketå¤„ç†å™¨

```cpp
// modules/dreamview_plus/backend/multi_camera_websocket/multi_camera_websocket_handler.cc
#include "modules/dreamview_plus/backend/multi_camera_websocket/multi_camera_websocket_handler.h"

namespace apollo {
namespace dreamview {

MultiCameraWebSocketHandler::MultiCameraWebSocketHandler(const std::string& name)
    : WebSocketHandler(name),
      node_(cyber::CreateNode("multi_camera_websocket")),
      transmission_rate_(10.0),  // é»˜è®¤10fps
      compression_quality_(75),  // é»˜è®¤75%è´¨é‡
      max_bandwidth_(2.0),       // é»˜è®¤2MB/s
      is_running_(false) {
  
  bandwidth_controller_.reset(new BandwidthController(max_bandwidth_.load()));
}

void MultiCameraWebSocketHandler::Start() {
  if (is_running_.exchange(true)) {
    return;  // å·²ç»åœ¨è¿è¡Œ
  }
  
  // å¯åŠ¨ä¼ è¾“å®šæ—¶å™¨
  double interval_ms = 1000.0 / transmission_rate_.load();
  transmission_timer_.reset(new cyber::Timer(
      interval_ms,
      [this]() { this->PublishMultiCameraData(); },
      false));
  transmission_timer_->Start();
  
  AINFO << "MultiCameraWebSocketHandler started with " 
        << transmission_rate_.load() << " fps";
}

void MultiCameraWebSocketHandler::Stop() {
  if (!is_running_.exchange(false)) {
    return;  // å·²ç»åœæ­¢
  }
  
  if (transmission_timer_) {
    transmission_timer_->Stop();
    transmission_timer_.reset();
  }
  
  // åœæ­¢æ‰€æœ‰æ‘„åƒå¤´
  std::lock_guard<std::mutex> lock(cameras_mutex_);
  for (auto& [camera_id, camera_info] : cameras_) {
    camera_info->is_active = false;
  }
  
  AINFO << "MultiCameraWebSocketHandler stopped";
}

void MultiCameraWebSocketHandler::AddCamera(const std::string& channel_name, 
                                           const std::string& camera_id) {
  std::lock_guard<std::mutex> lock(cameras_mutex_);
  
  auto camera_info = std::make_unique<CameraInfo>(channel_name, camera_id);
  camera_info->reader = node_->CreateReader<apollo::drivers::Image>(
      channel_name,
      [this, camera_id](const std::shared_ptr<apollo::drivers::Image>& image) {
        OnCameraImage(image, camera_id);
      });
  
  cameras_[camera_id] = std::move(camera_info);
  
  AINFO << "Added camera: " << camera_id << " (channel: " << channel_name << ")";
}

void MultiCameraWebSocketHandler::RemoveCamera(const std::string& camera_id) {
  std::lock_guard<std::mutex> lock(cameras_mutex_);
  
  auto it = cameras_.find(camera_id);
  if (it != cameras_.end()) {
    it->second->is_active = false;
    cameras_.erase(it);
    AINFO << "Removed camera: " << camera_id;
  }
}

void MultiCameraWebSocketHandler::SetTransmissionRate(double fps) {
  transmission_rate_.store(fps);
  
  // é‡å¯å®šæ—¶å™¨ä»¥åº”ç”¨æ–°çš„å¸§ç‡
  if (is_running_.load() && transmission_timer_) {
    transmission_timer_->Stop();
    double interval_ms = 1000.0 / fps;
    transmission_timer_.reset(new cyber::Timer(
        interval_ms,
        [this]() { this->PublishMultiCameraData(); },
        false));
    transmission_timer_->Start();
  }
  
  AINFO << "Transmission rate set to: " << fps << " fps";
}

void MultiCameraWebSocketHandler::OnCameraImage(const std::shared_ptr<apollo::drivers::Image>& image,
                                               const std::string& camera_id) {
  if (!image || image->data().empty()) {
    return;
  }
  
  std::lock_guard<std::mutex> lock(cameras_mutex_);
  auto it = cameras_.find(camera_id);
  if (it == cameras_.end() || !it->second->is_active) {
    return;
  }
  
  auto& camera_info = it->second;
  std::lock_guard<std::mutex> image_lock(camera_info->image_mutex);
  
  // è½¬æ¢å›¾åƒæ ¼å¼
  cv::Mat cv_image(image->height(), image->width(), CV_8UC3,
                   const_cast<char*>(image->data().data()), image->step());
  cv::Mat bgr_image;
  cv::cvtColor(cv_image, bgr_image, cv::COLOR_RGB2BGR);
  
  // æ›´æ–°æœ€æ–°å›¾åƒ
  camera_info->latest_image = bgr_image.clone();
  camera_info->last_timestamp = image->header().timestamp_sec();
}

void MultiCameraWebSocketHandler::PublishMultiCameraData() {
  if (!is_running_.load()) {
    return;
  }
  
  MultiCameraUpdate multi_update;
  multi_update.set_timestamp(cyber::Time::Now().ToSecond());
  multi_update.set_k_image_scale(0.4);  // 40%ç¼©æ”¾
  
  std::vector<CameraFrame> frames;
  double total_size_kb = 0;
  
  // æ”¶é›†æ‰€æœ‰æ‘„åƒå¤´çš„å›¾åƒæ•°æ®
  {
    std::lock_guard<std::mutex> lock(cameras_mutex_);
    
    for (auto& [camera_id, camera_info] : cameras_) {
      if (!camera_info->is_active) {
        continue;
      }
      
      std::lock_guard<std::mutex> image_lock(camera_info->image_mutex);
      if (camera_info->latest_image.empty()) {
        continue;
      }
      
      // å‹ç¼©å›¾åƒ
      auto compressed_data = CompressImage(camera_info->latest_image);
      if (compressed_data.empty()) {
        continue;
      }
      
      // æ£€æŸ¥å¸¦å®½é™åˆ¶
      double size_kb = compressed_data.size() / 1024.0;
      if (!bandwidth_controller_->CanTransmit(total_size_kb + size_kb)) {
        AINFO << "Bandwidth limit reached, skipping camera: " << camera_id;
        continue;
      }
      
      // åˆ›å»ºå¸§æ•°æ®
      CameraFrame* frame = multi_update.add_frames();
      frame->set_camera_id(camera_id);
      frame->set_image_data(compressed_data.data(), compressed_data.size());
      frame->set_timestamp(camera_info->last_timestamp);
      frame->set_width(camera_info->latest_image.cols);
      frame->set_height(camera_info->latest_image.rows);
      frame->set_compression_ratio(
          static_cast<double>(compressed_data.size()) / 
          (camera_info->latest_image.total() * camera_info->latest_image.elemSize()));
      frame->set_frame_id("frame_" + std::to_string(static_cast<int>(multi_update.timestamp() * 1000)));
      
      total_size_kb += size_kb;
    }
  }
  
  if (multi_update.frames_size() > 0) {
    multi_update.set_frame_count(multi_update.frames_size());
    
    // åºåˆ—åŒ–å¹¶å‘é€
    std::string serialized_data;
    multi_update.SerializeToString(&serialized_data);
    
    // é€šè¿‡WebSocketå¹¿æ’­
    BroadcastBinaryData(serialized_data);
    
    // è®°å½•å¸¦å®½ä½¿ç”¨
    bandwidth_controller_->RecordTransmission(multi_update.timestamp(), total_size_kb);
    
    AINFO << "Published multi-camera data: " << multi_update.frames_size() 
          << " frames, " << total_size_kb << "KB, " 
          << bandwidth_controller_->GetCurrentBandwidth() << "KB/s";
  }
}

std::vector<uint8_t> MultiCameraWebSocketHandler::CompressImage(const cv::Mat& image) {
  if (image.empty()) {
    return {};
  }
  
  // å›¾åƒç¼©æ”¾
  cv::Mat resized_image;
  int target_width = static_cast<int>(image.cols * 0.4);   // 40%ç¼©æ”¾
  int target_height = static_cast<int>(image.rows * 0.4);
  cv::resize(image, resized_image, cv::Size(target_width, target_height), 
             0, 0, cv::INTER_AREA);
  
  // JPEGå‹ç¼©
  std::vector<int> compression_params = {
    cv::IMWRITE_JPEG_QUALITY, compression_quality_.load(),
    cv::IMWRITE_JPEG_OPTIMIZE, 1,
    cv::IMWRITE_JPEG_PROGRESSIVE, 1
  };
  
  std::vector<uint8_t> compressed_data;
  cv::imencode(".jpg", resized_image, compressed_data, compression_params);
  
  return compressed_data;
}

// å¸¦å®½æ§åˆ¶å™¨å®ç°
bool MultiCameraWebSocketHandler::BandwidthController::CanTransmit(double size_kb) {
  double current_bandwidth = GetCurrentBandwidth();
  double size_mbps = size_kb / 1024.0;
  return (current_bandwidth + size_mbps) <= max_bandwidth_mbps_;
}

void MultiCameraWebSocketHandler::BandwidthController::RecordTransmission(double timestamp, double size_kb) {
  bandwidth_history_.push_back({timestamp, size_kb});
  
  // æ¸…ç†5ç§’å‰çš„å†å²æ•°æ®
  while (!bandwidth_history_.empty() && 
         timestamp - bandwidth_history_.front().first > 5.0) {
    bandwidth_history_.pop_front();
  }
}

double MultiCameraWebSocketHandler::BandwidthController::GetCurrentBandwidth() {
  if (bandwidth_history_.size() < 2) {
    return 0.0;
  }
  
  double total_size = 0.0;
  double time_span = bandwidth_history_.back().first - bandwidth_history_.front().first;
  
  for (const auto& [timestamp, size] : bandwidth_history_) {
    total_size += size;
  }
  
  return total_size / time_span / 1024.0;  // MB/s
}

}  // namespace dreamview
}  // namespace apollo
```

## 2. **æ–¹æ¡ˆBï¼šåŸºäºHTTP REST APIçš„ä¼ è¾“**

### 2.1 åˆ›å»ºHTTP APIå¤„ç†å™¨

```cpp
// modules/dreamview_plus/backend/multi_camera_api/multi_camera_api_handler.h
#pragma once

#include "modules/dreamview/backend/common/handlers/websocket_handler.h"
#include "modules/dreamview_plus/backend/multi_camera_websocket/multi_camera_websocket_handler.h"

namespace apollo {
namespace dreamview {

class MultiCameraApiHandler : public CivetHandler {
public:
  explicit MultiCameraApiHandler(std::shared_ptr<MultiCameraWebSocketHandler> ws_handler);
  
  // HTTPè¯·æ±‚å¤„ç†
  bool handleGet(CivetServer *server, struct mg_connection *conn) override;
  bool handlePost(CivetServer *server, struct mg_connection *conn) override;
  bool handlePut(CivetServer *server, struct mg_connection *conn) override;
  bool handleDelete(CivetServer *server, struct mg_connection *conn) override;

private:
  std::shared_ptr<MultiCameraWebSocketHandler> ws_handler_;
  
  // APIç«¯ç‚¹å¤„ç†
  bool HandleGetCameras(CivetServer *server, struct mg_connection *conn);
  bool HandleGetCameraData(CivetServer *server, struct mg_connection *conn);
  bool HandleUpdateSettings(CivetServer *server, struct mg_connection *conn);
  bool HandleAddCamera(CivetServer *server, struct mg_connection *conn);
  bool HandleRemoveCamera(CivetServer *server, struct mg_connection *conn);
  
  // å·¥å…·æ–¹æ³•
  std::string GetRequestPath(struct mg_connection *conn);
  std::string GetQueryParam(struct mg_connection *conn, const std::string& param);
  void SendJsonResponse(struct mg_connection *conn, const std::string& json);
  void SendErrorResponse(struct mg_connection *conn, int code, const std::string& message);
};

}  // namespace dreamview
}  // namespace apollo
```

### 2.2 å®ç°HTTP APIå¤„ç†å™¨

```cpp
// modules/dreamview_plus/backend/multi_camera_api/multi_camera_api_handler.cc
#include "modules/dreamview_plus/backend/multi_camera_api/multi_camera_api_handler.h"
#include "modules/common/util/json_util.h"

namespace apollo {
namespace dreamview {

MultiCameraApiHandler::MultiCameraApiHandler(std::shared_ptr<MultiCameraWebSocketHandler> ws_handler)
    : ws_handler_(ws_handler) {}

bool MultiCameraApiHandler::handleGet(CivetServer *server, struct mg_connection *conn) {
  std::string path = GetRequestPath(conn);
  
  if (path == "/api/multicamera/cameras") {
    return HandleGetCameras(server, conn);
  } else if (path.find("/api/multicamera/camera/") == 0) {
    return HandleGetCameraData(server, conn);
  } else {
    SendErrorResponse(conn, 404, "Not Found");
    return false;
  }
}

bool MultiCameraApiHandler::handlePost(CivetServer *server, struct mg_connection *conn) {
  std::string path = GetRequestPath(conn);
  
  if (path == "/api/multicamera/camera") {
    return HandleAddCamera(server, conn);
  } else if (path == "/api/multicamera/settings") {
    return HandleUpdateSettings(server, conn);
  } else {
    SendErrorResponse(conn, 404, "Not Found");
    return false;
  }
}

bool MultiCameraApiHandler::handleDelete(CivetServer *server, struct mg_connection *conn) {
  std::string path = GetRequestPath(conn);
  
  if (path.find("/api/multicamera/camera/") == 0) {
    return HandleRemoveCamera(server, conn);
  } else {
    SendErrorResponse(conn, 404, "Not Found");
    return false;
  }
}

bool MultiCameraApiHandler::HandleGetCameras(CivetServer *server, struct mg_connection *conn) {
  // è¿”å›æ‰€æœ‰æ‘„åƒå¤´åˆ—è¡¨
  nlohmann::json response;
  response["cameras"] = nlohmann::json::array();
  
  // è¿™é‡Œéœ€è¦ä»ws_handler_è·å–æ‘„åƒå¤´åˆ—è¡¨
  // ç”±äºCameraInfoæ˜¯privateçš„ï¼Œéœ€è¦é€šè¿‡å…¬å…±æ¥å£è·å–
  
  SendJsonResponse(conn, response.dump());
  return true;
}

bool MultiCameraApiHandler::HandleGetCameraData(CivetServer *server, struct mg_connection *conn) {
  std::string camera_id = GetQueryParam(conn, "id");
  if (camera_id.empty()) {
    SendErrorResponse(conn, 400, "Missing camera ID");
    return false;
  }
  
  // è·å–æŒ‡å®šæ‘„åƒå¤´çš„å½“å‰å›¾åƒæ•°æ®
  // è¿™é‡Œéœ€è¦å®ç°è·å–å•æ‘„åƒå¤´æ•°æ®çš„é€»è¾‘
  
  nlohmann::json response;
  response["camera_id"] = camera_id;
  response["timestamp"] = cyber::Time::Now().ToSecond();
  // response["image_data"] = base64_encoded_image_data;
  
  SendJsonResponse(conn, response.dump());
  return true;
}

bool MultiCameraApiHandler::HandleUpdateSettings(CivetServer *server, struct mg_connection *conn) {
  // è¯»å–POSTæ•°æ®
  char post_data[4096];
  int post_data_len = mg_read(conn, post_data, sizeof(post_data) - 1);
  post_data[post_data_len] = '\0';
  
  try {
    nlohmann::json settings = nlohmann::json::parse(post_data);
    
    // æ›´æ–°ä¼ è¾“è®¾ç½®
    if (settings.contains("transmission_rate")) {
      double fps = settings["transmission_rate"];
      ws_handler_->SetTransmissionRate(fps);
    }
    
    if (settings.contains("compression_quality")) {
      int quality = settings["compression_quality"];
      ws_handler_->SetCompressionQuality(quality);
    }
    
    if (settings.contains("max_bandwidth")) {
      double bandwidth = settings["max_bandwidth"];
      ws_handler_->SetMaxBandwidth(bandwidth);
    }
    
    nlohmann::json response;
    response["status"] = "success";
    response["message"] = "Settings updated successfully";
    
    SendJsonResponse(conn, response.dump());
    return true;
    
  } catch (const std::exception& e) {
    SendErrorResponse(conn, 400, "Invalid JSON: " + std::string(e.what()));
    return false;
  }
}

bool MultiCameraApiHandler::HandleAddCamera(CivetServer *server, struct mg_connection *conn) {
  char post_data[1024];
  int post_data_len = mg_read(conn, post_data, sizeof(post_data) - 1);
  post_data[post_data_len] = '\0';
  
  try {
    nlohmann::json camera_config = nlohmann::json::parse(post_data);
    
    std::string channel_name = camera_config["channel_name"];
    std::string camera_id = camera_config["camera_id"];
    
    ws_handler_->AddCamera(channel_name, camera_id);
    
    nlohmann::json response;
    response["status"] = "success";
    response["message"] = "Camera added successfully";
    response["camera_id"] = camera_id;
    
    SendJsonResponse(conn, response.dump());
    return true;
    
  } catch (const std::exception& e) {
    SendErrorResponse(conn, 400, "Invalid camera config: " + std::string(e.what()));
    return false;
  }
}

bool MultiCameraApiHandler::HandleRemoveCamera(CivetServer *server, struct mg_connection *conn) {
  std::string path = GetRequestPath(conn);
  std::string camera_id = path.substr(path.find_last_of('/') + 1);
  
  if (camera_id.empty()) {
    SendErrorResponse(conn, 400, "Missing camera ID");
    return false;
  }
  
  ws_handler_->RemoveCamera(camera_id);
  
  nlohmann::json response;
  response["status"] = "success";
  response["message"] = "Camera removed successfully";
  response["camera_id"] = camera_id;
  
  SendJsonResponse(conn, response.dump());
  return true;
}

// å·¥å…·æ–¹æ³•å®ç°
std::string MultiCameraApiHandler::GetRequestPath(struct mg_connection *conn) {
  const struct mg_request_info *request_info = mg_get_request_info(conn);
  return std::string(request_info->request_uri);
}

std::string MultiCameraApiHandler::GetQueryParam(struct mg_connection *conn, const std::string& param) {
  const struct mg_request_info *request_info = mg_get_request_info(conn);
  return std::string(mg_get_var(request_info->query_string, param.c_str()));
}

void MultiCameraApiHandler::SendJsonResponse(struct mg_connection *conn, const std::string& json) {
  mg_printf(conn,
            "HTTP/1.1 200 OK\r\n"
            "Content-Type: application/json\r\n"
            "Content-Length: %zu\r\n"
            "Access-Control-Allow-Origin: *\r\n"
            "Access-Control-Allow-Methods: GET, POST, PUT, DELETE\r\n"
            "Access-Control-Allow-Headers: Content-Type\r\n"
            "\r\n"
            "%s",
            json.length(), json.c_str());
}

void MultiCameraApiHandler::SendErrorResponse(struct mg_connection *conn, int code, const std::string& message) {
  nlohmann::json error_response;
  error_response["error"] = message;
  error_response["code"] = code;
  
  mg_printf(conn,
            "HTTP/1.1 %d Error\r\n"
            "Content-Type: application/json\r\n"
            "Content-Length: %zu\r\n"
            "\r\n"
            "%s",
            code, error_response.dump().length(), error_response.dump().c_str());
}

}  // namespace dreamview
}  // namespace apollo
```

## 3. **æ–¹æ¡ˆCï¼šåŸºäºgRPCçš„ä¼ è¾“**

### 3.1 å®šä¹‰gRPCæœåŠ¡

```protobuf
// modules/dreamview_plus/proto/multi_camera_service.proto
syntax = "proto3";

package apollo.dreamview;

import "modules/dreamview_plus/proto/multi_camera_update.proto";

service MultiCameraService {
  // æµå¼ä¼ è¾“å¤šæ‘„åƒå¤´æ•°æ®
  rpc StreamMultiCameraData(StreamRequest) returns (stream MultiCameraUpdate);
  
  // è·å–å•å¼ å›¾åƒ
  rpc GetCameraImage(ImageRequest) returns (ImageResponse);
  
  // ç®¡ç†æ‘„åƒå¤´
  rpc AddCamera(CameraConfig) returns (StatusResponse);
  rpc RemoveCamera(CameraRequest) returns (StatusResponse);
  rpc ListCameras(Empty) returns (CameraListResponse);
  
  // æ§åˆ¶ä¼ è¾“
  rpc UpdateSettings(TransmissionSettings) returns (StatusResponse);
}

message StreamRequest {
  repeated string camera_ids = 1;
  double max_fps = 2;
  double max_bandwidth_mbps = 3;
}

message ImageRequest {
  string camera_id = 1;
  int32 width = 2;
  int32 height = 3;
  int32 quality = 4;
}

message ImageResponse {
  bytes image_data = 1;
  string camera_id = 2;
  double timestamp = 3;
  int32 width = 4;
  int32 height = 5;
}

message CameraConfig {
  string camera_id = 1;
  string channel_name = 2;
  bool enabled = 3;
}

message CameraRequest {
  string camera_id = 1;
}

message CameraListResponse {
  repeated CameraInfo cameras = 1;
}

message CameraInfo {
  string camera_id = 1;
  string channel_name = 2;
  bool is_active = 3;
  double last_update_time = 4;
}

message TransmissionSettings {
  double fps = 1;
  int32 compression_quality = 2;
  double max_bandwidth_mbps = 3;
}

message StatusResponse {
  bool success = 1;
  string message = 2;
}

message Empty {}
```

### 3.2 å®ç°gRPCæœåŠ¡

```cpp
// modules/dreamview_plus/backend/multi_camera_grpc/multi_camera_grpc_service.h
#pragma once

#include <memory>
#include <grpcpp/grpcpp.h>
#include "modules/dreamview_plus/proto/multi_camera_service.grpc.pb.h"
#include "modules/dreamview_plus/backend/multi_camera_websocket/multi_camera_websocket_handler.h"

namespace apollo {
namespace dreamview {

class MultiCameraGrpcService final : public MultiCameraService::Service {
public:
  explicit MultiCameraGrpcService(std::shared_ptr<MultiCameraWebSocketHandler> ws_handler);
  
  // gRPCæœåŠ¡å®ç°
  grpc::Status StreamMultiCameraData(
      grpc::ServerContext* context,
      const StreamRequest* request,
      grpc::ServerWriter<MultiCameraUpdate>* writer) override;
  
  grpc::Status GetCameraImage(
      grpc::ServerContext* context,
      const ImageRequest* request,
      ImageResponse* response) override;
  
  grpc::Status AddCamera(
      grpc::ServerContext* context,
      const CameraConfig* request,
      StatusResponse* response) override;
  
  grpc::Status RemoveCamera(
      grpc::ServerContext* context,
      const CameraRequest* request,
      StatusResponse* response) override;
  
  grpc::Status ListCameras(
      grpc::ServerContext* context,
      const Empty* request,
      CameraListResponse* response) override;
  
  grpc::Status UpdateSettings(
      grpc::ServerContext* context,
      const TransmissionSettings* request,
      StatusResponse* response) override;

private:
  std::shared_ptr<MultiCameraWebSocketHandler> ws_handler_;
  std::atomic<bool> is_streaming_;
};

}  // namespace dreamview
}  // namespace apollo
```

## 4. **åœ¨Dreamviewä¸»ç¨‹åºä¸­é›†æˆ**

### 4.1 ä¿®æ”¹Dreamviewä¸»ç¨‹åº

```cpp
// modules/dreamview_plus/backend/dreamview.cc

// åœ¨Dreamviewç±»ä¸­æ·»åŠ æˆå‘˜å˜é‡
private:
  std::shared_ptr<MultiCameraWebSocketHandler> multi_camera_ws_;
  std::unique_ptr<MultiCameraApiHandler> multi_camera_api_;
  std::unique_ptr<grpc::Server> grpc_server_;

// åœ¨Init()æ–¹æ³•ä¸­åˆå§‹åŒ–
apollo::common::Status Dreamview::Init() {
  // ... ç°æœ‰ä»£ç  ...
  
  // åˆ›å»ºå¤šæ‘„åƒå¤´WebSocketå¤„ç†å™¨
  multi_camera_ws_ = std::make_shared<MultiCameraWebSocketHandler>("MultiCamera");
  
  // æ·»åŠ æ‘„åƒå¤´
  multi_camera_ws_->AddCamera("/apollo/sensor/camera/front_6mm/image", "front_6mm");
  multi_camera_ws_->AddCamera("/apollo/sensor/camera/front_12mm/image", "front_12mm");
  multi_camera_ws_->AddCamera("/apollo/sensor/camera/front_fisheye/image", "front_fisheye");
  multi_camera_ws_->AddCamera("/apollo/sensor/camera/left_front/image", "left_front");
  multi_camera_ws_->AddCamera("/apollo/sensor/camera/left_rear/image", "left_rear");
  multi_camera_ws_->AddCamera("/apollo/sensor/camera/right_front/image", "right_front");
  multi_camera_ws_->AddCamera("/apollo/sensor/camera/right_rear/image", "right_rear");
  
  // è®¾ç½®ä¼ è¾“å‚æ•°
  multi_camera_ws_->SetTransmissionRate(10.0);  // 10fps
  multi_camera_ws_->SetCompressionQuality(75);  // 75%è´¨é‡
  multi_camera_ws_->SetMaxBandwidth(2.0);       // 2MB/s
  
  // æ³¨å†ŒWebSocketå¤„ç†å™¨
  server_->addWebSocketHandler("/multicamera", *multi_camera_ws_);
  
  // åˆ›å»ºHTTP APIå¤„ç†å™¨
  multi_camera_api_ = std::make_unique<MultiCameraApiHandler>(multi_camera_ws_);
  server_->addHandler("/api/multicamera", *multi_camera_api_);
  
  // å¯åŠ¨gRPCæœåŠ¡ï¼ˆå¯é€‰ï¼‰
  StartGrpcService();
  
  return Status::OK();
}

// åœ¨Start()æ–¹æ³•ä¸­å¯åŠ¨
apollo::common::Status Dreamview::Start() {
  // ... ç°æœ‰ä»£ç  ...
  
  // å¯åŠ¨å¤šæ‘„åƒå¤´ä¼ è¾“
  multi_camera_ws_->Start();
  
  return Status::OK();
}

// åœ¨Stop()æ–¹æ³•ä¸­åœæ­¢
void Dreamview::Stop() {
  // ... ç°æœ‰ä»£ç  ...
  
  // åœæ­¢å¤šæ‘„åƒå¤´ä¼ è¾“
  multi_camera_ws_->Stop();
  
  // åœæ­¢gRPCæœåŠ¡
  if (grpc_server_) {
    grpc_server_->Shutdown();
  }
}

private:
void Dreamview::StartGrpcService() {
  std::string server_address("0.0.0.0:50051");
  
  auto grpc_service = std::make_unique<MultiCameraGrpcService>(multi_camera_ws_);
  
  grpc::ServerBuilder builder;
  builder.AddListeningPort(server_address, grpc::InsecureServerCredentials());
  builder.RegisterService(grpc_service.get());
  
  grpc_server_ = builder.BuildAndStart();
  
  AINFO << "gRPC MultiCamera service listening on " << server_address;
}
```

## 5. **å‰ç«¯ç‹¬ç«‹å®ç°**

### 5.1 åˆ›å»ºç‹¬ç«‹çš„å‰ç«¯æœåŠ¡

```typescript
// modules/dreamview_plus/frontend/packages/dreamview-core/src/services/independent-multi-camera.service.ts
import { Observable, Subject, interval } from 'rxjs';
import { map, filter, switchMap } from 'rxjs/operators';

export interface IndependentMultiCameraConfig {
  websocketUrl: string;
  apiUrl: string;
  grpcUrl?: string;
  cameraIds: string[];
  transmissionRate: number;
  maxBandwidth: number;
}

export class IndependentMultiCameraService {
  private config: IndependentMultiCameraConfig;
  private websocket: WebSocket | null = null;
  private dataSubject = new Subject<MultiCameraData>();
  private isConnected = false;
  
  constructor(config: IndependentMultiCameraConfig) {
    this.config = config;
  }
  
  // WebSocketè¿æ¥
  connectWebSocket(): Observable<MultiCameraData> {
    if (this.websocket) {
      this.websocket.close();
    }
    
    this.websocket = new WebSocket(this.config.websocketUrl);
    this.websocket.binaryType = 'arraybuffer';
    
    this.websocket.onopen = () => {
      this.isConnected = true;
      console.log('MultiCamera WebSocket connected');
    };
    
    this.websocket.onmessage = (event) => {
      try {
        const data = new Uint8Array(event.data);
        const multiUpdate = MultiCameraUpdate.decode(data);
        
        const frames: CameraFrame[] = (multiUpdate.frames || []).map(frame => ({
          cameraId: frame.cameraId || '',
          imageData: new Uint8Array(frame.imageData || []),
          timestamp: frame.timestamp || 0,
          width: frame.width || 0,
          height: frame.height || 0,
          compressionRatio: frame.compressionRatio || 0,
          frameId: frame.frameId || ''
        }));
        
        this.dataSubject.next({
          frames,
          timestamp: multiUpdate.timestamp || 0,
          frameCount: multiUpdate.frameCount || 0,
          kImageScale: multiUpdate.kImageScale || 1.0
        });
      } catch (error) {
        console.error('Failed to parse WebSocket data:', error);
      }
    };
    
    this.websocket.onclose = () => {
      this.isConnected = false;
      console.log('MultiCamera WebSocket disconnected');
    };
    
    this.websocket.onerror = (error) => {
      console.error('MultiCamera WebSocket error:', error);
    };
    
    return this.dataSubject.asObservable();
  }
  
  // HTTP APIè°ƒç”¨
  async updateSettings(settings: {
    fps?: number;
    quality?: number;
    maxBandwidth?: number;
  }): Promise<void> {
    const response = await fetch(`${this.config.apiUrl}/settings`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(settings)
    });
    
    if (!response.ok) {
      throw new Error(`Failed to update settings: ${response.statusText}`);
    }
  }
  
  async addCamera(channelName: string, cameraId: string): Promise<void> {
    const response = await fetch(`${this.config.apiUrl}/camera`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        channel_name: channelName,
        camera_id: cameraId
      })
    });
    
    if (!response.ok) {
      throw new Error(`Failed to add camera: ${response.statusText}`);
    }
  }
  
  async removeCamera(cameraId: string): Promise<void> {
    const response = await fetch(`${this.config.apiUrl}/camera/${cameraId}`, {
      method: 'DELETE'
    });
    
    if (!response.ok) {
      throw new Error(`Failed to remove camera: ${response.statusText}`);
    }
  }
  
  async getCameraList(): Promise<CameraInfo[]> {
    const response = await fetch(`${this.config.apiUrl}/cameras`);
    
    if (!response.ok) {
      throw new Error(`Failed to get camera list: ${response.statusText}`);
    }
    
    const data = await response.json();
    return data.cameras;
  }
  
  // æ–­å¼€è¿æ¥
  disconnect() {
    if (this.websocket) {
      this.websocket.close();
      this.websocket = null;
    }
    this.isConnected = false;
  }
  
  // è·å–è¿æ¥çŠ¶æ€
  getConnectionStatus(): boolean {
    return this.isConnected;
  }
}

// ä½¿ç”¨ç¤ºä¾‹
const multiCameraService = new IndependentMultiCameraService({
  websocketUrl: 'ws://localhost:8888/multicamera',
  apiUrl: 'http://localhost:8888/api/multicamera',
  cameraIds: ['front_6mm', 'front_12mm', 'front_fisheye'],
  transmissionRate: 10,
  maxBandwidth: 2.0
});

// è¿æ¥å¹¶è®¢é˜…æ•°æ®
const subscription = multiCameraService.connectWebSocket().subscribe({
  next: (data) => {
    console.log('Received multi-camera data:', data);
    // å¤„ç†æ•°æ®...
  },
  error: (error) => {
    console.error('Multi-camera service error:', error);
  }
});
```

## 6. **æ€»ç»“**

ä¸ä½¿ç”¨Image Handlerçš„ç‹¬ç«‹å®ç°æ–¹æ¡ˆæœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š

### âœ… **æ¶æ„æ¸…æ™°**
- ä¸“é—¨ä¸ºå¤šæ‘„åƒå¤´è®¾è®¡ï¼Œæ²¡æœ‰å†å²åŒ…è¢±
- æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•
- ç‹¬ç«‹çš„ä¼ è¾“åè®®ï¼Œä¸ä¾èµ–ç°æœ‰Image Handler

### âœ… **æ€§èƒ½ä¼˜åŒ–**
- æ‰¹é‡ä¼ è¾“ï¼Œå‡å°‘ç½‘ç»œå¼€é”€
- æ™ºèƒ½å¸¦å®½æ§åˆ¶
- å¯é…ç½®çš„å‹ç¼©å‚æ•°

### âœ… **åŠŸèƒ½ä¸°å¯Œ**
- æ”¯æŒWebSocketå®æ—¶ä¼ è¾“
- æä¾›HTTP REST APIç®¡ç†
- å¯é€‰gRPCæœåŠ¡æ”¯æŒ
- çµæ´»çš„å‰ç«¯é›†æˆ

### âœ… **æ˜“äºæ‰©å±•**
- å¯ä»¥è½»æ¾æ·»åŠ æ–°çš„ä¼ è¾“åè®®
- æ”¯æŒå¤šç§å‰ç«¯é›†æˆæ–¹å¼
- ä¾¿äºæ·»åŠ æ–°åŠŸèƒ½ï¼ˆå¦‚å½•åˆ¶ã€å›æ”¾ç­‰ï¼‰

è¿™ç§ç‹¬ç«‹å®ç°æ–¹æ¡ˆæ›´é€‚åˆå¤šæ‘„åƒå¤´åœºæ™¯ï¼Œé¿å…äº†ä¸ç°æœ‰Image Handlerçš„å…¼å®¹æ€§é—®é¢˜ï¼ŒåŒæ—¶æä¾›äº†æ›´å¥½çš„æ€§èƒ½å’Œå¯ç»´æŠ¤æ€§ã€‚

è®©æˆ‘åˆ†æä¸€ä¸‹ç°æœ‰çš„CameraViewç»„ä»¶æ˜¯å¦å¯ä»¥æ¥æ”¶å’Œæ˜¾ç¤º7ä¸ªæ‘„åƒå¤´æ•°æ®ï¼Œä»¥åŠå¦‚ä½•è¿›è¡Œä¿®æ”¹ã€‚


[3 tools called]

æ ¹æ®æˆ‘å¯¹ç°æœ‰CameraViewç»„ä»¶çš„åˆ†æï¼Œ**ç°æœ‰çš„CameraViewç»„ä»¶æ— æ³•ç›´æ¥æ¥æ”¶å’Œæ˜¾ç¤º7ä¸ªæ‘„åƒå¤´æ•°æ®**ã€‚è®©æˆ‘è¯¦ç»†è¯´æ˜åŸå› å’Œä¿®æ”¹æ–¹æ¡ˆï¼š

## 1. **ç°æœ‰CameraViewç»„ä»¶çš„é™åˆ¶**

### 1.1 æ•°æ®ç»“æ„é™åˆ¶
```typescript
// ç°æœ‰ç»„ä»¶åªèƒ½å¤„ç†å•ä¸ªæ‘„åƒå¤´æ•°æ®
type ICameraUpdate = apollo.dreamview.ICameraUpdate;  // å•ä¸ªæ‘„åƒå¤´æ›´æ–°
const [data, setData] = useState<ICameraUpdate>();   // åªèƒ½å­˜å‚¨ä¸€ä¸ªæ‘„åƒå¤´æ•°æ®
```

### 1.2 UIç»“æ„é™åˆ¶
```typescript
// åªæœ‰ä¸€ä¸ªCanvaså…ƒç´ 
const canvasRef = useRef<HTMLCanvasElement>(null);
return (
    <div className={classes['panel-camera-root']}>
        <canvas ref={canvasRef} />  // åªèƒ½æ˜¾ç¤ºä¸€ä¸ªæ‘„åƒå¤´ç”»é¢
    </div>
);
```

### 1.3 æ•°æ®å¤„ç†é€»è¾‘é™åˆ¶
```typescript
// å¤„ç†é€»è¾‘å‡è®¾åªæœ‰ä¸€ä¸ªå›¾åƒ
if (data?.image?.length > 0) {
    const imageData = new Uint8Array(data.image);  // åªå¤„ç†ä¸€ä¸ªå›¾åƒ
    createImageBitmap(blob).then((imageBitmap) => {
        // åªç»˜åˆ¶åˆ°ä¸€ä¸ªCanvas
        ctx.drawImage(imageBitmap, 0, 0, drawImageWidth, drawImageHeight);
    });
}
```

## 2. **ä¿®æ”¹æ–¹æ¡ˆï¼šåˆ›å»ºMultiCameraViewç»„ä»¶**

### 2.1 åˆ›å»ºæ–°çš„protobufç±»å‹å®šä¹‰

é¦–å…ˆéœ€è¦åˆ›å»ºæ”¯æŒå¤šæ‘„åƒå¤´çš„protobufå®šä¹‰ï¼š

```typescript
// modules/dreamview_plus/proto/multi_camera_update.proto
// åœ¨ç°æœ‰çš„protobufåŸºç¡€ä¸Šæ‰©å±•
interface IMultiCameraUpdate {
    frames: ICameraFrame[];  // 7ä¸ªæ‘„åƒå¤´å¸§æ•°æ®
    timestamp: number;
}

interface ICameraFrame {
    camera_id: string;      // æ‘„åƒå¤´ID
    image: Uint8Array;      // å‹ç¼©åçš„å›¾åƒæ•°æ®
    timestamp: number;
    width: number;
    height: number;
    bbox2d?: IBoundingBox[]; // æ£€æµ‹æ¡†æ•°æ®
    obstaclesId?: string[];
    obstaclesSubType?: string[];
}
```

### 2.2 åˆ›å»ºMultiCameraViewç»„ä»¶

```typescript
// modules/dreamview_plus/frontend/packages/dreamview-core/src/components/panels/MultiCameraView/index.tsx
import React, { useEffect, useMemo, useRef, useState, useLayoutEffect } from 'react';
import type { apollo } from '@dreamview/dreamview';
import { IconPark, Popover } from '@dreamview/dreamview-ui';
import { isEmpty } from 'lodash';
import { useTranslation } from 'react-i18next';
import { useLocalStorage, KEY_MANAGER } from '@dreamview/dreamview-core/src/util/storageManager';
import useStyle from './useStyle';
import { usePanelContext } from '../base/store/PanelStore';
import { ObstacleTypeColorMap } from '../CameraView/utils';  // å¤ç”¨æ£€æµ‹æ¡†é¢œè‰²æ˜ å°„
import LayerMenu from '../CameraView/LayerMenu';  // å¤ç”¨å›¾å±‚èœå•
import { StreamDataNames } from '../../../services/api/types';
import Panel from '../base/Panel';
import CustomScroll from '../../CustomScroll';

interface ICameraFrame {
    camera_id: string;
    image: Uint8Array;
    timestamp: number;
    width: number;
    height: number;
    bbox2d?: any[];
    obstaclesId?: string[];
    obstaclesSubType?: string[];
}

interface IMultiCameraUpdate {
    frames: ICameraFrame[];
    timestamp: number;
}

function InternalMultiCameraView() {
    const panelContext = usePanelContext();
    const { logger, panelId, onPanelResize, initSubscription } = panelContext;
    const localBoundingBoxManager = useLocalStorage(`${KEY_MANAGER.BBox}${panelId}`);

    const [showBoundingBox, setShowBoundingBox] = useState(() => localBoundingBoxManager.get());
    const [viewPortSize, setViewPortSize] = useState(null);
    const [data, setData] = useState<IMultiCameraUpdate>();
    
    // 7ä¸ªæ‘„åƒå¤´çš„Canvaså¼•ç”¨
    const canvasRefs = useRef<(HTMLCanvasElement | null)[]>(Array(7).fill(null));

    useEffect(() => {
        initSubscription({
            [StreamDataNames.MULTI_CAMERA]: {  // è®¢é˜…å¤šæ‘„åƒå¤´æ•°æ®
                consumer: (multiCameraData) => {
                    setData(multiCameraData);
                },
            },
        });
    }, []);

    useLayoutEffect(() => {
        onPanelResize((width, height) => {
            setViewPortSize({ viewPortWidth: width, viewPortHeight: height });
        });
    }, []);

    // æ¸²æŸ“å•ä¸ªæ‘„åƒå¤´å¸§çš„å‡½æ•°ï¼ˆå¤ç”¨CameraViewé€»è¾‘ï¼‰
    const renderCameraFrame = (frame: ICameraFrame, canvasIndex: number) => {
        if (!frame?.image?.length) return;
        
        const canvas = canvasRefs.current[canvasIndex];
        if (!canvas) return;

        const imageData = new Uint8Array(frame.image);
        const blob = new Blob([imageData], { type: 'image/jpeg' });

        createImageBitmap(blob)
            .then((imageBitmap) => {
                // è®¡ç®—æ¯ä¸ªCanvasçš„å°ºå¯¸ï¼ˆ7ä¸ªæ‘„åƒå¤´ç½‘æ ¼å¸ƒå±€ï¼‰
                const canvasWidth = viewPortSize.viewPortWidth / 4;  // 2è¡Œ4åˆ—å¸ƒå±€
                const canvasHeight = viewPortSize.viewPortHeight / 2;
                
                // è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
                const widthScale = canvasWidth / imageBitmap.width;
                const heightScale = canvasHeight / imageBitmap.height;
                const scale = Math.min(widthScale, heightScale);

                const drawWidth = imageBitmap.width * scale;
                const drawHeight = imageBitmap.height * scale;

                // è®¾ç½®Canvaså°ºå¯¸
                canvas.width = drawWidth;
                canvas.height = drawHeight;

                // ç»˜åˆ¶å›¾åƒ
                const ctx = canvas.getContext('2d');
                ctx.drawImage(imageBitmap, 0, 0, drawWidth, drawHeight);

                // ç»˜åˆ¶æ£€æµ‹æ¡†ï¼ˆå¤ç”¨CameraViewé€»è¾‘ï¼‰
                if (frame.bbox2d && frame.bbox2d.length > 0 && showBoundingBox) {
                    frame.bbox2d.forEach((bbox, index) => {
                        const obstaclesId = frame.obstaclesId?.[index];
                        const obstaclesSubType = frame.obstaclesSubType?.[index];

                        ctx.strokeStyle = ObstacleTypeColorMap.get(obstaclesSubType) || 'red';
                        
                        let { xmin, ymin, xmax, ymax } = bbox;
                        if (xmin === ymin && ymin === xmax && xmax === ymax) {
                            return;
                        }
                        
                        [xmin, ymin, xmax, ymax] = [xmin, ymin, xmax, ymax].map(
                            (value) => value * scale,
                        );
                        
                        ctx.strokeRect(xmin, ymin, xmax - xmin, ymax - ymin);
                        ctx.fillStyle = ObstacleTypeColorMap.get(obstaclesSubType) || 'white';
                        ctx.font = '12px Arial';
                        ctx.fillText(`${obstaclesSubType?.substring(3)}:${obstaclesId}`, xmin, ymin);
                    });
                }
            })
            .catch((e) => {
                logger.error(`Error rendering camera ${frame.camera_id}:`, e);
            });
    };

    // å¤„ç†å¤šæ‘„åƒå¤´æ•°æ®
    useEffect(() => {
        if (isEmpty(data) || !data.frames) return;
        
        // ä¸ºæ¯ä¸ªæ‘„åƒå¤´å¸§æ¸²æŸ“åˆ°å¯¹åº”çš„Canvas
        data.frames.forEach((frame, index) => {
            renderCameraFrame(frame, index);
        });
    }, [data, showBoundingBox, viewPortSize]);

    const { classes } = useStyle();
    
    return (
        <div className={classes['multi-camera-root']}>
            {/* å¤ç”¨CameraViewçš„æ§åˆ¶æŒ‰é’® */}
            <div className={classes['camera-btn-container']}>
                <Popover
                    placement='leftTop'
                    content={<LayerMenu setShowBoundingBox={setShowBoundingBox} />}
                    trigger='click'
                >
                    <span className={classes['camera-btn-item']}>
                        <IconPark name='IcCoverageHover' />
                    </span>
                </Popover>
            </div>
            
            {/* 7ä¸ªæ‘„åƒå¤´çš„ç½‘æ ¼å¸ƒå±€ */}
            <CustomScroll className={classes['multi-camera-container']}>
                <div className={classes['camera-grid']}>
                    {Array.from({ length: 7 }, (_, index) => (
                        <div key={index} className={classes['camera-item']}>
                            <div className={classes['camera-label']}>
                                Camera {index + 1}
                            </div>
                            <canvas 
                                ref={(el) => canvasRefs.current[index] = el}
                                className={classes['camera-canvas']}
                                id={`multi-camera-${panelId}-${index}`}
                            />
                        </div>
                    ))}
                </div>
            </CustomScroll>
        </div>
    );
}

function MultiCameraView(props: any) {
    const Component = useMemo(
        () =>
            Panel({
                PanelComponent: InternalMultiCameraView,
                panelId: props.panelId,
                subscribeInfo: [{ name: StreamDataNames.MULTI_CAMERA, needChannel: false }],  // ä¸éœ€è¦channelé€‰æ‹©
            }),
        [],
    );
    return <Component {...props} />;
}

InternalMultiCameraView.displayName = 'InternalMultiCameraView';

export default React.memo(MultiCameraView);
```

### 2.3 åˆ›å»ºå¯¹åº”çš„æ ·å¼æ–‡ä»¶

```typescript
// modules/dreamview_plus/frontend/packages/dreamview-core/src/components/panels/MultiCameraView/useStyle.ts
import { makeStyles } from '@dreamview/dreamview-theme';

export default makeStyles(() => ({
    'multi-camera-root': {
        position: 'relative',
        height: '100%',
        width: '100%',
        display: 'flex',
        justifyContent: 'center',
        alignItems: 'center',
    },
    'camera-btn-container': {
        position: 'absolute',
        bottom: '24px',
        right: '24px',
        zIndex: 10,
    },
    'camera-btn-item': {
        display: 'inline-block',
        cursor: 'pointer',
        textAlign: 'center',
        width: '32px',
        height: '32px',
        lineHeight: '32px',
        background: '#343C4D',
        borderRadius: '6px',
        marginTop: '12px',
        fontSize: '16px',
    },
    'multi-camera-container': {
        width: '100%',
        height: '100%',
        padding: '16px',
    },
    'camera-grid': {
        display: 'grid',
        gridTemplateColumns: 'repeat(4, 1fr)',  // 4åˆ—å¸ƒå±€
        gridTemplateRows: 'repeat(2, 1fr)',     // 2è¡Œå¸ƒå±€
        gap: '8px',
        height: '100%',
        width: '100%',
    },
    'camera-item': {
        position: 'relative',
        border: '1px solid #383B45',
        borderRadius: '4px',
        overflow: 'hidden',
        background: '#1E2329',
    },
    'camera-label': {
        position: 'absolute',
        top: '8px',
        left: '8px',
        background: 'rgba(0, 0, 0, 0.7)',
        color: '#FFFFFF',
        padding: '2px 6px',
        borderRadius: '3px',
        fontSize: '12px',
        zIndex: 5,
    },
    'camera-canvas': {
        width: '100%',
        height: '100%',
        objectFit: 'contain',
    },
}));
```

### 2.4 æ³¨å†Œæ–°ç»„ä»¶åˆ°é¢æ¿åˆ—è¡¨

```typescript
// modules/dreamview_plus/frontend/packages/dreamview-core/src/components/panels/index.tsx
// åœ¨localPanelsæ•°ç»„ä¸­æ·»åŠ ï¼š
{
    title: t('multiCameraViewTitle'),
    type: PanelType.MultiCameraView,
    thumbnail: multiCameraViewIllustratorImg,
    description: t('multiCameraViewDescription'),
    renderToolbar: ChannelSelectFactory({
        helpContent: <MultiCameraViewHelp />,
    }),
    module: () => import('@dreamview/dreamview-core/src/components/panels/MultiCameraView'),
},
```

## 3. **æ€»ç»“**

**ç°æœ‰CameraViewç»„ä»¶æ— æ³•ç›´æ¥æ˜¾ç¤º7ä¸ªæ‘„åƒå¤´æ•°æ®**ï¼Œä¸»è¦é™åˆ¶åŒ…æ‹¬ï¼š

1. **æ•°æ®ç»“æ„**ï¼šåªèƒ½å¤„ç†å•ä¸ª`ICameraUpdate`
2. **UIç»“æ„**ï¼šåªæœ‰ä¸€ä¸ªCanvaså…ƒç´ 
3. **å¤„ç†é€»è¾‘**ï¼šå‡è®¾åªæœ‰ä¸€ä¸ªå›¾åƒæµ

**ä¿®æ”¹æ–¹æ¡ˆ**ï¼š
1. **åˆ›å»ºæ–°çš„MultiCameraViewç»„ä»¶**ï¼Œå¤ç”¨CameraViewçš„æ ¸å¿ƒé€»è¾‘
2. **ä½¿ç”¨7ä¸ªCanvaså…ƒç´ **çš„ç½‘æ ¼å¸ƒå±€
3. **æ‰©å±•æ•°æ®å¤„ç†é€»è¾‘**æ”¯æŒå¤šæ‘„åƒå¤´å¸§æ•°ç»„
4. **å¤ç”¨ç°æœ‰çš„æ£€æµ‹æ¡†ç»˜åˆ¶å’Œå›¾å±‚æ§åˆ¶åŠŸèƒ½**

è¿™ç§æ–¹æ¡ˆå¯ä»¥æœ€å¤§åŒ–å¤ç”¨ç°æœ‰ä»£ç ï¼ŒåŒæ—¶æ”¯æŒ7ä¸ªæ‘„åƒå¤´çš„å¹¶è¡Œæ˜¾ç¤ºå’Œæ£€æµ‹æ¡†å åŠ ã€‚

æ˜¯çš„ï¼Œ**å‰åç«¯éƒ½éœ€è¦é‡‡ç”¨protobuf**æ¥å®ç°æˆ‘æ¨èçš„æ–¹æ¡ˆã€‚è®©æˆ‘è¯¦ç»†è¯´æ˜protobufåœ¨æ•´ä¸ªæ–¹æ¡ˆä¸­çš„ä½œç”¨å’Œå¿…è¦æ€§ï¼š

## 1. **ä¸ºä»€ä¹ˆå¿…é¡»ä½¿ç”¨protobuf**

### 1.1 Apolloé¡¹ç›®çš„æ¶æ„è¦æ±‚
```typescript
// Apolloé¡¹ç›®å·²ç»å»ºç«‹äº†å®Œæ•´çš„protobufç”Ÿæ€ç³»ç»Ÿ
// å‰ç«¯é€šè¿‡protobufjsç”Ÿæˆçš„TypeScriptå®šä¹‰ä¸åç«¯é€šä¿¡
import { apollo } from '@dreamview/dreamview';  // ç”Ÿæˆçš„protobufç±»å‹å®šä¹‰
```

### 1.2 æ•°æ®ä¸€è‡´æ€§å’Œç±»å‹å®‰å…¨
```typescript
// æ²¡æœ‰protobufï¼šå‰ç«¯éœ€è¦æ‰‹åŠ¨å®šä¹‰æ¥å£ï¼Œå®¹æ˜“å‡ºé”™
interface CameraFrame {
    camera_id: string;
    image: number[];  // âŒ ç±»å‹ä¸æ˜ç¡®ï¼Œå®¹æ˜“å‡ºé”™
}

// æœ‰protobufï¼šè‡ªåŠ¨ç”Ÿæˆç±»å‹å®‰å…¨çš„æ¥å£
interface ICameraFrame {
    camera_id?: string;
    image?: Uint8Array;  // âœ… æ˜ç¡®çš„äºŒè¿›åˆ¶æ•°æ®ç±»å‹
    timestamp?: number;
    width?: number;
    height?: number;
}
```

## 2. **åç«¯protobufå®ç°**

### 2.1 åˆ›å»ºæ–°çš„protobufå®šä¹‰æ–‡ä»¶

```protobuf
// modules/dreamview_plus/proto/multi_camera_update.proto
syntax = "proto2";

package apollo.dreamview;

import "modules/common_msgs/dreamview_msgs/simulation_world.proto";

message CameraFrame {
  optional string camera_id = 1;        // æ‘„åƒå¤´ID
  optional bytes image_data = 2;        // å‹ç¼©åçš„JPEGæ•°æ®
  optional double timestamp = 3;        // å¸§æ—¶é—´æˆ³
  optional uint32 width = 4;            // åŸå§‹å›¾åƒå®½åº¦
  optional uint32 height = 5;           // åŸå§‹å›¾åƒé«˜åº¦
  optional double compression_ratio = 6; // å‹ç¼©æ¯”
  
  // æ£€æµ‹æ¡†æ•°æ®ï¼ˆå¤ç”¨ç°æœ‰çš„BoundingBoxå®šä¹‰ï¼‰
  repeated apollo.dreamview.BoundingBox bbox2d = 7;
  repeated string obstacles_id = 8;
  repeated string obstacles_sub_type = 9;
}

message MultiCameraUpdate {
  repeated CameraFrame frames = 1;      // 7ä¸ªæ‘„åƒå¤´çš„å¸§æ•°æ®
  optional double timestamp = 2;        // æ•´ä½“æ—¶é—´æˆ³
  optional string frame_id = 3;         // å¸§ID
}
```

### 2.2 åç«¯ä½¿ç”¨protobufåºåˆ—åŒ–

```cpp
// modules/dreamview_plus/backend/multi_camera_simple/multi_camera_simple.cc
#include "modules/dreamview_plus/proto/multi_camera_update.pb.h"

void MultiCameraSimple::PublishMultiCameraData() {
    // 1. åˆ›å»ºprotobufæ¶ˆæ¯
    MultiCameraUpdate multi_camera_update;
    
    // 2. ä¸ºæ¯ä¸ªæ‘„åƒå¤´å¡«å……æ•°æ®
    for (int i = 0; i < 7; ++i) {
        CameraFrame* frame = multi_camera_update.add_frames();
        frame->set_camera_id("camera_" + std::to_string(i));
        frame->set_image_data(compressed_image_data[i].data(), compressed_image_data[i].size());
        frame->set_timestamp(current_timestamp);
        frame->set_width(960);
        frame->set_height(640);
        
        // æ·»åŠ æ£€æµ‹æ¡†æ•°æ®
        for (const auto& bbox : detection_boxes[i]) {
            apollo::dreamview::BoundingBox* pb_bbox = frame->add_bbox2d();
            pb_bbox->set_xmin(bbox.xmin);
            pb_bbox->set_ymin(bbox.ymin);
            pb_bbox->set_xmax(bbox.xmax);
            pb_bbox->set_ymax(bbox.ymax);
        }
    }
    
    // 3. åºåˆ—åŒ–ä¸ºäºŒè¿›åˆ¶æ•°æ®
    std::string serialized_data;
    multi_camera_update.SerializeToString(&serialized_data);
    
    // 4. å°è£…åˆ°StreamDataå¹¶å‘é€
    StreamData stream_data;
    stream_data.set_action("stream");
    stream_data.set_data_name("multi_camera");
    stream_data.set_type("multi_camera");
    stream_data.set_data(serialized_data.data(), serialized_data.size());
    
    std::string stream_data_string;
    stream_data.SerializeToString(&stream_data_string);
    websocket_->BroadcastBinaryData(stream_data_string);
}
```

## 3. **å‰ç«¯protobufä½¿ç”¨**

### 3.1 ç”ŸæˆTypeScriptå®šä¹‰

```bash
# ä½¿ç”¨ç°æœ‰çš„protobufjsç”Ÿæˆè„šæœ¬
# modules/dreamview_plus/frontend/packages/dreamview/scripts/gen.js
const generateProto = `
../node_modules/.bin/pbjs -t static-module -w commonjs \\
${DREAMVIEW_DIR}/proto/multi_camera_update.proto \\
-o ${DREAMVIEW_PROTO_BUNDLE_PATH}
`;

const generateDeclaration = `
../node_modules/.bin/pbts ${DREAMVIEW_PROTO_BUNDLE_PATH} -o ${DECLARATION_BUNDLE_PATH}
`;
```

### 3.2 å‰ç«¯ä½¿ç”¨ç”Ÿæˆçš„ç±»å‹å®šä¹‰

```typescript
// modules/dreamview_plus/frontend/packages/dreamview-core/src/components/panels/MultiCameraView/index.tsx
import { apollo } from '@dreamview/dreamview';  // åŒ…å«æ–°ç”Ÿæˆçš„MultiCameraUpdateç±»å‹

// ä½¿ç”¨protobufç”Ÿæˆçš„ç±»å‹
type IMultiCameraUpdate = apollo.dreamview.IMultiCameraUpdate;
type ICameraFrame = apollo.dreamview.ICameraFrame;

function InternalMultiCameraView() {
    const [data, setData] = useState<IMultiCameraUpdate>();
    
    useEffect(() => {
        initSubscription({
            [StreamDataNames.MULTI_CAMERA]: {
                consumer: (multiCameraData: IMultiCameraUpdate) => {
                    // protobufè‡ªåŠ¨ååºåˆ—åŒ–ï¼Œç±»å‹å®‰å…¨
                    setData(multiCameraData);
                },
            },
        });
    }, []);

    // å¤„ç†protobufæ•°æ®
    useEffect(() => {
        if (!data?.frames) return;
        
        // éå†protobufç”Ÿæˆçš„framesæ•°ç»„
        data.frames.forEach((frame: ICameraFrame, index: number) => {
            if (frame.image_data) {
                // frame.image_dataæ˜¯Uint8Arrayç±»å‹ï¼Œç›´æ¥ä½¿ç”¨
                const imageData = new Uint8Array(frame.image_data);
                const blob = new Blob([imageData], { type: 'image/jpeg' });
                
                createImageBitmap(blob).then((imageBitmap) => {
                    renderCameraFrame(frame, imageBitmap, index);
                });
            }
        });
    }, [data]);
}
```

## 4. **protobufçš„ä¼˜åŠ¿ä½“ç°**

### 4.1 è‡ªåŠ¨åºåˆ—åŒ–/ååºåˆ—åŒ–
```typescript
// å‰ç«¯æ¥æ”¶WebSocketæ•°æ®æ—¶ï¼Œprotobufjsè‡ªåŠ¨å¤„ç†
const streamData = StreamData.decode(new Uint8Array(binaryData));
const multiCameraUpdate = MultiCameraUpdate.decode(streamData.data);

// æ— éœ€æ‰‹åŠ¨è§£æJSONæˆ–å¤„ç†å­—èŠ‚å¯¹é½é—®é¢˜
```

### 4.2 ç‰ˆæœ¬å…¼å®¹æ€§
```protobuf
// æ·»åŠ æ–°å­—æ®µæ—¶ï¼Œå‘åå…¼å®¹
message CameraFrame {
  optional string camera_id = 1;
  optional bytes image_data = 2;
  optional double timestamp = 3;
  optional uint32 width = 4;
  optional uint32 height = 5;
  optional double compression_ratio = 6;
  
  // æ–°å¢å­—æ®µï¼Œæ—§ç‰ˆæœ¬å®¢æˆ·ç«¯å¿½ç•¥
  optional string camera_model = 7;  // æ–°å¢
  optional bool is_hdr_enabled = 8;  // æ–°å¢
}
```

### 4.3 æ•°æ®å‹ç¼©æ•ˆç‡
```cpp
// protobufçš„äºŒè¿›åˆ¶æ ¼å¼æ¯”JSONæ›´ç´§å‡‘
// å¯¹äºå›¾åƒæ•°æ®ï¼ŒäºŒè¿›åˆ¶ä¼ è¾“æ•ˆç‡æ›´é«˜
frame->set_image_data(compressed_data.data(), compressed_data.size());  // ç›´æ¥ä¼ è¾“äºŒè¿›åˆ¶
```

## 5. **é›†æˆåˆ°ç°æœ‰protobufä½“ç³»**

### 5.1 æ›´æ–°BUILDæ–‡ä»¶
```python
# modules/dreamview_plus/proto/BUILD
proto_library(
    name = "multi_camera_update_proto",
    srcs = ["multi_camera_update.proto"],
    deps = [
        "//modules/common_msgs/dreamview_msgs:simulation_world_proto",
    ],
)
```

### 5.2 æ›´æ–°æ•°æ®å¤„ç†å™¨é…ç½®
```json
// modules/dreamview_plus/conf/data_handler.conf
{
  "data_handler_config": [
    {
      "name": "multi_camera",
      "msg_type": "apollo.dreamview.MultiCameraUpdate",
      "need_channel": false,
      "frequency": 10
    }
  ]
}
```

## 6. **æ€»ç»“**

**æ˜¯çš„ï¼Œå‰åç«¯éƒ½å¿…é¡»ä½¿ç”¨protobuf**ï¼ŒåŸå› åŒ…æ‹¬ï¼š

1. **æ¶æ„ä¸€è‡´æ€§**ï¼šApolloé¡¹ç›®å·²å»ºç«‹å®Œæ•´çš„protobufç”Ÿæ€
2. **ç±»å‹å®‰å…¨**ï¼šè‡ªåŠ¨ç”ŸæˆTypeScriptå®šä¹‰ï¼Œé¿å…æ‰‹åŠ¨å®šä¹‰æ¥å£é”™è¯¯
3. **æ•°æ®æ•ˆç‡**ï¼šäºŒè¿›åˆ¶æ ¼å¼æ¯”JSONæ›´ç´§å‡‘ï¼Œç‰¹åˆ«é€‚åˆå›¾åƒæ•°æ®
4. **ç‰ˆæœ¬å…¼å®¹**ï¼šprotobufçš„å­—æ®µç‰ˆæœ¬æ§åˆ¶æœºåˆ¶
5. **è‡ªåŠ¨åŒ–å·¥å…·**ï¼šç°æœ‰çš„protobufjsç”Ÿæˆè„šæœ¬å¯ä»¥ç›´æ¥å¤ç”¨

ä¸ä½¿ç”¨protobufä¼šå¯¼è‡´ï¼š
- ä¸ç°æœ‰Apolloæ¶æ„ä¸ä¸€è‡´
- éœ€è¦æ‰‹åŠ¨å¤„ç†åºåˆ—åŒ–/ååºåˆ—åŒ–
- ç±»å‹å®‰å…¨é—®é¢˜
- æ•°æ®ä¼ è¾“æ•ˆç‡ä½ä¸‹

å› æ­¤ï¼Œ**protobufæ˜¯æ•´ä¸ªæ–¹æ¡ˆçš„æ ¸å¿ƒåŸºç¡€**ï¼Œå¿…é¡»é‡‡ç”¨ã€‚

**å®Œå…¨æ­£ç¡®ï¼** ä½¿ç”¨protobufçš„è‡ªåŠ¨åºåˆ—åŒ–æœºåˆ¶åï¼Œ**ä¸éœ€è¦ä½¿ç”¨base64ç¼–ç **ã€‚

## 1. **protobufç›´æ¥å¤„ç†äºŒè¿›åˆ¶æ•°æ®**

### 1.1 protobufçš„bytesç±»å‹ç›´æ¥æ”¯æŒäºŒè¿›åˆ¶
```protobuf
message CameraFrame {
  optional string camera_id = 1;
  optional bytes image_data = 2;  // ç›´æ¥å­˜å‚¨äºŒè¿›åˆ¶æ•°æ®ï¼Œæ— éœ€base64
  optional double timestamp = 3;
}
```

### 1.2 åç«¯ç›´æ¥è®¾ç½®äºŒè¿›åˆ¶æ•°æ®
```cpp
// åç«¯ï¼šç›´æ¥è®¾ç½®å‹ç¼©åçš„JPEGäºŒè¿›åˆ¶æ•°æ®
void MultiCameraSimple::OnImage(const std::shared_ptr<Image>& image, const std::string& camera_id) {
    // 1. å‹ç¼©å›¾åƒ
    std::vector<uint8_t> compressed_buffer;
    cv::imencode(".jpg", resized_mat, compressed_buffer, compression_params);
    
    // 2. ç›´æ¥è®¾ç½®äºŒè¿›åˆ¶æ•°æ®åˆ°protobuf
    CameraFrame* frame = multi_camera_update.add_frames();
    frame->set_camera_id(camera_id);
    frame->set_image_data(compressed_buffer.data(), compressed_buffer.size());  // ç›´æ¥è®¾ç½®äºŒè¿›åˆ¶
    // æ— éœ€base64ç¼–ç ï¼
}
```

### 1.3 å‰ç«¯ç›´æ¥æ¥æ”¶äºŒè¿›åˆ¶æ•°æ®
```typescript
// å‰ç«¯ï¼šprotobufè‡ªåŠ¨ååºåˆ—åŒ–ï¼Œç›´æ¥å¾—åˆ°Uint8Array
useEffect(() => {
    if (!data?.frames) return;
    
    data.frames.forEach((frame: ICameraFrame, index: number) => {
        if (frame.image_data) {
            // frame.image_data å·²ç»æ˜¯ Uint8Arrayï¼Œæ— éœ€base64è§£ç 
            const imageData = frame.image_data;  // ç›´æ¥ä½¿ç”¨
            const blob = new Blob([imageData], { type: 'image/jpeg' });
            
            createImageBitmap(blob).then((imageBitmap) => {
                renderCameraFrame(frame, imageBitmap, index);
            });
        }
    });
}, [data]);
```

## 2. **base64 vs protobuf byteså¯¹æ¯”**

### 2.1 ä½¿ç”¨base64çš„é—®é¢˜
```typescript
// âŒ ä½¿ç”¨base64çš„ç¹çè¿‡ç¨‹
// åç«¯ï¼š
std::string base64_encoded = base64_encode(compressed_data);
frame->set_image_data(base64_encoded);  // å­˜å‚¨base64å­—ç¬¦ä¸²

// å‰ç«¯ï¼š
const base64String = frame.image_data;  // å¾—åˆ°base64å­—ç¬¦ä¸²
const binaryData = atob(base64String);  // base64è§£ç 
const imageData = new Uint8Array(binaryData.length);
for (let i = 0; i < binaryData.length; i++) {
    imageData[i] = binaryData.charCodeAt(i);
}
const blob = new Blob([imageData], { type: 'image/jpeg' });
```

### 2.2 ä½¿ç”¨protobuf bytesçš„ä¼˜åŠ¿
```typescript
// âœ… ä½¿ç”¨protobuf bytesçš„ç®€æ´è¿‡ç¨‹
// åç«¯ï¼š
frame->set_image_data(compressed_data.data(), compressed_data.size());  // ç›´æ¥è®¾ç½®äºŒè¿›åˆ¶

// å‰ç«¯ï¼š
const imageData = frame.image_data;  // ç›´æ¥å¾—åˆ°Uint8Array
const blob = new Blob([imageData], { type: 'image/jpeg' });  // ç›´æ¥ä½¿ç”¨
```

## 3. **æ•°æ®å¤§å°å¯¹æ¯”**

### 3.1 base64ç¼–ç ä¼šå¢åŠ 33%çš„æ•°æ®é‡
```cpp
// åŸå§‹JPEGå‹ç¼©æ•°æ®ï¼š25KB
std::vector<uint8_t> compressed_data(25000);

// base64ç¼–ç åï¼š33,333 bytes (å¢åŠ 33%)
std::string base64_encoded = base64_encode(compressed_data);

// protobuf bytesï¼š25,000 bytes (æ— é¢å¤–å¼€é”€)
frame->set_image_data(compressed_data.data(), compressed_data.size());
```

### 3.2 7ä¸ªæ‘„åƒå¤´çš„ç´¯ç§¯æ•ˆåº”
```cpp
// 7ä¸ªæ‘„åƒå¤´ï¼Œæ¯ä¸ª25KB
// base64æ–¹æ¡ˆï¼š7 Ã— 33,333 = 233,331 bytes
// protobufæ–¹æ¡ˆï¼š7 Ã— 25,000 = 175,000 bytes
// èŠ‚çœï¼š58,331 bytes (çº¦25%çš„æ•°æ®ä¼ è¾“é‡)
```

## 4. **WebSocketä¼ è¾“æœºåˆ¶**

### 4.1 protobuf + WebSocketçš„å®Œç¾é…åˆ
```cpp
// åç«¯ï¼šprotobufåºåˆ—åŒ–åç›´æ¥é€šè¿‡WebSocketä¼ è¾“
void MultiCameraSimple::PublishMultiCameraData() {
    MultiCameraUpdate multi_camera_update;
    // ... å¡«å……æ•°æ®
    
    std::string serialized_data;
    multi_camera_update.SerializeToString(&serialized_data);  // äºŒè¿›åˆ¶åºåˆ—åŒ–
    
    // å°è£…åˆ°StreamData
    StreamData stream_data;
    stream_data.set_data(serialized_data.data(), serialized_data.size());
    
    std::string stream_data_string;
    stream_data.SerializeToString(&stream_data_string);
    
    // WebSocketç›´æ¥ä¼ è¾“äºŒè¿›åˆ¶æ•°æ®
    websocket_->BroadcastBinaryData(stream_data_string);  // æ— éœ€base64
}
```

### 4.2 å‰ç«¯æ¥æ”¶å’Œè§£æ
```typescript
// å‰ç«¯ï¼šWebSocketæ¥æ”¶äºŒè¿›åˆ¶æ•°æ®ï¼Œprotobufè‡ªåŠ¨è§£æ
useEffect(() => {
    const subscription = streamApi
        .subscribeToData('MULTI_CAMERA')
        .subscribe((binaryData: Uint8Array) => {
            // protobufè‡ªåŠ¨ååºåˆ—åŒ–
            const streamData = StreamData.decode(binaryData);
            const multiCameraUpdate = MultiCameraUpdate.decode(streamData.data);
            
            // ç›´æ¥ä½¿ç”¨ï¼Œæ— éœ€ä»»ä½•base64å¤„ç†
            setData(multiCameraUpdate);
        });
}, []);
```

## 5. **æ€§èƒ½ä¼˜åŠ¿æ€»ç»“**

| æ–¹é¢           | base64æ–¹æ¡ˆ       | protobuf bytesæ–¹æ¡ˆ |
| -------------- | ---------------- | ------------------ |
| **æ•°æ®å¤§å°**   | åŸå§‹å¤§å° Ã— 1.33  | åŸå§‹å¤§å° Ã— 1.0     |
| **ç¼–ç å¼€é”€**   | base64ç¼–ç /è§£ç   | æ— é¢å¤–å¼€é”€         |
| **å†…å­˜ä½¿ç”¨**   | éœ€è¦ä¸´æ—¶å­—ç¬¦ä¸²   | ç›´æ¥äºŒè¿›åˆ¶å¤„ç†     |
| **CPUä½¿ç”¨**    | ç¼–ç /è§£ç CPUå¯†é›† | æœ€å°CPUä½¿ç”¨        |
| **ä»£ç å¤æ‚åº¦** | éœ€è¦base64åº“     | protobufè‡ªåŠ¨å¤„ç†   |

## 6. **å®é™…ä»£ç ç¤ºä¾‹**

### 6.1 å®Œæ•´çš„æ— base64æ–¹æ¡ˆ
```typescript
// å‰ç«¯ï¼šç®€æ´çš„å›¾åƒå¤„ç†
const processCameraFrame = (frame: ICameraFrame, canvasIndex: number) => {
    if (!frame.image_data) return;
    
    // ç›´æ¥ä½¿ç”¨protobufçš„äºŒè¿›åˆ¶æ•°æ®
    const blob = new Blob([frame.image_data], { type: 'image/jpeg' });
    
    createImageBitmap(blob)
        .then((imageBitmap) => {
            const canvas = canvasRefs.current[canvasIndex];
            if (!canvas) return;
            
            const ctx = canvas.getContext('2d');
            ctx.drawImage(imageBitmap, 0, 0, canvas.width, canvas.height);
            
            // ç»˜åˆ¶æ£€æµ‹æ¡†
            if (frame.bbox2d && frame.bbox2d.length > 0) {
                drawBoundingBoxes(ctx, frame.bbox2d, frame.obstacles_id, frame.obstacles_sub_type);
            }
        })
        .catch((error) => {
            console.error(`Error processing camera ${frame.camera_id}:`, error);
        });
};
```

## 7. **æ€»ç»“**

**æ˜¯çš„ï¼Œä½¿ç”¨protobufçš„è‡ªåŠ¨åºåˆ—åŒ–æœºåˆ¶åï¼Œå®Œå…¨ä¸éœ€è¦base64ç¼–ç **ï¼Œå› ä¸ºï¼š

1. **protobufçš„`bytes`ç±»å‹**ç›´æ¥æ”¯æŒäºŒè¿›åˆ¶æ•°æ®å­˜å‚¨
2. **WebSocket**åŸç”Ÿæ”¯æŒäºŒè¿›åˆ¶æ•°æ®ä¼ è¾“
3. **protobufjs**è‡ªåŠ¨å¤„ç†äºŒè¿›åˆ¶æ•°æ®çš„åºåˆ—åŒ–/ååºåˆ—åŒ–
4. **æ€§èƒ½æ›´å¥½**ï¼šæ— base64ç¼–ç å¼€é”€ï¼Œæ•°æ®ä¼ è¾“é‡å‡å°‘25%
5. **ä»£ç æ›´ç®€æ´**ï¼šæ— éœ€base64ç¼–ç /è§£ç çš„ç¹çæ“ä½œ

è¿™ç§æ–¹æ¡ˆæ—¢ä¿æŒäº†ä¸Apolloé¡¹ç›®æ¶æ„çš„ä¸€è‡´æ€§ï¼Œåˆè·å¾—äº†æœ€ä½³çš„æ€§èƒ½è¡¨ç°ã€‚

------

å¥½çš„ï¼Œæˆ‘æ¥ä¸ºä½ æ•´ç†ä¸€ä¸ª**åˆ†æ­¥éª¤å®ç°**çš„å®Œæ•´æ–¹æ¡ˆï¼Œè®©ä½ å¯ä»¥ä¸€æ­¥ä¸€æ­¥åœ°å®Œæˆåç«¯å’Œå‰ç«¯çš„ä¿®æ”¹ã€‚

## ğŸ“‹ **å®æ–½è®¡åˆ’æ€»è§ˆ**

| æ­¥éª¤ | åç«¯ä¿®æ”¹         | å‰ç«¯ä¿®æ”¹            | é¢„è®¡æ—¶é—´ | éªŒè¯æ–¹æ³•      |
| ---- | ---------------- | ------------------- | -------- | ------------- |
| 1    | æ‰©å±•protobufå®šä¹‰ | -                   | 15åˆ†é’Ÿ   | ç¼–è¯‘é€šè¿‡      |
| 2    | ä¿®æ”¹åç«¯Updater  | -                   | 30åˆ†é’Ÿ   | åç«¯å¯åŠ¨æˆåŠŸ  |
| 3    | åˆ›å»ºå‰ç«¯ç»„ä»¶     | æ–°å»ºMultiCameraView | 45åˆ†é’Ÿ   | ç»„ä»¶æ˜¾ç¤º      |
| 4    | é›†æˆæµ‹è¯•         | è¿æ¥æµ‹è¯•            | 15åˆ†é’Ÿ   | 7ä¸ªæ‘„åƒå¤´æ˜¾ç¤º |

---

## ğŸ”§ **æ­¥éª¤1ï¼šæ‰©å±•protobufå®šä¹‰ï¼ˆåç«¯ï¼‰**

### 1.1 ä¿®æ”¹ç°æœ‰protobufæ–‡ä»¶
```bash
# æ–‡ä»¶ä½ç½®ï¼šmodules/dreamview/proto/camera_update.proto
```

```protobuf
// modules/dreamview/proto/camera_update.proto
syntax = "proto2";

package apollo.dreamview;

import "modules/common_msgs/dreamview_msgs/simulation_world.proto";

message BoundingBox {
  optional double xmin = 1;
  optional double ymin = 2;
  optional double xmax = 3;
  optional double ymax = 4;
}

message CameraUpdate {
  optional bytes image = 1;
  optional double kImageScale = 2;
  repeated BoundingBox bbox2d = 3;
  repeated string obstaclesId = 4;
  repeated string obstaclesSubType = 5;
  
  // æ–°å¢ï¼šå¤šæ‘„åƒå¤´æ”¯æŒ
  repeated CameraFrame multi_camera_frames = 6;
}

// æ–°å¢ï¼šå•ä¸ªæ‘„åƒå¤´å¸§å®šä¹‰
message CameraFrame {
  optional string camera_id = 1;        // æ‘„åƒå¤´ID
  optional bytes image_data = 2;        // å‹ç¼©åçš„JPEGæ•°æ®
  optional double timestamp = 3;        // å¸§æ—¶é—´æˆ³
  optional uint32 width = 4;            // åŸå§‹å›¾åƒå®½åº¦
  optional uint32 height = 5;           // åŸå§‹å›¾åƒé«˜åº¦
  repeated BoundingBox bbox2d = 6;      // æ£€æµ‹æ¡†æ•°æ®
  repeated string obstaclesId = 7;      // éšœç¢ç‰©ID
  repeated string obstaclesSubType = 8; // éšœç¢ç‰©ç±»å‹
}
```

### 1.2 éªŒè¯æ­¥éª¤1
```bash
# åœ¨Apolloæ ¹ç›®å½•æ‰§è¡Œ
./apollo.sh build
# ç¡®ä¿ç¼–è¯‘æ— é”™è¯¯
```

---

## ğŸ”§ **æ­¥éª¤2ï¼šä¿®æ”¹åç«¯Updaterï¼ˆåç«¯ï¼‰**

### 2.1 ä¿®æ”¹ç°æœ‰PerceptionCameraUpdaterå¤´æ–‡ä»¶
```bash
# æ–‡ä»¶ä½ç½®ï¼šmodules/dreamview_plus/backend/perception_camera_updater/perception_camera_updater.h
```

```cpp
// modules/dreamview_plus/backend/perception_camera_updater/perception_camera_updater.h
#ifndef MODULES_DREAMVIEW_BACKEND_PERCEPTION_CAMERA_UPDATER_PERCEPTION_CAMERA_UPDATER_H_
#define MODULES_DREAMVIEW_BACKEND_PERCEPTION_CAMERA_UPDATER_PERCEPTION_CAMERA_UPDATER_H_

#include <memory>
#include <string>
#include <vector>
#include <map>
#include <mutex>
#include <atomic>
#include <chrono>
#include <opencv2/opencv.hpp>

#include "cyber/cyber.h"
#include "modules/common_msgs/sensor_msgs/sensor_image.pb.h"
#include "modules/dreamview/proto/camera_update.pb.h"
#include "modules/dreamview/backend/common/handlers/websocket_handler.h"

namespace apollo {
namespace dreamview {

class PerceptionCameraUpdater {
public:
  PerceptionCameraUpdater();
  ~PerceptionCameraUpdater();

  void Start();
  void Stop();

private:
  // ç°æœ‰æ–¹æ³•ä¿æŒä¸å˜
  void OnImage(const std::shared_ptr<Image>& image);
  void ProcessSingleCamera(const std::shared_ptr<Image>& image);
  
  // æ–°å¢ï¼šå¤šæ‘„åƒå¤´å¤„ç†æ–¹æ³•
  void ProcessMultiCamera(const std::shared_ptr<Image>& image);
  void PublishMultiCameraUpdate();
  void ResetMultiCameraBatch();
  std::string GetCameraIdFromChannel(const std::string& channel_name);
  bool IsBatchTimeout();

private:
  // ç°æœ‰æˆå‘˜å˜é‡ä¿æŒä¸å˜
  std::unique_ptr<WebSocketHandler> websocket_;
  std::unique_ptr<cyber::Node> node_;
  std::vector<std::shared_ptr<cyber::Reader<Image>>> readers_;
  std::vector<uint8_t> image_buffer_;
  std::atomic<int> requests_;
  std::mutex mutex_;

  // æ–°å¢ï¼šå¤šæ‘„åƒå¤´ç›¸å…³æˆå‘˜å˜é‡
  std::map<std::string, CameraFrame> multi_camera_cache_;
  std::atomic<int> received_camera_count_{0};
  std::chrono::steady_clock::time_point batch_start_time_;
  std::mutex multi_camera_mutex_;
  static constexpr int EXPECTED_CAMERA_COUNT = 7;
  static constexpr int BATCH_TIMEOUT_MS = 100;  // 100msè¶…æ—¶
};

}  // namespace dreamview
}  // namespace apollo

#endif  // MODULES_DREAMVIEW_BACKEND_PERCEPTION_CAMERA_UPDATER_PERCEPTION_CAMERA_UPDATER_H_
```

### 2.2 ä¿®æ”¹å®ç°æ–‡ä»¶
```bash
# æ–‡ä»¶ä½ç½®ï¼šmodules/dreamview_plus/backend/perception_camera_updater/perception_camera_updater.cc
```

```cpp
// modules/dreamview_plus/backend/perception_camera_updater/perception_camera_updater.cc
#include "modules/dreamview_plus/backend/perception_camera_updater/perception_camera_updater.h"

namespace apollo {
namespace dreamview {

PerceptionCameraUpdater::PerceptionCameraUpdater() {
  // ç°æœ‰æ„é€ å‡½æ•°ä»£ç ä¿æŒä¸å˜
  websocket_.reset(new WebSocketHandler("Camera"));
  requests_ = 0;
}

PerceptionCameraUpdater::~PerceptionCameraUpdater() {
  Stop();
}

void PerceptionCameraUpdater::Start() {
  // ç°æœ‰Startæ–¹æ³•ä»£ç ä¿æŒä¸å˜
  node_ = cyber::CreateNode("perception_camera_updater");
  
  // åˆå§‹åŒ–å¤šæ‘„åƒå¤´æ‰¹å¤„ç†
  ResetMultiCameraBatch();
  
  // æ·»åŠ æ‘„åƒå¤´channelè®¢é˜…ï¼ˆ7ä¸ªæ‘„åƒå¤´ï¼‰
  std::vector<std::string> camera_channels = {
    "/apollo/sensor/camera/front_6mm/image",
    "/apollo/sensor/camera/front_12mm/image", 
    "/apollo/sensor/camera/front_fisheye/image",
    "/apollo/sensor/camera/left_front/image",
    "/apollo/sensor/camera/left_rear/image",
    "/apollo/sensor/camera/right_front/image",
    "/apollo/sensor/camera/right_rear/image"
  };
  
  for (const auto& channel : camera_channels) {
    auto reader = node_->CreateReader<Image>(channel, 
        [this](const std::shared_ptr<Image>& image) {
          OnImage(image);
        });
    readers_.push_back(reader);
  }
}

void PerceptionCameraUpdater::Stop() {
  // ç°æœ‰Stopæ–¹æ³•ä»£ç ä¿æŒä¸å˜
  readers_.clear();
  if (node_) {
    node_.reset();
  }
}

void PerceptionCameraUpdater::OnImage(const std::shared_ptr<Image>& image) {
  // ä¿æŒç°æœ‰å•æ‘„åƒå¤´é€»è¾‘
  ProcessSingleCamera(image);
  
  // æ–°å¢å¤šæ‘„åƒå¤´é€»è¾‘
  ProcessMultiCamera(image);
}

void PerceptionCameraUpdater::ProcessSingleCamera(const std::shared_ptr<Image>& image) {
  // ç°æœ‰å•æ‘„åƒå¤´å¤„ç†é€»è¾‘ä¿æŒä¸å˜
  std::lock_guard<std::mutex> lock(mutex_);
  
  cv::Mat mat(image->height(), image->width(), CV_8UC3,
              const_cast<char*>(image->data().data()), image->step());
  cv::cvtColor(mat, mat, cv::COLOR_RGB2BGR);
  cv::resize(mat, mat, cv::Size(static_cast<int>(image->width() * 0.5),
                               static_cast<int>(image->height() * 0.5)),
             0, 0, cv::INTER_LINEAR);
  cv::imencode(".jpg", mat, image_buffer_, std::vector<int>());
  
  // å‘é€å•æ‘„åƒå¤´æ›´æ–°ï¼ˆç°æœ‰é€»è¾‘ï¼‰
  CameraUpdate camera_update;
  camera_update.set_image(image_buffer_.data(), image_buffer_.size());
  camera_update.set_kimagescale(0.5);
  
  std::string to_send;
  camera_update.SerializeToString(&to_send);
  
  StreamData stream_data;
  stream_data.set_action("stream");
  stream_data.set_data_name("camera");
  stream_data.set_data(to_send.data(), to_send.size());
  stream_data.set_type("camera");
  
  std::string stream_data_string;
  stream_data.SerializeToString(&stream_data_string);
  websocket_->BroadcastBinaryData(stream_data_string);
}

// æ–°å¢ï¼šå¤šæ‘„åƒå¤´å¤„ç†æ–¹æ³•
void PerceptionCameraUpdater::ProcessMultiCamera(const std::shared_ptr<Image>& image) {
  std::lock_guard<std::mutex> lock(multi_camera_mutex_);
  
  // è·å–æ‘„åƒå¤´ID
  std::string camera_id = GetCameraIdFromChannel(image->frame_id());
  
  // å‹ç¼©å›¾åƒ
  cv::Mat mat(image->height(), image->width(), CV_8UC3,
              const_cast<char*>(image->data().data()), image->step());
  cv::cvtColor(mat, mat, cv::COLOR_RGB2BGR);
  cv::resize(mat, mat, cv::Size(384, 256), 0, 0, cv::INTER_LINEAR);
  
  std::vector<uint8_t> compressed_buffer;
  std::vector<int> compression_params = {
    cv::IMWRITE_JPEG_QUALITY, 85,
    cv::IMWRITE_JPEG_OPTIMIZE, 1
  };
  cv::imencode(".jpg", mat, compressed_buffer, compression_params);
  
  // åˆ›å»ºCameraFrame
  CameraFrame frame;
  frame.set_camera_id(camera_id);
  frame.set_image_data(compressed_buffer.data(), compressed_buffer.size());
  frame.set_timestamp(image->measurement_time());
  frame.set_width(image->width());
  frame.set_height(image->height());
  
  // ç¼“å­˜å¤šæ‘„åƒå¤´æ•°æ®
  multi_camera_cache_[camera_id] = frame;
  received_camera_count_++;
  
  // å½“æ”¶åˆ°7ä¸ªæ‘„åƒå¤´æ•°æ®æ—¶ï¼Œæˆ–è€…è¶…æ—¶æ—¶å‘é€
  if (received_camera_count_ >= EXPECTED_CAMERA_COUNT || IsBatchTimeout()) {
    PublishMultiCameraUpdate();
    ResetMultiCameraBatch();
  }
}

void PerceptionCameraUpdater::PublishMultiCameraUpdate() {
  if (multi_camera_cache_.empty()) return;
  
  CameraUpdate camera_update;
  
  // å¡«å……å¤šæ‘„åƒå¤´æ•°æ®
  for (const auto& [camera_id, frame] : multi_camera_cache_) {
    CameraFrame* new_frame = camera_update.add_multi_camera_frames();
    *new_frame = frame;
  }
  
  // å‘é€å¤šæ‘„åƒå¤´æ›´æ–°
  std::string to_send;
  camera_update.SerializeToString(&to_send);
  
  StreamData stream_data;
  stream_data.set_action("stream");
  stream_data.set_data_name("camera");
  stream_data.set_channel_name("multi_camera");  // ç‰¹æ®Šæ ‡è¯†
  stream_data.set_data(to_send.data(), to_send.size());
  stream_data.set_type("camera");
  
  std::string stream_data_string;
  stream_data.SerializeToString(&stream_data_string);
  websocket_->BroadcastBinaryData(stream_data_string);
}

void PerceptionCameraUpdater::ResetMultiCameraBatch() {
  multi_camera_cache_.clear();
  received_camera_count_ = 0;
  batch_start_time_ = std::chrono::steady_clock::now();
}

std::string PerceptionCameraUpdater::GetCameraIdFromChannel(const std::string& channel_name) {
  // ä»channelåç§°æå–æ‘„åƒå¤´ID
  if (channel_name.find("front_6mm") != std::string::npos) return "front_6mm";
  if (channel_name.find("front_12mm") != std::string::npos) return "front_12mm";
  if (channel_name.find("front_fisheye") != std::string::npos) return "front_fisheye";
  if (channel_name.find("left_front") != std::string::npos) return "left_front";
  if (channel_name.find("left_rear") != std::string::npos) return "left_rear";
  if (channel_name.find("right_front") != std::string::npos) return "right_front";
  if (channel_name.find("right_rear") != std::string::npos) return "right_rear";
  return "unknown";
}

bool PerceptionCameraUpdater::IsBatchTimeout() {
  auto now = std::chrono::steady_clock::now();
  auto elapsed = std::chrono::duration_cast<std::chrono::milliseconds>(
      now - batch_start_time_).count();
  return elapsed >= BATCH_TIMEOUT_MS;
}

}  // namespace dreamview
}  // namespace apollo
```

### 2.3 éªŒè¯æ­¥éª¤2
```bash
# ç¼–è¯‘åç«¯
./apollo.sh build

# å¯åŠ¨åç«¯æœåŠ¡
./apollo.sh build_opt
./scripts/bootstrap.sh

# æ£€æŸ¥æ—¥å¿—ï¼Œç¡®ä¿PerceptionCameraUpdaterå¯åŠ¨æˆåŠŸ
tail -f /opt/apollo/logs/dreamview.log
```

---

## ğŸ¨ **æ­¥éª¤3ï¼šåˆ›å»ºå‰ç«¯MultiCameraViewç»„ä»¶ï¼ˆå‰ç«¯ï¼‰**

### 3.1 åˆ›å»ºç»„ä»¶ç›®å½•ç»“æ„
```bash
mkdir -p modules/dreamview_plus/frontend/packages/dreamview-core/src/components/panels/MultiCameraView
```

### 3.2 åˆ›å»ºæ ·å¼æ–‡ä»¶
```typescript
// modules/dreamview_plus/frontend/packages/dreamview-core/src/components/panels/MultiCameraView/useStyle.ts
import { makeStyles } from '@dreamview/dreamview-theme';

export default makeStyles(() => ({
    'multi-camera-root': {
        position: 'relative',
        height: '100%',
        width: '100%',
        display: 'flex',
        justifyContent: 'center',
        alignItems: 'center',
    },
    'camera-btn-container': {
        position: 'absolute',
        bottom: '24px',
        right: '24px',
        zIndex: 10,
    },
    'camera-btn-item': {
        display: 'inline-block',
        cursor: 'pointer',
        textAlign: 'center',
        width: '32px',
        height: '32px',
        lineHeight: '32px',
        background: '#343C4D',
        borderRadius: '6px',
        marginTop: '12px',
        fontSize: '16px',
    },
    'multi-camera-container': {
        width: '100%',
        height: '100%',
        padding: '16px',
    },
    'camera-grid': {
        display: 'grid',
        gridTemplateColumns: 'repeat(4, 1fr)',
        gridTemplateRows: 'repeat(2, 1fr)',
        gap: '8px',
        height: '100%',
        width: '100%',
    },
    'camera-item': {
        position: 'relative',
        border: '1px solid #383B45',
        borderRadius: '4px',
        overflow: 'hidden',
        background: '#1E2329',
    },
    'camera-label': {
        position: 'absolute',
        top: '8px',
        left: '8px',
        background: 'rgba(0, 0, 0, 0.7)',
        color: '#FFFFFF',
        padding: '2px 6px',
        borderRadius: '3px',
        fontSize: '12px',
        zIndex: 5,
    },
    'camera-canvas': {
        width: '100%',
        height: '100%',
        objectFit: 'contain',
    },
}));
```

### 3.3 åˆ›å»ºä¸»ç»„ä»¶æ–‡ä»¶
```typescript
// modules/dreamview_plus/frontend/packages/dreamview-core/src/components/panels/MultiCameraView/index.tsx
import React, { useEffect, useMemo, useRef, useState, useLayoutEffect } from 'react';
import type { apollo } from '@dreamview/dreamview';
import { IconPark, Popover } from '@dreamview/dreamview-ui';
import { isEmpty } from 'lodash';
import { useTranslation } from 'react-i18next';
import { useLocalStorage, KEY_MANAGER } from '@dreamview/dreamview-core/src/util/storageManager';
import useStyle from './useStyle';
import { usePanelContext } from '../base/store/PanelStore';
import { ObstacleTypeColorMap } from '../CameraView/utils';
import LayerMenu from '../CameraView/LayerMenu';
import { StreamDataNames } from '../../../services/api/types';
import Panel from '../base/Panel';
import CustomScroll from '../../CustomScroll';

type ICameraUpdate = apollo.dreamview.ICameraUpdate;
type ICameraFrame = apollo.dreamview.ICameraFrame;

function InternalMultiCameraView() {
    const panelContext = usePanelContext();
    const { logger, panelId, onPanelResize, initSubscription } = panelContext;
    const localBoundingBoxManager = useLocalStorage(`${KEY_MANAGER.BBox}${panelId}`);

    const [showBoundingBox, setShowBoundingBox] = useState(() => localBoundingBoxManager.get());
    const [viewPortSize, setViewPortSize] = useState(null);
    const [data, setData] = useState<ICameraUpdate>();
    
    // 7ä¸ªæ‘„åƒå¤´çš„Canvaså¼•ç”¨
    const canvasRefs = useRef<(HTMLCanvasElement | null)[]>(Array(7).fill(null));

    useEffect(() => {
        initSubscription({
            [StreamDataNames.CAMERA]: {
                consumer: (cameraData: ICameraUpdate) => {
                    // æ£€æŸ¥æ˜¯å¦æ˜¯å¤šæ‘„åƒå¤´æ•°æ®
                    if (cameraData.multi_camera_frames && cameraData.multi_camera_frames.length > 0) {
                        logger.debug(panelId, `Received ${cameraData.multi_camera_frames.length} camera frames`);
                        setData(cameraData);
                    }
                },
            },
        });
    }, []);

    useLayoutEffect(() => {
        onPanelResize((width, height) => {
            setViewPortSize({ viewPortWidth: width, viewPortHeight: height });
        });
    }, []);

    // æ¸²æŸ“å•ä¸ªæ‘„åƒå¤´å¸§
    const renderCameraFrame = (frame: ICameraFrame, canvasIndex: number) => {
        if (!frame?.image_data?.length) {
            logger.debug(panelId, `No image data for camera ${frame?.camera_id}`);
            return;
        }
        
        const canvas = canvasRefs.current[canvasIndex];
        if (!canvas) {
            logger.debug(panelId, `Canvas ${canvasIndex} not available`);
            return;
        }

        try {
            const imageData = new Uint8Array(frame.image_data);
            const blob = new Blob([imageData], { type: 'image/jpeg' });

            createImageBitmap(blob)
                .then((imageBitmap) => {
                    // è®¡ç®—Canvaså°ºå¯¸ï¼ˆ7ä¸ªæ‘„åƒå¤´ç½‘æ ¼å¸ƒå±€ï¼‰
                    const canvasWidth = viewPortSize.viewPortWidth / 4;
                    const canvasHeight = viewPortSize.viewPortHeight / 2;
                    
                    const widthScale = canvasWidth / imageBitmap.width;
                    const heightScale = canvasHeight / imageBitmap.height;
                    const scale = Math.min(widthScale, heightScale);

                    const drawWidth = imageBitmap.width * scale;
                    const drawHeight = imageBitmap.height * scale;

                    canvas.width = drawWidth;
                    canvas.height = drawHeight;

                    const ctx = canvas.getContext('2d');
                    if (!ctx) return;
                    
                    ctx.drawImage(imageBitmap, 0, 0, drawWidth, drawHeight);

                    // ç»˜åˆ¶æ£€æµ‹æ¡†
                    if (frame.bbox2d && frame.bbox2d.length > 0 && showBoundingBox) {
                        frame.bbox2d.forEach((bbox, index) => {
                            const obstaclesId = frame.obstaclesId?.[index];
                            const obstaclesSubType = frame.obstaclesSubType?.[index];

                            ctx.strokeStyle = ObstacleTypeColorMap.get(obstaclesSubType) || 'red';
                            ctx.lineWidth = 2;
                            
                            let { xmin, ymin, xmax, ymax } = bbox;
                            if (xmin === ymin && ymin === xmax && xmax === ymax) {
                                return;
                            }
                            
                            [xmin, ymin, xmax, ymax] = [xmin, ymin, xmax, ymax].map(
                                (value) => value * scale,
                            );
                            
                            ctx.strokeRect(xmin, ymin, xmax - xmin, ymax - ymin);
                            ctx.fillStyle = ObstacleTypeColorMap.get(obstaclesSubType) || 'white';
                            ctx.font = '12px Arial';
                            ctx.fillText(`${obstaclesSubType?.substring(3)}:${obstaclesId}`, xmin, ymin);
                        });
                    }
                })
                .catch((e) => {
                    logger.error(`Error rendering camera ${frame.camera_id}:`, e);
                });
        } catch (error) {
            logger.error(`Error processing camera ${frame.camera_id}:`, error);
        }
    };

    // å¤„ç†å¤šæ‘„åƒå¤´æ•°æ®
    useEffect(() => {
        if (isEmpty(data) || !data.multi_camera_frames) return;
        
        logger.debug(panelId, `Processing ${data.multi_camera_frames.length} camera frames`);
        data.multi_camera_frames.forEach((frame, index) => {
            renderCameraFrame(frame, index);
        });
    }, [data, showBoundingBox, viewPortSize]);

    const { classes } = useStyle();
    
    return (
        <div className={classes['multi-camera-root']}>
            {/* å¤ç”¨CameraViewçš„æ§åˆ¶æŒ‰é’® */}
            <div className={classes['camera-btn-container']}>
                <Popover
                    placement='leftTop'
                    content={<LayerMenu setShowBoundingBox={setShowBoundingBox} />}
                    trigger='click'
                >
                    <span className={classes['camera-btn-item']}>
                        <IconPark name='IcCoverageHover' />
                    </span>
                </Popover>
            </div>
            
            {/* 7ä¸ªæ‘„åƒå¤´çš„ç½‘æ ¼å¸ƒå±€ */}
            <CustomScroll className={classes['multi-camera-container']}>
                <div className={classes['camera-grid']}>
                    {Array.from({ length: 7 }, (_, index) => (
                        <div key={index} className={classes['camera-item']}>
                            <div className={classes['camera-label']}>
                                Camera {index + 1}
                            </div>
                            <canvas 
                                ref={(el) => canvasRefs.current[index] = el}
                                className={classes['camera-canvas']}
                                id={`multi-camera-${panelId}-${index}`}
                            />
                        </div>
                    ))}
                </div>
            </CustomScroll>
        </div>
    );
}

function MultiCameraView(props: any) {
    const Component = useMemo(
        () =>
            Panel({
                PanelComponent: InternalMultiCameraView,
                panelId: props.panelId,
                subscribeInfo: [{ name: StreamDataNames.CAMERA, needChannel: true }],
            }),
        [],
    );
    return <Component {...props} />;
}

InternalMultiCameraView.displayName = 'InternalMultiCameraView';

export default React.memo(MultiCameraView);
```

### 3.4 éªŒè¯æ­¥éª¤3
```bash
# ç¼–è¯‘å‰ç«¯
cd modules/dreamview_plus/frontend
npm run build

# æ£€æŸ¥ç¼–è¯‘æ˜¯å¦æˆåŠŸ
echo $?  # åº”è¯¥è¿”å›0
```

---

## ğŸ”— **æ­¥éª¤4ï¼šæ³¨å†Œæ–°ç»„ä»¶ï¼ˆå‰ç«¯ï¼‰**

### 4.1 æ·»åŠ é¢æ¿ç±»å‹å®šä¹‰
```typescript
// modules/dreamview_plus/frontend/packages/dreamview-core/src/components/panels/type/Panel.ts
// åœ¨PanelTypeæšä¸¾ä¸­æ·»åŠ ï¼š
export enum PanelType {
    // ... ç°æœ‰ç±»å‹
    MultiCameraView = 'MultiCameraView',
}
```

### 4.2 æ³¨å†Œåˆ°é¢æ¿åˆ—è¡¨
```typescript
// modules/dreamview_plus/frontend/packages/dreamview-core/src/components/panels/index.tsx
// åœ¨localPanelsæ•°ç»„ä¸­æ·»åŠ ï¼š
{
    title: t('multiCameraViewTitle'),
    type: PanelType.MultiCameraView,
    thumbnail: cameraViewIllustratorImg,  // å¤ç”¨ç°æœ‰å›¾æ ‡
    description: t('multiCameraViewDescription'),
    renderToolbar: ChannelSelectFactory({
        name: StreamDataNames.CAMERA,
        CustomToolBar: (props) => <DemoChannelSelect {...props} />,
        helpContent: <CameraViewHelp />,  // å¤ç”¨ç°æœ‰å¸®åŠ©
    }),
    module: () => import('@dreamview/dreamview-core/src/components/panels/MultiCameraView'),
},
```

### 4.3 æ·»åŠ å›½é™…åŒ–æ–‡æœ¬
```typescript
// modules/dreamview_plus/frontend/packages/dreamview-lang/zh/panels.ts
export default {
    // ... ç°æœ‰æ–‡æœ¬
    multiCameraViewTitle: 'å¤šæ‘„åƒå¤´è§†å›¾',
    multiCameraViewDescription: 'æ˜¾ç¤º7ä¸ªæ‘„åƒå¤´çš„å®æ—¶ç”»é¢å’Œæ£€æµ‹ç»“æœ',
};

// modules/dreamview_plus/frontend/packages/dreamview-lang/en/panels.ts
export default {
    // ... ç°æœ‰æ–‡æœ¬
    multiCameraViewTitle: 'Multi Camera View',
    multiCameraViewDescription: 'Display real-time views from 7 cameras with detection results',
};
```

### 4.4 éªŒè¯æ­¥éª¤4
```bash
# ç¼–è¯‘å‰ç«¯
cd modules/dreamview_plus/frontend
npm run build

# å¯åŠ¨å‰ç«¯å¼€å‘æœåŠ¡å™¨
npm run dev

# è®¿é—® http://localhost:8080ï¼Œæ£€æŸ¥é¢æ¿åˆ—è¡¨ä¸­æ˜¯å¦å‡ºç°"å¤šæ‘„åƒå¤´è§†å›¾"
```

---

## ğŸ§ª **æ­¥éª¤5ï¼šé›†æˆæµ‹è¯•**

### 5.1 å¯åŠ¨å®Œæ•´ç³»ç»Ÿ
```bash
# å¯åŠ¨Apolloç³»ç»Ÿ
./apollo.sh build_opt
./scripts/bootstrap.sh

# å¯åŠ¨Dreamview Pluså‰ç«¯
cd modules/dreamview_plus/frontend
npm run dev
```

### 5.2 æµ‹è¯•æ­¥éª¤
1. **æ‰“å¼€æµè§ˆå™¨**ï¼šè®¿é—® `http://localhost:8080`
2. **æ·»åŠ é¢æ¿**ï¼šåœ¨é¢æ¿åˆ—è¡¨ä¸­æ‰¾åˆ°"å¤šæ‘„åƒå¤´è§†å›¾"
3. **æ‹–æ‹½é¢æ¿**ï¼šå°†å¤šæ‘„åƒå¤´è§†å›¾æ‹–æ‹½åˆ°å·¥ä½œåŒº
4. **æ£€æŸ¥æ˜¾ç¤º**ï¼šç¡®è®¤7ä¸ªæ‘„åƒå¤´ç”»é¢æ­£å¸¸æ˜¾ç¤º
5. **æ£€æŸ¥æ£€æµ‹æ¡†**ï¼šç¡®è®¤æ£€æµ‹æ¡†å åŠ åŠŸèƒ½æ­£å¸¸

### 5.3 è°ƒè¯•æ–¹æ³•
```bash
# æŸ¥çœ‹åç«¯æ—¥å¿—
tail -f /opt/apollo/logs/dreamview.log

# æŸ¥çœ‹å‰ç«¯æ§åˆ¶å°
# åœ¨æµè§ˆå™¨å¼€å‘è€…å·¥å…·ä¸­æŸ¥çœ‹Networkæ ‡ç­¾ï¼Œç¡®è®¤WebSocketè¿æ¥æ­£å¸¸

# æ£€æŸ¥protobufæ•°æ®
# åœ¨æµè§ˆå™¨æ§åˆ¶å°ä¸­æ‰§è¡Œï¼š
console.log('MultiCamera data:', data);
```

---

## ğŸ“Š **å®æ–½æ£€æŸ¥æ¸…å•**

### åç«¯æ£€æŸ¥é¡¹
- [ ] protobufå®šä¹‰ç¼–è¯‘é€šè¿‡
- [ ] PerceptionCameraUpdaterå¯åŠ¨æˆåŠŸ
- [ ] 7ä¸ªæ‘„åƒå¤´channelè®¢é˜…æ­£å¸¸
- [ ] WebSocketæ•°æ®å‘é€æ­£å¸¸

### å‰ç«¯æ£€æŸ¥é¡¹
- [ ] MultiCameraViewç»„ä»¶ç¼–è¯‘é€šè¿‡
- [ ] é¢æ¿æ³¨å†ŒæˆåŠŸ
- [ ] WebSocketæ•°æ®æ¥æ”¶æ­£å¸¸
- [ ] 7ä¸ªCanvasæ¸²æŸ“æ­£å¸¸
- [ ] æ£€æµ‹æ¡†å åŠ æ­£å¸¸

### ç³»ç»Ÿæ£€æŸ¥é¡¹
- [ ] å‰åç«¯é€šä¿¡æ­£å¸¸
- [ ] æ•°æ®åŒæ­¥æ€§è‰¯å¥½
- [ ] æ€§èƒ½è¡¨ç°ç¬¦åˆé¢„æœŸ
- [ ] æ— å†…å­˜æ³„æ¼

---

## ğŸ¯ **é¢„æœŸç»“æœ**

å®Œæˆæ‰€æœ‰æ­¥éª¤åï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š
1. **åœ¨é¢æ¿åˆ—è¡¨**ä¸­çœ‹åˆ°"å¤šæ‘„åƒå¤´è§†å›¾"é€‰é¡¹
2. **æ‹–æ‹½é¢æ¿**åˆ°å·¥ä½œåŒºå¹¶æ­£å¸¸æ˜¾ç¤º
3. **åŒæ—¶çœ‹åˆ°7ä¸ªæ‘„åƒå¤´**çš„å®æ—¶ç”»é¢
4. **æ£€æµ‹æ¡†æ­£å¸¸å åŠ **åœ¨å›¾åƒä¸Š
5. **æ§åˆ¶æŒ‰é’®æ­£å¸¸å·¥ä½œ**ï¼ˆæ˜¾ç¤º/éšè—æ£€æµ‹æ¡†ï¼‰

å¦‚æœé‡åˆ°é—®é¢˜ï¼Œå¯ä»¥æŒ‰ç…§æ¯ä¸ªæ­¥éª¤çš„éªŒè¯æ–¹æ³•è¿›è¡Œè°ƒè¯•ï¼Œç¡®ä¿æ¯æ­¥éƒ½æˆåŠŸåå†è¿›è¡Œä¸‹ä¸€æ­¥ã€‚

å¥½çš„ï¼Œæˆ‘æ¥é‡æ–°æ•´ç†æ–¹æ¡ˆï¼Œé’ˆå¯¹**ä»æ–‡ä»¶ä¸­è¯»å–7ä¸ªæ‘„åƒå¤´å›¾åƒ**çš„åœºæ™¯è¿›è¡Œä¼˜åŒ–ã€‚

## ğŸ“‹ **æ–‡ä»¶è¯»å–åœºæ™¯çš„å®æ–½è®¡åˆ’**

| æ­¥éª¤ | åç«¯ä¿®æ”¹         | å‰ç«¯ä¿®æ”¹            | é¢„è®¡æ—¶é—´ | éªŒè¯æ–¹æ³•      |
| ---- | ---------------- | ------------------- | -------- | ------------- |
| 1    | æ‰©å±•protobufå®šä¹‰ | -                   | 10åˆ†é’Ÿ   | ç¼–è¯‘é€šè¿‡      |
| 2    | åˆ›å»ºæ–‡ä»¶è¯»å–å™¨   | -                   | 30åˆ†é’Ÿ   | æ–‡ä»¶è¯»å–æˆåŠŸ  |
| 3    | ä¿®æ”¹æ•°æ®å‘å¸ƒé€»è¾‘ | -                   | 20åˆ†é’Ÿ   | æ•°æ®å‘é€æ­£å¸¸  |
| 4    | åˆ›å»ºå‰ç«¯ç»„ä»¶     | æ–°å»ºMultiCameraView | 45åˆ†é’Ÿ   | ç»„ä»¶æ˜¾ç¤º      |
| 5    | é›†æˆæµ‹è¯•         | è¿æ¥æµ‹è¯•            | 15åˆ†é’Ÿ   | 7ä¸ªæ‘„åƒå¤´æ˜¾ç¤º |

---

## ğŸ”§ **æ­¥éª¤1ï¼šæ‰©å±•protobufå®šä¹‰ï¼ˆåç«¯ï¼‰**

### 1.1 ä¿®æ”¹ç°æœ‰protobufæ–‡ä»¶
```protobuf
// modules/dreamview/proto/camera_update.proto
syntax = "proto2";

package apollo.dreamview;

import "modules/common_msgs/dreamview_msgs/simulation_world.proto";

message BoundingBox {
  optional double xmin = 1;
  optional double ymin = 2;
  optional double xmax = 3;
  optional double ymax = 4;
}

message CameraUpdate {
  optional bytes image = 1;
  optional double kImageScale = 2;
  repeated BoundingBox bbox2d = 3;
  repeated string obstaclesId = 4;
  repeated string obstaclesSubType = 5;
  
  // æ–°å¢ï¼šå¤šæ‘„åƒå¤´æ”¯æŒ
  repeated CameraFrame multi_camera_frames = 6;
}

// æ–°å¢ï¼šå•ä¸ªæ‘„åƒå¤´å¸§å®šä¹‰
message CameraFrame {
  optional string camera_id = 1;        // æ‘„åƒå¤´ID (å¦‚: front_6mm)
  optional bytes image_data = 2;        // å‹ç¼©åçš„JPEGæ•°æ®
  optional double timestamp = 3;        // å¸§æ—¶é—´æˆ³
  optional uint32 width = 4;            // åŸå§‹å›¾åƒå®½åº¦
  optional uint32 height = 5;           // åŸå§‹å›¾åƒé«˜åº¦
  optional string file_path = 6;        // æ–°å¢ï¼šæºæ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºè°ƒè¯•ï¼‰
  repeated BoundingBox bbox2d = 7;      // æ£€æµ‹æ¡†æ•°æ®
  repeated string obstaclesId = 8;      // éšœç¢ç‰©ID
  repeated string obstaclesSubType = 9; // éšœç¢ç‰©ç±»å‹
}
```

---

## ğŸ”§ **æ­¥éª¤2ï¼šåˆ›å»ºæ–‡ä»¶è¯»å–å™¨ï¼ˆåç«¯ï¼‰**

### 2.1 åˆ›å»ºæ–‡ä»¶è¯»å–å™¨å¤´æ–‡ä»¶
```cpp
// modules/dreamview_plus/backend/file_camera_reader/file_camera_reader.h
#ifndef MODULES_DREAMVIEW_PLUS_BACKEND_FILE_CAMERA_READER_FILE_CAMERA_READER_H_
#define MODULES_DREAMVIEW_PLUS_BACKEND_FILE_CAMERA_READER_FILE_CAMERA_READER_H_

#include <memory>
#include <string>
#include <vector>
#include <map>
#include <mutex>
#include <atomic>
#include <thread>
#include <chrono>
#include <opencv2/opencv.hpp>

#include "cyber/cyber.h"
#include "modules/dreamview/proto/camera_update.pb.h"
#include "modules/dreamview/backend/common/handlers/websocket_handler.h"

namespace apollo {
namespace dreamview {

struct CameraFileInfo {
  std::string camera_id;
  std::string file_path;
  std::vector<std::string> image_files;  // å›¾åƒæ–‡ä»¶åˆ—è¡¨
  size_t current_index;
  uint32_t width;
  uint32_t height;
};

class FileCameraReader {
public:
  FileCameraReader();
  ~FileCameraReader();

  // åˆå§‹åŒ–æ‘„åƒå¤´æ–‡ä»¶ä¿¡æ¯
  bool Initialize(const std::vector<std::string>& camera_directories);
  
  // å¼€å§‹è¯»å–å’Œå‘é€æ•°æ®
  void Start();
  void Stop();
  
  // è®¾ç½®WebSocketå¤„ç†å™¨
  void SetWebSocketHandler(std::shared_ptr<WebSocketHandler> websocket);
  
  // è®¾ç½®å‘é€é¢‘ç‡ (fps)
  void SetFrameRate(int fps);

private:
  void ReadingLoop();
  void ProcessCameraFrame(const CameraFileInfo& camera_info);
  void PublishMultiCameraUpdate();
  void ResetMultiCameraBatch();
  bool LoadImageFiles(const std::string& directory, std::vector<std::string>& image_files);
  cv::Mat LoadAndProcessImage(const std::string& file_path);
  std::vector<uint8_t> CompressImage(const cv::Mat& image);

private:
  std::vector<CameraFileInfo> camera_infos_;
  std::map<std::string, CameraFrame> multi_camera_cache_;
  std::atomic<int> received_camera_count_{0};
  std::chrono::steady_clock::time_point batch_start_time_;
  std::mutex multi_camera_mutex_;
  
  std::shared_ptr<WebSocketHandler> websocket_;
  std::unique_ptr<cyber::Node> node_;
  std::atomic<bool> running_{false};
  std::unique_ptr<std::thread> reading_thread_;
  
  int frame_rate_{10};  // é»˜è®¤10fps
  static constexpr int EXPECTED_CAMERA_COUNT = 7;
  static constexpr int BATCH_TIMEOUT_MS = 100;
};

}  // namespace dreamview
}  // namespace apollo

#endif  // MODULES_DREAMVIEW_PLUS_BACKEND_FILE_CAMERA_READER_FILE_CAMERA_READER_H_
```

### 2.2 å®ç°æ–‡ä»¶è¯»å–å™¨
```cpp
// modules/dreamview_plus/backend/file_camera_reader/file_camera_reader.cc
#include "modules/dreamview_plus/backend/file_camera_reader/file_camera_reader.h"
#include <filesystem>
#include <algorithm>
#include <fstream>
#include <sstream>

namespace apollo {
namespace dreamview {

FileCameraReader::FileCameraReader() {
  node_ = cyber::CreateNode("file_camera_reader");
}

FileCameraReader::~FileCameraReader() {
  Stop();
}

bool FileCameraReader::Initialize(const std::vector<std::string>& camera_directories) {
  if (camera_directories.size() != 7) {
    AERROR << "Expected 7 camera directories, got " << camera_directories.size();
    return false;
  }
  
  std::vector<std::string> camera_ids = {
    "front_6mm", "front_12mm", "front_fisheye", 
    "left_front", "left_rear", "right_front", "right_rear"
  };
  
  camera_infos_.clear();
  
  for (size_t i = 0; i < camera_directories.size(); ++i) {
    CameraFileInfo camera_info;
    camera_info.camera_id = camera_ids[i];
    camera_info.file_path = camera_directories[i];
    camera_info.current_index = 0;
    camera_info.width = 960;   // é»˜è®¤å®½åº¦
    camera_info.height = 640;  // é»˜è®¤é«˜åº¦
    
    // åŠ è½½å›¾åƒæ–‡ä»¶åˆ—è¡¨
    if (!LoadImageFiles(camera_directories[i], camera_info.image_files)) {
      AERROR << "Failed to load image files from " << camera_directories[i];
      return false;
    }
    
    AINFO << "Loaded " << camera_info.image_files.size() 
          << " images for camera " << camera_info.camera_id;
    
    camera_infos_.push_back(camera_info);
  }
  
  return true;
}

void FileCameraReader::Start() {
  if (running_) {
    AWARN << "FileCameraReader already running";
    return;
  }
  
  running_ = true;
  ResetMultiCameraBatch();
  
  // å¯åŠ¨è¯»å–çº¿ç¨‹
  reading_thread_ = std::make_unique<std::thread>(&FileCameraReader::ReadingLoop, this);
  
  AINFO << "FileCameraReader started";
}

void FileCameraReader::Stop() {
  if (!running_) return;
  
  running_ = false;
  
  if (reading_thread_ && reading_thread_->joinable()) {
    reading_thread_->join();
  }
  
  AINFO << "FileCameraReader stopped";
}

void FileCameraReader::SetWebSocketHandler(std::shared_ptr<WebSocketHandler> websocket) {
  websocket_ = websocket;
}

void FileCameraReader::SetFrameRate(int fps) {
  frame_rate_ = std::max(1, std::min(30, fps));  // é™åˆ¶åœ¨1-30fps
  AINFO << "Frame rate set to " << frame_rate_ << " fps";
}

void FileCameraReader::ReadingLoop() {
  const auto frame_duration = std::chrono::milliseconds(1000 / frame_rate_);
  
  while (running_) {
    auto start_time = std::chrono::steady_clock::now();
    
    // å¤„ç†æ¯ä¸ªæ‘„åƒå¤´çš„å½“å‰å¸§
    for (auto& camera_info : camera_infos_) {
      ProcessCameraFrame(camera_info);
    }
    
    // å‘é€æ‰¹é‡æ›´æ–°
    PublishMultiCameraUpdate();
    ResetMultiCameraBatch();
    
    // ç­‰å¾…ä¸‹ä¸€å¸§
    auto elapsed = std::chrono::steady_clock::now() - start_time;
    if (elapsed < frame_duration) {
      std::this_thread::sleep_for(frame_duration - elapsed);
    }
  }
}

void FileCameraReader::ProcessCameraFrame(const CameraFileInfo& camera_info) {
  if (camera_info.image_files.empty()) return;
  
  // è·å–å½“å‰å›¾åƒæ–‡ä»¶è·¯å¾„
  const std::string& current_file = camera_info.image_files[camera_info.current_index];
  
  // åŠ è½½å’Œå¤„ç†å›¾åƒ
  cv::Mat image = LoadAndProcessImage(current_file);
  if (image.empty()) {
    AWARN << "Failed to load image: " << current_file;
    return;
  }
  
  // å‹ç¼©å›¾åƒ
  std::vector<uint8_t> compressed_data = CompressImage(image);
  if (compressed_data.empty()) {
    AWARN << "Failed to compress image: " << current_file;
    return;
  }
  
  // åˆ›å»ºCameraFrame
  std::lock_guard<std::mutex> lock(multi_camera_mutex_);
  CameraFrame frame;
  frame.set_camera_id(camera_info.camera_id);
  frame.set_image_data(compressed_data.data(), compressed_data.size());
  frame.set_timestamp(std::chrono::duration_cast<std::chrono::milliseconds>(
      std::chrono::steady_clock::now().time_since_epoch()).count() / 1000.0);
  frame.set_width(camera_info.width);
  frame.set_height(camera_info.height);
  frame.set_file_path(current_file);
  
  // ç¼“å­˜å¤šæ‘„åƒå¤´æ•°æ®
  multi_camera_cache_[camera_info.camera_id] = frame;
  received_camera_count_++;
  
  AINFO << "Processed frame for camera " << camera_info.camera_id 
        << " from file " << current_file;
}

void FileCameraReader::PublishMultiCameraUpdate() {
  if (multi_camera_cache_.empty()) return;
  
  CameraUpdate camera_update;
  
  // å¡«å……å¤šæ‘„åƒå¤´æ•°æ®
  for (const auto& [camera_id, frame] : multi_camera_cache_) {
    CameraFrame* new_frame = camera_update.add_multi_camera_frames();
    *new_frame = frame;
  }
  
  // å‘é€å¤šæ‘„åƒå¤´æ›´æ–°
  std::string to_send;
  camera_update.SerializeToString(&to_send);
  
  StreamData stream_data;
  stream_data.set_action("stream");
  stream_data.set_data_name("camera");
  stream_data.set_channel_name("multi_camera_file");  // æ ‡è¯†æ–‡ä»¶æ¥æº
  stream_data.set_data(to_send.data(), to_send.size());
  stream_data.set_type("camera");
  
  std::string stream_data_string;
  stream_data.SerializeToString(&stream_data_string);
  
  if (websocket_) {
    websocket_->BroadcastBinaryData(stream_data_string);
    AINFO << "Published multi-camera update with " << multi_camera_cache_.size() << " frames";
  }
}

void FileCameraReader::ResetMultiCameraBatch() {
  multi_camera_cache_.clear();
  received_camera_count_ = 0;
  batch_start_time_ = std::chrono::steady_clock::now();
}

bool FileCameraReader::LoadImageFiles(const std::string& directory, std::vector<std::string>& image_files) {
  image_files.clear();
  
  try {
    for (const auto& entry : std::filesystem::directory_iterator(directory)) {
      if (entry.is_regular_file()) {
        std::string file_path = entry.path().string();
        std::string extension = entry.path().extension().string();
        
        // æ”¯æŒå¸¸è§å›¾åƒæ ¼å¼
        std::transform(extension.begin(), extension.end(), extension.begin(), ::tolower);
        if (extension == ".jpg" || extension == ".jpeg" || extension == ".png" || 
            extension == ".bmp" || extension == ".tiff") {
          image_files.push_back(file_path);
        }
      }
    }
    
    // æŒ‰æ–‡ä»¶åæ’åº
    std::sort(image_files.begin(), image_files.end());
    
    return !image_files.empty();
  } catch (const std::exception& e) {
    AERROR << "Error loading image files from " << directory << ": " << e.what();
    return false;
  }
}

cv::Mat FileCameraReader::LoadAndProcessImage(const std::string& file_path) {
  cv::Mat image = cv::imread(file_path);
  if (image.empty()) {
    return image;
  }
  
  // è½¬æ¢ä¸ºRGBæ ¼å¼
  cv::cvtColor(image, image, cv::COLOR_BGR2RGB);
  
  // è°ƒæ•´å¤§å°åˆ°960x640
  cv::resize(image, image, cv::Size(960, 640));
  
  return image;
}

std::vector<uint8_t> FileCameraReader::CompressImage(const cv::Mat& image) {
  std::vector<uint8_t> compressed_data;
  
  // å‹ç¼©å‚æ•°ï¼šè´¨é‡85%ï¼Œä¼˜åŒ–å‹ç¼©
  std::vector<int> compression_params = {
    cv::IMWRITE_JPEG_QUALITY, 85,
    cv::IMWRITE_JPEG_OPTIMIZE, 1
  };
  
  cv::imencode(".jpg", image, compressed_data, compression_params);
  
  return compressed_data;
}

}  // namespace dreamview
}  // namespace apollo
```

### 2.3 åˆ›å»ºBUILDæ–‡ä»¶
```python
# modules/dreamview_plus/backend/file_camera_reader/BUILD
cc_library(
    name = "file_camera_reader",
    srcs = ["file_camera_reader.cc"],
    hdrs = ["file_camera_reader.h"],
    deps = [
        "//cyber",
        "//modules/dreamview/proto:camera_update_cc_proto",
        "//modules/dreamview/backend/common/handlers:websocket_handler",
        "@opencv",
    ],
)

cc_binary(
    name = "file_camera_reader_main",
    srcs = ["main.cc"],
    deps = [
        ":file_camera_reader",
        "//cyber",
    ],
)
```

### 2.4 åˆ›å»ºä¸»ç¨‹åº
```cpp
// modules/dreamview_plus/backend/file_camera_reader/main.cc
#include "modules/dreamview_plus/backend/file_camera_reader/file_camera_reader.h"
#include "modules/dreamview/backend/common/handlers/websocket_handler.h"
#include "cyber/cyber.h"

int main(int argc, char** argv) {
  // åˆå§‹åŒ–Cyber
  apollo::cyber::Init(argv[0]);
  
  // ç¤ºä¾‹ï¼š7ä¸ªæ‘„åƒå¤´çš„æ–‡ä»¶ç›®å½•
  std::vector<std::string> camera_directories = {
    "/path/to/camera1/images",  // front_6mm
    "/path/to/camera2/images",  // front_12mm
    "/path/to/camera3/images",  // front_fisheye
    "/path/to/camera4/images",  // left_front
    "/path/to/camera5/images",  // left_rear
    "/path/to/camera6/images",  // right_front
    "/path/to/camera7/images"   // right_rear
  };
  
  // åˆ›å»ºæ–‡ä»¶è¯»å–å™¨
  auto file_reader = std::make_unique<apollo::dreamview::FileCameraReader>();
  
  // åˆå§‹åŒ–
  if (!file_reader->Initialize(camera_directories)) {
    AERROR << "Failed to initialize file camera reader";
    return -1;
  }
  
  // è®¾ç½®WebSocketå¤„ç†å™¨
  auto websocket = std::make_shared<apollo::dreamview::WebSocketHandler>("FileCamera");
  file_reader->SetWebSocketHandler(websocket);
  
  // è®¾ç½®å¸§ç‡
  file_reader->SetFrameRate(10);  // 10fps
  
  // å¯åŠ¨è¯»å–
  file_reader->Start();
  
  AINFO << "File camera reader started. Press Ctrl+C to stop.";
  
  // ç­‰å¾…ä¸­æ–­ä¿¡å·
  apollo::cyber::WaitForShutdown();
  
  // åœæ­¢è¯»å–
  file_reader->Stop();
  
  AINFO << "File camera reader stopped";
  return 0;
}
```

---

## ğŸ”§ **æ­¥éª¤3ï¼šé›†æˆåˆ°Dreamview Plusï¼ˆåç«¯ï¼‰**

### 3.1 ä¿®æ”¹Dreamview Plusä¸»ç¨‹åº
```cpp
// modules/dreamview_plus/backend/dreamview.cc
// åœ¨ç°æœ‰ä»£ç ä¸­æ·»åŠ ï¼š

#include "modules/dreamview_plus/backend/file_camera_reader/file_camera_reader.h"

// åœ¨Dreamviewç±»ä¸­æ·»åŠ æˆå‘˜å˜é‡
class Dreamview {
private:
  // ç°æœ‰æˆå‘˜å˜é‡...
  std::unique_ptr<FileCameraReader> file_camera_reader_;
  
public:
  void Start() {
    // ç°æœ‰å¯åŠ¨ä»£ç ...
    
    // åˆå§‹åŒ–æ–‡ä»¶æ‘„åƒå¤´è¯»å–å™¨
    InitializeFileCameraReader();
  }
  
private:
  void InitializeFileCameraReader() {
    // ä»é…ç½®æ–‡ä»¶è¯»å–æ‘„åƒå¤´ç›®å½•è·¯å¾„
    std::vector<std::string> camera_directories = {
      "/opt/apollo/data/cameras/front_6mm",
      "/opt/apollo/data/cameras/front_12mm", 
      "/opt/apollo/data/cameras/front_fisheye",
      "/opt/apollo/data/cameras/left_front",
      "/opt/apollo/data/cameras/left_rear",
      "/opt/apollo/data/cameras/right_front",
      "/opt/apollo/data/cameras/right_rear"
    };
    
    file_camera_reader_ = std::make_unique<FileCameraReader>();
    
    if (file_camera_reader_->Initialize(camera_directories)) {
      file_camera_reader_->SetWebSocketHandler(websocket_);
      file_camera_reader_->SetFrameRate(10);
      file_camera_reader_->Start();
      AINFO << "File camera reader initialized successfully";
    } else {
      AWARN << "Failed to initialize file camera reader";
    }
  }
};
```

### 3.2 åˆ›å»ºé…ç½®æ–‡ä»¶
```json
// modules/dreamview_plus/conf/file_camera_config.json
{
  "camera_directories": [
    "/opt/apollo/data/cameras/front_6mm",
    "/opt/apollo/data/cameras/front_12mm",
    "/opt/apollo/data/cameras/front_fisheye",
    "/opt/apollo/data/cameras/left_front",
    "/opt/apollo/data/cameras/left_rear",
    "/opt/apollo/data/cameras/right_front",
    "/opt/apollo/data/cameras/right_rear"
  ],
  "frame_rate": 10,
  "image_format": ["jpg", "jpeg", "png"],
  "target_size": {
    "width": 960,
    "height": 640
  },
  "compression": {
    "quality": 85,
    "optimize": true
  }
}
```

---

## ğŸ¨ **æ­¥éª¤4ï¼šåˆ›å»ºå‰ç«¯ç»„ä»¶ï¼ˆå‰ç«¯ï¼‰**

### 4.1 åˆ›å»ºMultiCameraViewç»„ä»¶ï¼ˆå¤ç”¨ä¹‹å‰çš„ä»£ç ï¼‰
```typescript
// modules/dreamview_plus/frontend/packages/dreamview-core/src/components/panels/MultiCameraView/index.tsx
// ï¼ˆä½¿ç”¨ä¹‹å‰æ­¥éª¤4ä¸­çš„å®Œæ•´ä»£ç ï¼Œè¿™é‡Œçœç•¥é‡å¤å†…å®¹ï¼‰
```

### 4.2 æ·»åŠ æ–‡ä»¶ä¿¡æ¯æ˜¾ç¤º
```typescript
// åœ¨MultiCameraViewç»„ä»¶ä¸­æ·»åŠ æ–‡ä»¶ä¿¡æ¯æ˜¾ç¤º
const renderCameraFrame = (frame: ICameraFrame, canvasIndex: number) => {
    if (!frame?.image_data?.length) {
        logger.debug(panelId, `No image data for camera ${frame?.camera_id}`);
        return;
    }
    
    const canvas = canvasRefs.current[canvasIndex];
    if (!canvas) return;

    try {
        const imageData = new Uint8Array(frame.image_data);
        const blob = new Blob([imageData], { type: 'image/jpeg' });

        createImageBitmap(blob)
            .then((imageBitmap) => {
                // ... ç°æœ‰çš„æ¸²æŸ“é€»è¾‘ ...
                
                // æ–°å¢ï¼šæ˜¾ç¤ºæ–‡ä»¶è·¯å¾„ä¿¡æ¯
                const ctx = canvas.getContext('2d');
                if (ctx && frame.file_path) {
                    const fileName = frame.file_path.split('/').pop() || 'unknown';
                    ctx.fillStyle = 'rgba(0, 0, 0, 0.7)';
                    ctx.fillRect(0, canvas.height - 20, canvas.width, 20);
                    ctx.fillStyle = '#FFFFFF';
                    ctx.font = '10px Arial';
                    ctx.fillText(fileName, 5, canvas.height - 8);
                }
            })
            .catch((e) => {
                logger.error(`Error rendering camera ${frame.camera_id}:`, e);
            });
    } catch (error) {
        logger.error(`Error processing camera ${frame.camera_id}:`, error);
    }
};
```

---

## ğŸ§ª **æ­¥éª¤5ï¼šæµ‹è¯•å’ŒéªŒè¯**

### 5.1 å‡†å¤‡æµ‹è¯•æ•°æ®
```bash
# åˆ›å»ºæµ‹è¯•ç›®å½•ç»“æ„
mkdir -p /opt/apollo/data/cameras/{front_6mm,front_12mm,front_fisheye,left_front,left_rear,right_front,right_rear}

# å¤åˆ¶ä¸€äº›æµ‹è¯•å›¾åƒåˆ°å„ä¸ªç›®å½•
# ç¡®ä¿æ¯ä¸ªç›®å½•éƒ½æœ‰ç›¸åŒæ•°é‡çš„å›¾åƒæ–‡ä»¶
```

### 5.2 ç¼–è¯‘å’Œå¯åŠ¨
```bash
# ç¼–è¯‘åç«¯
./apollo.sh build

# å¯åŠ¨ç³»ç»Ÿ
./apollo.sh build_opt
./scripts/bootstrap.sh

# å¯åŠ¨å‰ç«¯
cd modules/dreamview_plus/frontend
npm run dev
```

### 5.3 éªŒè¯æ£€æŸ¥æ¸…å•
- [ ] æ–‡ä»¶è¯»å–å™¨æˆåŠŸåŠ è½½å›¾åƒæ–‡ä»¶
- [ ] 7ä¸ªæ‘„åƒå¤´æ•°æ®æ­£å¸¸å‘é€
- [ ] å‰ç«¯æ­£ç¡®æ¥æ”¶å’Œæ˜¾ç¤ºå›¾åƒ
- [ ] æ–‡ä»¶è·¯å¾„ä¿¡æ¯æ­£ç¡®æ˜¾ç¤º
- [ ] å¸§ç‡æ§åˆ¶æ­£å¸¸å·¥ä½œ
- [ ] å†…å­˜ä½¿ç”¨æ­£å¸¸ï¼ˆæ— æ³„æ¼ï¼‰

---

## ğŸ“Š **æ–‡ä»¶è¯»å–æ–¹æ¡ˆçš„ä¼˜åŠ¿**

| ç‰¹æ€§           | æ–‡ä»¶è¯»å–æ–¹æ¡ˆ | å®æ—¶æ‘„åƒå¤´æ–¹æ¡ˆ |
| -------------- | ------------ | -------------- |
| **æ•°æ®æ¥æº**   | æœ¬åœ°æ–‡ä»¶     | å®æ—¶æ‘„åƒå¤´     |
| **è°ƒè¯•å‹å¥½**   | âœ… å¯é‡å¤æ’­æ”¾ | âŒ å®æ—¶å˜åŒ–     |
| **æ•°æ®ä¸€è‡´æ€§** | âœ… å›ºå®šæ•°æ®é›† | âŒ åŠ¨æ€å˜åŒ–     |
| **å¼€å‘ä¾¿åˆ©**   | âœ… æ— éœ€ç¡¬ä»¶   | âŒ éœ€è¦æ‘„åƒå¤´   |
| **æ€§èƒ½ç¨³å®š**   | âœ… å¯æ§å¸§ç‡   | âŒ ä¾èµ–ç¡¬ä»¶     |
| **æµ‹è¯•å¯é **   | âœ… å¯é¢„æµ‹ç»“æœ | âŒ ç¯å¢ƒæ•æ„Ÿ     |

è¿™ä¸ªæ–¹æ¡ˆç‰¹åˆ«é€‚åˆï¼š
1. **ç®—æ³•å¼€å‘**ï¼šä½¿ç”¨å›ºå®šçš„æµ‹è¯•æ•°æ®é›†
2. **ç³»ç»Ÿè°ƒè¯•**ï¼šå¯é‡å¤æ’­æ”¾ç›¸åŒåœºæ™¯
3. **æ€§èƒ½æµ‹è¯•**ï¼šç¨³å®šçš„æ•°æ®æº
4. **æ¼”ç¤ºå±•ç¤º**ï¼šå¯æ§çš„æ’­æ”¾æ•ˆæœ